{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">S2R Analytics</h1>\n",
    "<h2 align=\"center\">Profitability of Client X projects: run 1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "* [Part 6](#part6): Classification\n",
    "    * [6.0](#6_0): Data splitting\n",
    "    * [6.1](#6_1): Models\n",
    "<br />\n",
    "<br />\n",
    "* [Part 7](#part7): Fine-tuning\n",
    "* [Part 8](#part8): Ensemble learning\n",
    "* [Part 9](#part9): Evaluation of the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentials\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from pandas.api.types import CategoricalDtype\n",
    "pd.options.display.max_columns = None\n",
    "import sqlite3\n",
    "import pyodbc\n",
    "import numpy as np; np.random.seed(1)\n",
    "\n",
    "# Image creation and display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import pyplot\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Metrics of accuracy\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from pycm import *\n",
    "import imbalanced_ensemble as imbens\n",
    "from imbalanced_ensemble.ensemble.base import sort_dict_by_key\n",
    "from collections import Counter\n",
    "\n",
    "# Fine-tuning and enseble learning\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Other\n",
    "import itertools as it\n",
    "import io\n",
    "import os\n",
    "os.sys.path\n",
    "import sys\n",
    "import glob\n",
    "import concurrent.futures\n",
    "from __future__ import print_function\n",
    "import binascii\n",
    "import struct\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import scipy.cluster\n",
    "import datetime, time\n",
    "import functools, operator\n",
    "from datetime import datetime\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../csv-files/active_projects.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project ID</th>\n",
       "      <th>Country</th>\n",
       "      <th>Office</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Project Size Sort Order</th>\n",
       "      <th>Is Multi Discipline Project</th>\n",
       "      <th>Is Multi Team</th>\n",
       "      <th>Team Size</th>\n",
       "      <th>Perc of Team Recent</th>\n",
       "      <th>Is First Client Project</th>\n",
       "      <th>Perc of Subcontractors</th>\n",
       "      <th>Project Duration Weeks</th>\n",
       "      <th>Director Is Recent</th>\n",
       "      <th>Manager Is Recent</th>\n",
       "      <th>Perc of Stages with Hourly Rates</th>\n",
       "      <th>Profit Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>367711</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>367721</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>2326.47</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45.56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>367723</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>367725</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>1861.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>367729</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>1972.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>1119794</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>1146871</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>1172310</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>1174126</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>1240781</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2133 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Project ID  Country  Office  Sector  Project Size Sort Order  \\\n",
       "0         367711        0       3       0                      4.0   \n",
       "1         367721        0       3      10                      8.0   \n",
       "2         367723        0       3       6                      5.0   \n",
       "3         367725        0       3      10                      8.0   \n",
       "4         367729        0       3      10                      8.0   \n",
       "...          ...      ...     ...     ...                      ...   \n",
       "2128     1119794        0       3       2                      6.0   \n",
       "2129     1146871        0       3       7                      3.0   \n",
       "2130     1172310        0       3       7                      4.0   \n",
       "2131     1174126        0       3       7                      5.0   \n",
       "2132     1240781        0       3       6                      5.0   \n",
       "\n",
       "      Is Multi Discipline Project  Is Multi Team  Team Size  \\\n",
       "0                               1              1         11   \n",
       "1                               1              1         68   \n",
       "2                               1              1         16   \n",
       "3                               1              1         91   \n",
       "4                               1              1         92   \n",
       "...                           ...            ...        ...   \n",
       "2128                            0              0          0   \n",
       "2129                            0              0          0   \n",
       "2130                            0              0          0   \n",
       "2131                            0              0          0   \n",
       "2132                            0              0          0   \n",
       "\n",
       "      Perc of Team Recent  Is First Client Project  Perc of Subcontractors  \\\n",
       "0                    0.00                        1                     0.0   \n",
       "1                 2326.47                        1                     0.0   \n",
       "2                    0.00                        1                     0.0   \n",
       "3                 1861.54                        1                     0.0   \n",
       "4                 1972.83                        1                     0.0   \n",
       "...                   ...                      ...                     ...   \n",
       "2128               100.00                        0                     0.0   \n",
       "2129               100.00                        0                     0.0   \n",
       "2130               100.00                        0                     0.0   \n",
       "2131               100.00                        0                     0.0   \n",
       "2132               100.00                        0                     0.0   \n",
       "\n",
       "      Project Duration Weeks  Director Is Recent  Manager Is Recent  \\\n",
       "0                      104.0                   0                  0   \n",
       "1                      343.0                   0                  1   \n",
       "2                       43.0                   0                  0   \n",
       "3                      342.0                   0                  0   \n",
       "4                      398.0                   0                  0   \n",
       "...                      ...                 ...                ...   \n",
       "2128                    54.0                   1                  1   \n",
       "2129                     3.0                   1                  1   \n",
       "2130                     5.0                   1                  1   \n",
       "2131                    51.0                   1                  1   \n",
       "2132                     9.0                   1                  1   \n",
       "\n",
       "      Perc of Stages with Hourly Rates  Profit Class  \n",
       "0                               100.00             1  \n",
       "1                                45.56             2  \n",
       "2                                75.00             0  \n",
       "3                                44.33             1  \n",
       "4                                28.26             2  \n",
       "...                                ...           ...  \n",
       "2128                              0.00             0  \n",
       "2129                            100.00             1  \n",
       "2130                              0.00             1  \n",
       "2131                              0.00             0  \n",
       "2132                              0.00             1  \n",
       "\n",
       "[2133 rows x 16 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: <a class=\"anchor\" id=\"part6\"></a> Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0 <a class=\"anchor\" id=\"6_0\"></a> Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'Profit Class':'Profit_Class'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training data: 1706\n",
      "No. of training targets: 1706\n",
      "No. of testing data: 427\n",
      "No. of testing targets: 427\n"
     ]
    }
   ],
   "source": [
    "# Choose dependent variables\n",
    "Y = df[['Profit_Class']]\n",
    "\n",
    "# Drop the dependent variables from the feature data set\n",
    "X = df.drop(columns = ['Profit_Class'])\n",
    "\n",
    "# Scale the explanatory variables\n",
    "X1 = pd.DataFrame(StandardScaler().fit_transform(X))\n",
    "X1.columns = X.columns\n",
    "X = X1\n",
    "\n",
    "# Split data set into train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=1, stratify = Y)\n",
    "\n",
    "print(f'No. of training data: {X_train.shape[0]}')\n",
    "print(f'No. of training targets: {Y_train.shape[0]}')\n",
    "print(f'No. of testing data: {X_test.shape[0]}')\n",
    "print(f'No. of testing targets: {Y_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 has 410 samples in full dataset.\n",
      "Class 0 has 328 samples in training set.\n",
      "Class 0 has 82 samples in test set.\n",
      "Class 1 has 921 samples in full dataset.\n",
      "Class 1 has 737 samples in training set.\n",
      "Class 1 has 184 samples in test set.\n",
      "Class 2 has 802 samples in full dataset.\n",
      "Class 2 has 641 samples in training set.\n",
      "Class 2 has 161 samples in test set.\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f'Class {i} has {(Y.Profit_Class==i).sum()} samples in full dataset.')\n",
    "    print(f'Class {i} has {(Y_train.Profit_Class==i).sum()} samples in training set.')\n",
    "    print(f'Class {i} has {(Y_test.Profit_Class==i).sum()} samples in test set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 <a class=\"anchor\" id=\"6_1\"></a> Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1  <a class=\"anchor\" id=\"6_1_1\"></a> Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of LOG: 45.0%\n",
      "F1 of LOG: 44.9%\n",
      "Recall score of LOG: 46.400000000000006%\n",
      "Accuracy score of LOG: 46.400000000000006%\n"
     ]
    }
   ],
   "source": [
    "# Create a logistic regression model\n",
    "log = LogisticRegression(random_state = 1, max_iter = 30000)\n",
    "\n",
    "# Train the model using train set\n",
    "log.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "log_y_pred=log.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Precision score of LOG: ' + str(round(metrics.precision_score(Y_test, np.round(log_y_pred), average='weighted', zero_division=0), 3)*100)+'%')\n",
    "print('F1 of LOG: ' + str(round(metrics.f1_score(Y_test, np.round(log_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall score of LOG: ' + str(round(metrics.recall_score(Y_test, np.round(log_y_pred), average='weighted', zero_division=0), 3)*100)+'%')\n",
    "print('Accuracy score of LOG: ' + str(round(metrics.accuracy_score(Y_test, np.round(log_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.2 <a class=\"anchor\" id=\"6_1_2\"></a> K-Neighbours classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of KNN-7: 50.1%\n",
      "F1 of KNN-7: 49.8%\n",
      "Recall score of KNN-7: 49.6%\n",
      "Accuracy score of KNN-7: 49.6%\n"
     ]
    }
   ],
   "source": [
    "# Create a k-Neighbours classifier model with 7 neighbours\n",
    "np.random.seed(1)\n",
    "knn_7 = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "# Train the model using train set\n",
    "knn_7.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "knn_7_y_pred = knn_7.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Precision score of KNN-7: ' + str(round(metrics.precision_score(Y_test, np.round(knn_7_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of KNN-7: ' + str(round(metrics.f1_score(Y_test, np.round(knn_7_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall score of KNN-7: ' + str(round(metrics.recall_score(Y_test, np.round(knn_7_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of KNN-7: ' + str(round(metrics.accuracy_score(Y_test, np.round(knn_7_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3  <a class=\"anchor\" id=\"6_1_3\"></a> Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of DTC: 52.2%\n",
      "F1 of DTC: 51.9%\n",
      "Recall score of DTC: 51.800000000000004%\n",
      "Accuracy score of DTC: 51.800000000000004%\n"
     ]
    }
   ],
   "source": [
    "# Create a decision tree classifier model\n",
    "dtc = DecisionTreeClassifier(random_state = 1)\n",
    "\n",
    "# Train the model using train set\n",
    "dtc = dtc.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "dtc_y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Precision score of DTC: ' + str(round(metrics.precision_score(Y_test, np.round(dtc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of DTC: ' + str(round(metrics.f1_score(Y_test, np.round(dtc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall score of DTC: ' + str(round(metrics.recall_score(Y_test, np.round(dtc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of DTC: ' + str(round(metrics.accuracy_score(Y_test, np.round(dtc_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.4  <a class=\"anchor\" id=\"6_1_4\"></a> Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of RFC: 57.099999999999994%\n",
      "F1 of RFC: 57.099999999999994%\n",
      "Recall score of RFC: 57.4%\n",
      "Accuracy score of RFC: 57.4%\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier model\n",
    "rfc = RandomForestClassifier(random_state = 1)\n",
    "\n",
    "# Train the model using train set\n",
    "rfc.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "rfc_y_pred=rfc.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Precision score of RFC: ' + str(round(metrics.precision_score(Y_test, np.round(rfc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of RFC: ' + str(round(metrics.f1_score(Y_test, np.round(rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall score of RFC: ' + str(round(metrics.recall_score(Y_test, np.round(rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(rfc_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict   0         1         2         \n",
      "Actual\n",
      "0         33        33        16        \n",
      "\n",
      "1         25        110       49        \n",
      "\n",
      "2         6         53        102       \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overall Statistics : \n",
      "\n",
      "95% CI                                                            (0.52686,0.62068)\n",
      "ACC Macro                                                         0.71585\n",
      "ARI                                                               0.11652\n",
      "AUNP                                                              0.65594\n",
      "AUNU                                                              0.65761\n",
      "Bangdiwala B                                                      0.34594\n",
      "Bennett S                                                         0.36066\n",
      "CBA                                                               0.52481\n",
      "CSI                                                               0.10714\n",
      "Chi-Squared                                                       102.54335\n",
      "Chi-Squared DF                                                    4\n",
      "Conditional Entropy                                               1.29311\n",
      "Cramer V                                                          0.34652\n",
      "Cross Entropy                                                     1.52057\n",
      "F1 Macro                                                          0.55098\n",
      "F1 Micro                                                          0.57377\n",
      "FNR Macro                                                         0.4554\n",
      "FNR Micro                                                         0.42623\n",
      "FPR Macro                                                         0.22938\n",
      "FPR Micro                                                         0.21311\n",
      "Gwet AC1                                                          0.37991\n",
      "Hamming Loss                                                      0.42623\n",
      "Joint Entropy                                                     2.8042\n",
      "KL Divergence                                                     0.00948\n",
      "Kappa                                                             0.31907\n",
      "Kappa 95% CI                                                      (0.24414,0.39401)\n",
      "Kappa No Prevalence                                               0.14754\n",
      "Kappa Standard Error                                              0.03823\n",
      "Kappa Unbiased                                                    0.31832\n",
      "Krippendorff Alpha                                                0.31912\n",
      "Lambda A                                                          0.25103\n",
      "Lambda B                                                          0.21212\n",
      "Mutual Information                                                0.16263\n",
      "NIR                                                               0.43091\n",
      "Overall ACC                                                       0.57377\n",
      "Overall CEN                                                       0.6447\n",
      "Overall J                                                         (1.15077,0.38359)\n",
      "Overall MCC                                                       0.31983\n",
      "Overall MCEN                                                      0.76031\n",
      "Overall RACC                                                      0.37404\n",
      "Overall RACCU                                                     0.37473\n",
      "P-Value                                                           0.0\n",
      "PPV Macro                                                         0.56254\n",
      "PPV Micro                                                         0.57377\n",
      "Pearson C                                                         0.44005\n",
      "Phi-Squared                                                       0.24015\n",
      "RCI                                                               0.10763\n",
      "RR                                                                142.33333\n",
      "Reference Entropy                                                 1.51108\n",
      "Response Entropy                                                  1.45575\n",
      "SOA1(Landis & Koch)                                               Fair\n",
      "SOA2(Fleiss)                                                      Poor\n",
      "SOA3(Altman)                                                      Fair\n",
      "SOA4(Cicchetti)                                                   Poor\n",
      "SOA5(Cramer)                                                      Moderate\n",
      "SOA6(Matthews)                                                    Weak\n",
      "Scott PI                                                          0.31832\n",
      "Standard Error                                                    0.02393\n",
      "TNR Macro                                                         0.77062\n",
      "TNR Micro                                                         0.78689\n",
      "TPR Macro                                                         0.5446\n",
      "TPR Micro                                                         0.57377\n",
      "Zero-one Loss                                                     182\n",
      "\n",
      "Class Statistics :\n",
      "\n",
      "Classes                                                           0             1             2             \n",
      "ACC(Accuracy)                                                     0.81265       0.62529       0.7096        \n",
      "AGF(Adjusted F-score)                                             0.60642       0.63005       0.69564       \n",
      "AGM(Adjusted geometric mean)                                      0.74148       0.63041       0.71637       \n",
      "AM(Difference between automatic and manual classification)        -18           12            6             \n",
      "AUC(Area under the ROC curve)                                     0.65629       0.62196       0.69459       \n",
      "AUCI(AUC value interpretation)                                    Fair          Fair          Fair          \n",
      "AUPR(Area under the PR curve)                                     0.45903       0.57953       0.62216       \n",
      "BCD(Bray-Curtis dissimilarity)                                    0.02108       0.01405       0.00703       \n",
      "BM(Informedness or bookmaker informedness)                        0.31258       0.24392       0.38918       \n",
      "CEN(Confusion entropy)                                            0.72985       0.67094       0.57641       \n",
      "DOR(Diagnostic odds ratio)                                        6.82159       2.7137        5.34602       \n",
      "DP(Discriminant power)                                            0.45975       0.23904       0.40138       \n",
      "DPI(Discriminant power interpretation)                            Poor          Poor          Poor          \n",
      "ERR(Error rate)                                                   0.18735       0.37471       0.2904        \n",
      "F0.5(F0.5 score)                                                  0.48817       0.56818       0.6152        \n",
      "F1(F1 score - harmonic mean of precision and sensitivity)         0.45205       0.57895       0.62195       \n",
      "F2(F2 score)                                                      0.42092       0.59013       0.62885       \n",
      "FDR(False discovery rate)                                         0.48438       0.43878       0.38922       \n",
      "FN(False negative/miss/type 2 error)                              49            74            59            \n",
      "FNR(Miss rate or false negative rate)                             0.59756       0.40217       0.36646       \n",
      "FOR(False omission rate)                                          0.13499       0.32035       0.22692       \n",
      "FP(False positive/type 1 error/false alarm)                       31            86            65            \n",
      "FPR(Fall-out or false positive rate)                              0.08986       0.35391       0.24436       \n",
      "G(G-measure geometric mean of precision and sensitivity)          0.45553       0.57924       0.62206       \n",
      "GI(Gini index)                                                    0.31258       0.24392       0.38918       \n",
      "GM(G-mean geometric mean of specificity and sensitivity)          0.60521       0.62149       0.6919        \n",
      "IBA(Index of balanced accuracy)                                   0.18032       0.36761       0.42028       \n",
      "ICSI(Individual classification success index)                     -0.08194      0.15905       0.24432       \n",
      "IS(Information score)                                             1.42493       0.38118       0.6959        \n",
      "J(Jaccard index)                                                  0.29204       0.40741       0.45133       \n",
      "LS(Lift score)                                                    2.68502       1.30241       1.61989       \n",
      "MCC(Matthews correlation coefficient)                             0.34494       0.24239       0.38651       \n",
      "MCCI(Matthews correlation coefficient interpretation)             Weak          Negligible    Weak          \n",
      "MCEN(Modified confusion entropy)                                  0.81214       0.7982        0.68914       \n",
      "MK(Markedness)                                                    0.38064       0.24088       0.38386       \n",
      "N(Condition negative)                                             345           243           266           \n",
      "NLR(Negative likelihood ratio)                                    0.65656       0.62247       0.48497       \n",
      "NLRI(Negative likelihood ratio interpretation)                    Negligible    Negligible    Poor          \n",
      "NPV(Negative predictive value)                                    0.86501       0.67965       0.77308       \n",
      "OC(Overlap coefficient)                                           0.51562       0.59783       0.63354       \n",
      "OOC(Otsuka-Ochiai coefficient)                                    0.45553       0.57924       0.62206       \n",
      "OP(Optimized precision)                                           0.42585       0.58649       0.62171       \n",
      "P(Condition positive or support)                                  82            184           161           \n",
      "PLR(Positive likelihood ratio)                                    4.47876       1.68921       2.59264       \n",
      "PLRI(Positive likelihood ratio interpretation)                    Poor          Poor          Poor          \n",
      "POP(Population)                                                   427           427           427           \n",
      "PPV(Precision or positive predictive value)                       0.51562       0.56122       0.61078       \n",
      "PRE(Prevalence)                                                   0.19204       0.43091       0.37705       \n",
      "Q(Yule Q - coefficient of colligation)                            0.7443        0.46145       0.68484       \n",
      "QI(Yule Q interpretation)                                         Moderate      Weak          Moderate      \n",
      "RACC(Random accuracy)                                             0.02878       0.1978        0.14746       \n",
      "RACCU(Random accuracy unbiased)                                   0.02923       0.19799       0.14751       \n",
      "TN(True negative/correct rejection)                               314           157           201           \n",
      "TNR(Specificity or true negative rate)                            0.91014       0.64609       0.75564       \n",
      "TON(Test outcome negative)                                        363           231           260           \n",
      "TOP(Test outcome positive)                                        64            196           167           \n",
      "TP(True positive/hit)                                             33            110           102           \n",
      "TPR(Sensitivity, recall, hit rate, or true positive rate)         0.40244       0.59783       0.63354       \n",
      "Y(Youden index)                                                   0.31258       0.24392       0.38918       \n",
      "dInd(Distance index)                                              0.60428       0.53572       0.44046       \n",
      "sInd(Similarity index)                                            0.57271       0.62119       0.68855       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_actu = Y_test['Profit_Class'].to_numpy()\n",
    "y_pred = rfc_y_pred\n",
    "cm = ConfusionMatrix(actual_vector=y_actu, predict_vector=y_pred)\n",
    "cm.classes\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'negative'), Text(0, 1.5, 'low'), Text(0, 2.5, 'good')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize = (8,7))\n",
    "final_matrix = confusion_matrix(Y_test, rfc_y_pred)\n",
    "ax = sns.heatmap(final_matrix/np.sum(final_matrix), annot=True, fmt='.1%', linewidths=.2, cmap='Greens')\n",
    "\n",
    "ax.set_title('Confusion matrix of the best untuned base model\\n', fontsize = 14)\n",
    "ax.set_xlabel('\\nPredicted profitability Class')\n",
    "ax.set_ylabel('Actual profitability Class')\n",
    "ax.xaxis.set_ticklabels(['negative','low', 'good'])\n",
    "ax.yaxis.set_ticklabels(['negative','low', 'good'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.5  <a class=\"anchor\" id=\"6_1_5\"></a> XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of XGBC: 51.7%\n",
      "F1 of XGBC: 51.7%\n",
      "Recall score of XGBC: 52.0%\n",
      "Accuracy score of XGBC: 52.0%\n"
     ]
    }
   ],
   "source": [
    "# Create a Gaussian classifier model\n",
    "xgbc = XGBClassifier(n_estimators=100, learning_rate=0.05, booster='gbtree', random_state = 1, eval_metric='mlogloss', use_label_encoder=False)\n",
    "\n",
    "# Train the model using train set\n",
    "xgbc.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "xgbc_y_pred=xgbc.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Precision score of XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(xgbc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(xgbc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall score of XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(xgbc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(xgbc_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.6  <a class=\"anchor\" id=\"6_1_6\"></a> Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of GNB: 52.5%\n",
      "F1 of GNB: 30.5%\n",
      "Recall score of GNB: 40.300000000000004%\n",
      "Accuracy score of GNB: 40.300000000000004%\n"
     ]
    }
   ],
   "source": [
    "# Create a Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model using train set\n",
    "gnb.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "gnb_y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Precision score of GNB: ' + str(round(metrics.precision_score(Y_test, np.round(gnb_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of GNB: ' + str(round(metrics.f1_score(Y_test, np.round(gnb_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall score of GNB: ' + str(round(metrics.recall_score(Y_test, np.round(gnb_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of GNB: ' + str(round(metrics.accuracy_score(Y_test, np.round(gnb_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.7  <a class=\"anchor\" id=\"6_1_7\"></a> Linear discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of LDA: 44.3%\n",
      "F1 of LDA: 44.4%\n",
      "Recall score of LDA: 45.4%\n",
      "Accuracy score of LDA: 45.4%\n"
     ]
    }
   ],
   "source": [
    "# Create a linear discriminant analysis model\n",
    "lda = LinearDiscriminantAnalysis(n_components = 2)\n",
    "\n",
    "# Train the model using train set\n",
    "lda.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "lda_y_pred = lda.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Precision score of LDA: ' + str(round(metrics.precision_score(Y_test, np.round(lda_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of LDA: ' + str(round(metrics.f1_score(Y_test, np.round(lda_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall score of LDA: ' + str(round(metrics.recall_score(Y_test, np.round(lda_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of LDA: ' + str(round(metrics.accuracy_score(Y_test, np.round(lda_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.8  <a class=\"anchor\" id=\"6_1_8\"></a> Quadratic discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of QDA: 48.199999999999996%\n",
      "F1 of QDA: 32.0%\n",
      "Recall score of QDA: 40.699999999999996%\n",
      "Accuracy score of QDA: 40.699999999999996%\n"
     ]
    }
   ],
   "source": [
    "# Create a quadratic discriminant analysis model\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "# Train the model using train set\n",
    "qda.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "qda_y_pred = qda.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Precision score of QDA: ' + str(round(metrics.precision_score(Y_test, np.round(qda_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of QDA: ' + str(round(metrics.f1_score(Y_test, np.round(qda_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall score of QDA: ' + str(round(metrics.recall_score(Y_test, np.round(qda_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of QDA: ' + str(round(metrics.accuracy_score(Y_test, np.round(qda_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.9  <a class=\"anchor\" id=\"6_1_9\"></a> Ridge regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of RDG: 46.5%\n",
      "F1 of RDG: 46.300000000000004%\n",
      "Recall score of RDG: 48.0%\n",
      "Accuracy score of RDG: 48.0%\n"
     ]
    }
   ],
   "source": [
    "# Create a ridge regression classifier model\n",
    "rdg = RidgeClassifier(alpha=1.0, random_state = 1, max_iter = 30000)\n",
    "\n",
    "# Train the model using train set\n",
    "rdg.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "rdg_y_pred=rdg.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Precision score of RDG: ' + str(round(metrics.precision_score(Y_test, np.round(rdg_y_pred), average='weighted', zero_division=0), 3)*100)+'%')\n",
    "print('F1 of RDG: ' + str(round(metrics.f1_score(Y_test, np.round(rdg_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall score of RDG: ' + str(round(metrics.recall_score(Y_test, np.round(rdg_y_pred), average='weighted', zero_division=0), 3)*100)+'%')\n",
    "print('Accuracy score of RDG: ' + str(round(metrics.accuracy_score(Y_test, np.round(rdg_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.10  <a class=\"anchor\" id=\"6_1_10\"></a> Support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of SVM: 45.9%\n",
      "F1 of SVM: 46.0%\n",
      "Recall score of SVM: 47.8%\n",
      "Accuracy score of SVM: 47.8%\n"
     ]
    }
   ],
   "source": [
    "# Create an SVM Classifier model\n",
    "svm = SVC(kernel='linear', random_state = 1, probability=True)\n",
    "\n",
    "# Train the model using the train set\n",
    "svm.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "svm_y_pred = svm.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Precision score of SVM: ' + str(round(metrics.precision_score(Y_test, np.round(svm_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of SVM: ' + str(round(metrics.f1_score(Y_test, np.round(svm_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall score of SVM: ' + str(round(metrics.recall_score(Y_test, np.round(svm_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of SVM: ' + str(round(metrics.accuracy_score(Y_test, np.round(svm_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: <a class=\"anchor\" id=\"part7\"></a> Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1  <a class=\"anchor\" id=\"7_1\"></a> XGBoost grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'base_score': 0.5,\n",
      " 'booster': 'gbtree',\n",
      " 'callbacks': None,\n",
      " 'colsample_bylevel': 1,\n",
      " 'colsample_bynode': 1,\n",
      " 'colsample_bytree': 1,\n",
      " 'early_stopping_rounds': None,\n",
      " 'enable_categorical': False,\n",
      " 'eval_metric': 'mlogloss',\n",
      " 'gamma': 0,\n",
      " 'gpu_id': -1,\n",
      " 'grow_policy': 'depthwise',\n",
      " 'importance_type': None,\n",
      " 'interaction_constraints': '',\n",
      " 'learning_rate': 0.05,\n",
      " 'max_bin': 256,\n",
      " 'max_cat_to_onehot': 4,\n",
      " 'max_delta_step': 0,\n",
      " 'max_depth': 6,\n",
      " 'max_leaves': 0,\n",
      " 'min_child_weight': 1,\n",
      " 'missing': nan,\n",
      " 'monotone_constraints': '()',\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': 0,\n",
      " 'num_parallel_tree': 1,\n",
      " 'objective': 'multi:softprob',\n",
      " 'predictor': 'auto',\n",
      " 'random_state': 1,\n",
      " 'reg_alpha': 0,\n",
      " 'reg_lambda': 1,\n",
      " 'sampling_method': 'uniform',\n",
      " 'scale_pos_weight': None,\n",
      " 'subsample': 1,\n",
      " 'tree_method': 'exact',\n",
      " 'use_label_encoder': False,\n",
      " 'validate_parameters': 1,\n",
      " 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "# Look at parameters used by our current XGBoost model\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(xgbc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
      " 'eval_metric': ['mlogloss'],\n",
      " 'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
      " 'learning_rate': [0.1],\n",
      " 'max_depth': [4, 5, 6],\n",
      " 'min_child_weight': [6, 8, 10, 12],\n",
      " 'n_estimators': [1000],\n",
      " 'nthread': [4],\n",
      " 'objective': ['binary:logistic'],\n",
      " 'seed': [1],\n",
      " 'subsample': [0.6, 0.7, 0.8, 0.9]}\n"
     ]
    }
   ],
   "source": [
    "# Defining parameter range\n",
    "xgbc_grid = {'learning_rate':[0.1],\n",
    "    'n_estimators':[1000],\n",
    "    'max_depth':[4,5,6],\n",
    "    'min_child_weight':[6,8,10,12],\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "    'objective':['binary:logistic'],\n",
    "    'nthread':[4],\n",
    "    'seed':[1],\n",
    "    'eval_metric':['mlogloss']}\n",
    "\n",
    "pprint(xgbc_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model for grid search\n",
    "xgbc_tuned = GridSearchCV(XGBClassifier(), xgbc_grid, refit = True)\n",
    "xgbc_tuned.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best parameter after tuning\n",
    "print(xgbc_tuned.best_params_)\n",
    " \n",
    "# Print how our model looks after hyper-parameter tuning\n",
    "print(xgbc_tuned.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a XGBoost_tuned model\n",
    "xgbc_tuned = XGBClassifier(colsample_bytree=0.6, eval_metric='mlogloss',\n",
    "gamma=0.2, learning_rate=0.1, max_depth=4, metric='muticlass',\n",
    "min_child_weight=12, n_estimators=1000, nthread=4, objective='binary:logistic',\n",
    "scale_pos_weight = 1, seed=1, subsample=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of base XGBC is 57.8%\n",
      "[15:39:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"metric\", \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "Accuracy of tuned XGBC is 57.599999999999994%\n",
      "Improvement of -0.3%\n"
     ]
    }
   ],
   "source": [
    "# Base model results\n",
    "xgbc_base_y_pred = xgbc.predict(X_test)\n",
    "xgbc_base_accuracy = round(metrics.accuracy_score(Y_test, np.round(xgbc_base_y_pred)), 3)*100\n",
    "print('Accuracy of base XGBC is ' + str(xgbc_base_accuracy)+'%')\n",
    "\n",
    "# Tuned model results\n",
    "#xgbc_tuned = xgbc_tuned.best_estimator_\n",
    "xgbc_tuned.fit(X_train, Y_train.values.ravel())\n",
    "xgbc_tuned_y_pred = xgbc_tuned.predict(X_test)\n",
    "xgbc_tuned_accuracy = round(metrics.accuracy_score(Y_test, np.round(xgbc_tuned_y_pred)), 3)*100\n",
    "print('Accuracy of tuned XGBC is ' + str(xgbc_tuned_accuracy)+'%')\n",
    "\n",
    "# Comparison\n",
    "print('Improvement of {:0.1f}%'.format(100 * (xgbc_tuned_accuracy - xgbc_base_accuracy) / xgbc_base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2  <a class=\"anchor\" id=\"7_2\"></a> Random forest classifier grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [100, 311, 522, 733, 944, 1155, 1366, 1577, 1788, 2000]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto','sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "                     'max_features': max_features,\n",
    "                     'max_depth': max_depth,\n",
    "                     'min_samples_split': min_samples_split,\n",
    "                      'min_samples_leaf': min_samples_leaf,\n",
    "                      'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MarfaPopova\\S2R Analytics\\Development & Support Team - Power BI for Synergy - Advanced Analytics\\DataFlowExtract\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=1),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 311, 522, 733,\n",
       "                                                         944, 1155, 1366, 1577,\n",
       "                                                         1788, 2000]},\n",
       "                   random_state=1, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=1),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 311, 522, 733,\n",
       "                                                         944, 1155, 1366, 1577,\n",
       "                                                         1788, 2000]},\n",
       "                   random_state=1, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=1),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 311, 522, 733,\n",
       "                                                         944, 1155, 1366, 1577,\n",
       "                                                         1788, 2000]},\n",
       "                   random_state=1, verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_tuned = RandomizedSearchCV(estimator = rfc,\n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 100,\n",
    "                               cv = 5,\n",
    "                               verbose = 2,\n",
    "                               random_state = 1,\n",
    "                               n_jobs = -1)\n",
    "                               \n",
    "# Fit the random search model\n",
    "rfc_tuned.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of base RFC is 57.699999999999996%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MarfaPopova\\S2R Analytics\\Development & Support Team - Power BI for Synergy - Advanced Analytics\\DataFlowExtract\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of tuned RFC is 59.0%\n",
      "Improvement of 2.3%\n"
     ]
    }
   ],
   "source": [
    "# Base model results\n",
    "rfc_base_y_pred = rfc.predict(X_test)\n",
    "rfc_base_accuracy = round(metrics.accuracy_score(Y_test, np.round(rfc_base_y_pred)), 3)*100\n",
    "print('Accuracy of base RFC is ' + str(rfc_base_accuracy)+'%')\n",
    "\n",
    "# Tuned model results\n",
    "rfc_tuned = rfc_tuned.best_estimator_\n",
    "rfc_tuned.fit(X_train, Y_train.values.ravel())\n",
    "rfc_tuned_y_pred = rfc_tuned.predict(X_test)\n",
    "rfc_tuned_accuracy = round(metrics.accuracy_score(Y_test, np.round(rfc_tuned_y_pred)), 3)*100\n",
    "print('Accuracy of tuned RFC is ' + str(rfc_tuned_accuracy)+'%')\n",
    "\n",
    "# Comparison\n",
    "print('Improvement of {:0.1f}%'.format(100 * (rfc_tuned_accuracy - rfc_base_accuracy) / rfc_base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of tuned RFC: 54.300000000000004%\n",
      "F1 of tuned RFC: 51.5%\n",
      "Recall score of tuned RFC: 59.0%\n",
      "Accuracy score of tuned RFC: 59.0%\n"
     ]
    }
   ],
   "source": [
    "print('Precision score of tuned RFC: ' + str(round(metrics.precision_score(Y_test, np.round(rfc_tuned_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of tuned RFC: ' + str(round(metrics.f1_score(Y_test, np.round(rfc_tuned_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall score of tuned RFC: ' + str(round(metrics.recall_score(Y_test, np.round(rfc_tuned_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of tuned RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(rfc_tuned_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3  <a class=\"anchor\" id=\"7_3\"></a> SVM RBF grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'C': 1.0,\n",
      " 'break_ties': False,\n",
      " 'cache_size': 200,\n",
      " 'class_weight': None,\n",
      " 'coef0': 0.0,\n",
      " 'decision_function_shape': 'ovr',\n",
      " 'degree': 3,\n",
      " 'gamma': 'scale',\n",
      " 'kernel': 'linear',\n",
      " 'max_iter': -1,\n",
      " 'probability': True,\n",
      " 'random_state': 1,\n",
      " 'shrinking': True,\n",
      " 'tol': 0.001,\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "# Look at parameters used by our current SVM model\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(svm.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [1, 0.1, 0.01],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [1, 0.1, 0.01],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01],\n",
       "                         'kernel': ['linear']})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining parameter range\n",
    "svm_grid = {'C': [0.1, 1, 10],\n",
    "            'gamma': [1, 0.1, 0.01],\n",
    "            'kernel': ['linear']}\n",
    " \n",
    "# Fitting the model for grid search\n",
    "svm_tuned = GridSearchCV(SVC(), svm_grid, refit = True) \n",
    "svm_tuned.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'gamma': 1, 'kernel': 'linear'}\n",
      "SVC(C=0.1, gamma=1, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "# Print best parameter after tuning\n",
    "print(svm_tuned.best_params_)\n",
    " \n",
    "# Print how our model looks after hyper-parameter tuning\n",
    "print(svm_tuned.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1, gamma=1, kernel=&#x27;linear&#x27;, probability=True, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1, gamma=1, kernel=&#x27;linear&#x27;, probability=True, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.1, gamma=1, kernel='linear', probability=True, random_state=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tuned SVC model with linear kernel\n",
    "svm_tuned = SVC(kernel='linear', C = 0.1, gamma = 1, random_state = 1, probability=True)\n",
    "svm_tuned.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of base SVM is 45.9%\n",
      "Precision of tuned SVM with RBF kernel is 45.9%\n",
      "Improvement of 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Base model results\n",
    "svm_base_y_pred = svm.predict(X_test)\n",
    "svm_base_precision = round(metrics.precision_score(Y_test, np.round(svm_base_y_pred), average='weighted', zero_division=1), 3)*100\n",
    "print('Precision of base SVM is ' + str(svm_base_precision)+'%')\n",
    "\n",
    "# Tuned model results with kernel\n",
    "svm_tuned_y_pred = svm_tuned.predict(X_test)\n",
    "svm_tuned_precision = round(metrics.precision_score(Y_test, np.round(svm_tuned_y_pred), average='weighted', zero_division=1), 3)*100\n",
    "print('Precision of tuned SVM with RBF kernel is ' + str(svm_tuned_precision)+'%')\n",
    "\n",
    "print('Improvement of {:0.2f}%'.format(100 * (svm_tuned_precision - svm_base_precision) / svm_base_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 of tuned SVM with RBF kernel: 46.0%\n",
      "Recall of tuned SVM with RBF kernel: 47.8%\n",
      "Accuracy of tuned SVM with RBF kernel: 47.8%\n"
     ]
    }
   ],
   "source": [
    "# Rest of the measures\n",
    "print('F1 of tuned SVM with RBF kernel: ' + str(round(metrics.f1_score(Y_test, np.round(svm_tuned_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall of tuned SVM with RBF kernel: ' + str(round(metrics.recall_score(Y_test, np.round(svm_tuned_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy of tuned SVM with RBF kernel: ' + str(round(metrics.accuracy_score(Y_test, np.round(svm_tuned_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1, gamma=1, probability=True, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1, gamma=1, probability=True, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.1, gamma=1, probability=True, random_state=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tuned SVC model with RBF kernel\n",
    "svm_tuned = SVC(kernel='rbf', C = 0.1, gamma = 1, random_state = 1, probability=True)\n",
    "svm_tuned.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of base SVM is 45.9%\n",
      "Precision of tuned SVM with RBF kernel is 56.599999999999994%\n",
      "Improvement of 23.31%\n"
     ]
    }
   ],
   "source": [
    "# Base model results\n",
    "svm_base_y_pred = svm.predict(X_test)\n",
    "svm_base_precision = round(metrics.precision_score(Y_test, np.round(svm_base_y_pred), average='weighted', zero_division=1), 3)*100\n",
    "print('Precision of base SVM is ' + str(svm_base_precision)+'%')\n",
    "\n",
    "# Tuned model results with kernel\n",
    "svm_tuned_y_pred = svm_tuned.predict(X_test)\n",
    "svm_tuned_precision = round(metrics.precision_score(Y_test, np.round(svm_tuned_y_pred), average='weighted', zero_division=1), 3)*100\n",
    "print('Precision of tuned SVM with RBF kernel is ' + str(svm_tuned_precision)+'%')\n",
    "\n",
    "print('Improvement of {:0.2f}%'.format(100 * (svm_tuned_precision - svm_base_precision) / svm_base_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 of tuned SVM with RBF kernel: 26.400000000000002%\n",
      "Recall of tuned SVM with RBF kernel: 43.1%\n",
      "Accuracy of tuned SVM with RBF kernel: 43.1%\n"
     ]
    }
   ],
   "source": [
    "# Rest of the measures\n",
    "print('F1 of tuned SVM with RBF kernel: ' + str(round(metrics.f1_score(Y_test, np.round(svm_tuned_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall of tuned SVM with RBF kernel: ' + str(round(metrics.recall_score(Y_test, np.round(svm_tuned_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy of tuned SVM with RBF kernel: ' + str(round(metrics.accuracy_score(Y_test, np.round(svm_tuned_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: <a class=\"anchor\" id=\"part8\"></a> Ensemble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1  <a class=\"anchor\" id=\"8_1\"></a> Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_voting = VotingClassifier(estimators=[('svm_t', svm_tuned), ('rfc', rfc)],voting='soft')\n",
    "soft_voting.fit(X_train, Y_train.values.ravel())\n",
    "sv_y_pred = soft_voting.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of soft voting classifier: 56.39999999999999%\n",
      "F1 of soft voting classifier: 55.1%\n",
      "Recall score of soft voting classifier 56.00000000000001%\n",
      "Accuracy score of soft voting classifier: 56.00000000000001%\n"
     ]
    }
   ],
   "source": [
    "print('Precision score of soft voting classifier: ' + str(round(metrics.precision_score(Y_test, np.round(sv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of soft voting classifier: ' + str(round(metrics.f1_score(Y_test, np.round(sv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall score of soft voting classifier ' + str(round(metrics.recall_score(Y_test, np.round(sv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of soft voting classifier: ' + str(round(metrics.accuracy_score(Y_test, np.round(sv_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_voting = VotingClassifier(estimators=[('svm_t', svm_tuned), ('rfc', rfc)],voting='hard')\n",
    "hard_voting.fit(X_train, Y_train.values.ravel())\n",
    "hv_y_pred = hard_voting.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of hard voting classifier: 66.5%\n",
      "F1 of hard voting classifier: 34.2%\n",
      "Recall score of hard voting classifier 45.2%\n",
      "Accuracy score of hard voting classifier: 45.2%\n"
     ]
    }
   ],
   "source": [
    "print('Precision score of hard voting classifier: ' + str(round(metrics.precision_score(Y_test, np.round(hv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of hard voting classifier: ' + str(round(metrics.f1_score(Y_test, np.round(hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall score of hard voting classifier ' + str(round(metrics.recall_score(Y_test, np.round(hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of hard voting classifier: ' + str(round(metrics.accuracy_score(Y_test, np.round(hv_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2  <a class=\"anchor\" id=\"8_2\"></a> Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.1  <a class=\"anchor\" id=\"8_2_1\"></a> Top 9 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel9 = list()\n",
    "\tlevel9.append(('gnb', gnb))\n",
    "\tlevel9.append(('qda', qda))\n",
    "\tlevel9.append(('log', log))\n",
    "\tlevel9.append(('knn', knn_7))\n",
    "\tlevel9.append(('dtc', dtc))\n",
    "\tlevel9.append(('xgbc tuned', xgbc_tuned))\n",
    "\tlevel9.append(('soft voting', soft_voting))\n",
    "\tlevel9.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel9.append(('lda', lda))\n",
    "\t\n",
    "\t# Define the stacking ensemble learnt on tuned RFC\n",
    "\tmodel = StackingClassifier(estimators=level9, final_estimator=rfc_tuned, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models separately\n",
    "level9 = list()\n",
    "level9.append(('gnb', gnb))\n",
    "level9.append(('qda', qda))\n",
    "level9.append(('log', log))\n",
    "level9.append(('knn', knn_7))\n",
    "level9.append(('dtc', dtc))\n",
    "level9.append(('xgbc tuned', xgbc_tuned))\n",
    "level9.append(('soft voting', soft_voting))\n",
    "level9.append(('rfc tuned', rfc_tuned))\n",
    "level9.append(('lda', lda))\n",
    "level9.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on tuned RFC\n",
    "stack9_rfc_t = StackingClassifier(estimators=level9, final_estimator=rfc_tuned, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack9_rfc_t = stack9_rfc_t.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack9_rfc_t_y_pred = stack9_rfc_t.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 9 models learnt on tuned RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack9_rfc_t_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 9 models learnt on tuned RFC: ' + str(round(metrics.recall_score(Y_test, np.round(stack9_rfc_t_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 9 models learnt on tuned RFC: ' + str(round(metrics.precision_score(Y_test, np.round(stack9_rfc_t_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 9 models learnt on tuned RFC: ' + str(round(metrics.f1_score(Y_test, np.round(stack9_rfc_t_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel9 = list()\n",
    "\tlevel9.append(('gnb', gnb))\n",
    "\tlevel9.append(('qda', qda))\n",
    "\tlevel9.append(('log', log))\n",
    "\tlevel9.append(('knn', knn_7))\n",
    "\tlevel9.append(('dtc', dtc))\n",
    "\tlevel9.append(('xgbc tuned', xgbc_tuned))\n",
    "\tlevel9.append(('soft voting', soft_voting))\n",
    "\tlevel9.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel9.append(('lda', lda))\n",
    "\t\n",
    "\t# Define the stacking ensemble learnt on base XGBC\n",
    "\tmodel = StackingClassifier(estimators=level9, final_estimator=xgbc, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models separately\n",
    "level9 = list()\n",
    "level9.append(('gnb', gnb))\n",
    "level9.append(('qda', qda))\n",
    "level9.append(('log', log))\n",
    "level9.append(('knn', knn_7))\n",
    "level9.append(('dtc', dtc))\n",
    "level9.append(('xgbc tuned', xgbc_tuned))\n",
    "level9.append(('soft voting', soft_voting))\n",
    "level9.append(('rfc tuned', rfc_tuned))\n",
    "level9.append(('lda', lda))\n",
    "level9.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on base XGBC\n",
    "xgbc_stack9 = StackingClassifier(estimators=level9, final_estimator=xgbc, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "xgbc_stack9 = xgbc_stack9.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "xgbc_stack9_y_pred = xgbc_stack9.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 9 models learnt on base XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(xgbc_stack9_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 9 models learnt on base XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(xgbc_stack9_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 9 models learnt on base XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(xgbc_stack9_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 9 models learnt on base XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(xgbc_stack9_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.2  <a class=\"anchor\" id=\"8_2_2\"></a> Top 8 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models\n",
    "level0 = list()\n",
    "level0.append(('log', log))\n",
    "level0.append(('knn', knn_7))\n",
    "level0.append(('dtc', dtc))\n",
    "level0.append(('xgbc tuned', xgbc_tuned))\n",
    "level0.append(('soft voting', soft_voting))\n",
    "level0.append(('rfc tuned', rfc_tuned))\n",
    "level0.append(('lda', lda))\n",
    "level0.append(('stacking', get_stacking()))\n",
    "\n",
    "# Define meta learner model\n",
    "level1 = xgbc\n",
    "\n",
    "# Define the final stacking ensemble\n",
    "final1 = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "final1 = final1.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "final1_y_pred = final1.predict(X_test)\n",
    "\n",
    "# Make a prediction for one example\n",
    "random_project = X.sample(n=1)\n",
    "yhat1 = final1.predict(random_project)\n",
    "print('Predicted Recoverability Class: %d' % (yhat1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel8 = list()\n",
    "\tlevel8.append(('qda', qda))\n",
    "\tlevel8.append(('lda', lda))\n",
    "\tlevel8.append(('log', log))\n",
    "\tlevel8.append(('knn', knn_7))\n",
    "\tlevel8.append(('dtc', dtc))\n",
    "\tlevel8.append(('soft voting', soft_voting))\n",
    "\tlevel8.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel8.append(('xgbc tuned', xgbc_tuned))\n",
    "\n",
    "\t# Define the stacking ensemble\n",
    "\tmodel = StackingClassifier(estimators=level8, final_estimator=xgbc_tuned, cv=5)\n",
    "\treturn model\n",
    "\n",
    "# Define the base models separately\n",
    "level8 = list()\n",
    "level8.append(('qda', qda))\n",
    "level8.append(('lda', lda))\n",
    "level8.append(('log', log))\n",
    "level8.append(('knn', knn_7))\n",
    "level8.append(('dtc', dtc))\n",
    "level8.append(('soft voting', soft_voting))\n",
    "level8.append(('rfc tuned', rfc_tuned))\n",
    "level8.append(('xgbc tuned', xgbc_tuned))\n",
    "level8.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the final stacking ensemble\n",
    "xgbc_stack8 = StackingClassifier(estimators=level8, final_estimator=xgbc, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "xgbc_stack8 = xgbc_stack8.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "xgbc_stack8_y_pred = xgbc_stack8.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 8 models learnt on base XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(xgbc_stack8_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 8 models learnt on base XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(xgbc_stack8_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 8 models learnt on base XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(xgbc_stack8_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 8 models learnt on base XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(xgbc_stack8_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.3  <a class=\"anchor\" id=\"8_2_3\"></a> Top 7 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models separately\n",
    "level7 = list()\n",
    "level7.append(('lda', lda))\n",
    "level7.append(('log', log))\n",
    "level7.append(('knn', knn_7))\n",
    "level7.append(('dtc', dtc))\n",
    "level7.append(('soft voting', soft_voting))\n",
    "level7.append(('rfc tuned', rfc_tuned))\n",
    "level7.append(('xgbc tuned', xgbc_tuned))\n",
    "level7.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel7 = list()\n",
    "\tlevel7.append(('lda', lda))\n",
    "\tlevel7.append(('log', log))\n",
    "\tlevel7.append(('knn', knn_7))\n",
    "\tlevel7.append(('dtc', dtc))\n",
    "\tlevel7.append(('soft voting', soft_voting))\n",
    "\tlevel7.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel7.append(('xgbc tuned', xgbc_tuned))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on tuned random forest classifier\n",
    "\tmodel = StackingClassifier(estimators=level7, final_estimator=soft_voting, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on tuned random forest classifier\n",
    "sv_stack7 = StackingClassifier(estimators=level7, final_estimator=soft_voting, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "sv_stack7 = sv_stack7.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "sv_stack7_y_pred = sv_stack7.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 7 models learnt on soft voting classifier: ' + str(round(metrics.accuracy_score(Y_test, np.round(sv_stack7_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 7 models learnt on soft voting classifier: ' + str(round(metrics.recall_score(Y_test, np.round(sv_stack7_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 7 models learnt on soft voting classifier: ' + str(round(metrics.precision_score(Y_test, np.round(sv_stack7_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 7 models learnt on soft voting classifier: ' + str(round(metrics.f1_score(Y_test, np.round(sv_stack7_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.4  <a class=\"anchor\" id=\"8_2_4\"></a> Top 6 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models separately\n",
    "level6 = list()\n",
    "level6.append(('log', log))\n",
    "level6.append(('knn', knn_7))\n",
    "level6.append(('dtc', dtc))\n",
    "level6.append(('soft voting', soft_voting))\n",
    "level6.append(('rfc tuned', rfc_tuned))\n",
    "level6.append(('xgbc tuned', xgbc_tuned))\n",
    "level6.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a stacking ensemble of models based on base XGBC\n",
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel6 = list()\n",
    "\tlevel6.append(('log', log))\n",
    "\tlevel6.append(('knn', knn_7))\n",
    "\tlevel6.append(('dtc', dtc))\n",
    "\tlevel6.append(('soft voting', soft_voting))\n",
    "\tlevel6.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel6.append(('xgbc tuned', xgbc_tuned))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on tuned random forest classifier\n",
    "\tmodel = StackingClassifier(estimators=level6, final_estimator=rfc_tuned, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on tuned random forest classifier\n",
    "rfc_t_stack6 = StackingClassifier(estimators=level6, final_estimator=rfc_tuned, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "rfc_t_stack6 = rfc_t_stack6.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "rfc_t_stack6_y_pred = rfc_t_stack6.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 6 models learnt on tuned RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(rfc_t_stack6_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 6 models learnt on tuned RFC: ' + str(round(metrics.recall_score(Y_test, np.round(rfc_t_stack6_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 6 models learnt on tuned RFC: ' + str(round(metrics.precision_score(Y_test, np.round(rfc_t_stack6_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 6 models learnt on tuned RFC: ' + str(round(metrics.f1_score(Y_test, np.round(rfc_t_stack6_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a stacking ensemble of models based on base XGBC\n",
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel6 = list()\n",
    "\tlevel6.append(('log', log))\n",
    "\tlevel6.append(('knn', knn_7))\n",
    "\tlevel6.append(('dtc', dtc))\n",
    "\tlevel6.append(('soft voting', soft_voting))\n",
    "\tlevel6.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel6.append(('xgbc tuned', xgbc_tuned))\n",
    "\n",
    "\t# Define the stacking ensemble\n",
    "\tmodel = StackingClassifier(estimators=level6, final_estimator=xgbc, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble based on tuned XGBC\n",
    "xgbc_stack6 = StackingClassifier(estimators=level6, final_estimator=xgbc, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "xgbc_stack6 = xgbc_stack6.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "xgbc_stack6_y_pred = xgbc_stack6.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 6 models learnt on base XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(xgbc_stack6_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 6 models learnt on base XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(xgbc_stack6_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 6 models learnt on base XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(xgbc_stack6_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 6 models learnt on base XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(xgbc_stack6_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a stacking ensemble of models based on tuned XGBC\n",
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel6 = list()\n",
    "\tlevel6.append(('log', log))\n",
    "\tlevel6.append(('knn', knn_7))\n",
    "\tlevel6.append(('dtc', dtc))\n",
    "\tlevel6.append(('soft voting', soft_voting))\n",
    "\tlevel6.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel6.append(('xgbc tuned', xgbc_tuned))\n",
    "\n",
    "\t# Define the stacking ensemble\n",
    "\tmodel = StackingClassifier(estimators=level6, final_estimator=soft_voting, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on soft voting classifier\n",
    "stack6_sv = StackingClassifier(estimators=level6, final_estimator=soft_voting, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack6_sv = stack6_sv.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack6_sv_y_pred = stack6_sv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 6 models learnt on soft voting classifier: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack6_sv_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 6 models learnt on soft voting classifier: ' + str(round(metrics.recall_score(Y_test, np.round(stack6_sv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 6 models learnt on soft voting classifier: ' + str(round(metrics.precision_score(Y_test, np.round(stack6_sv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 6 models learnt on soft voting classifier: ' + str(round(metrics.f1_score(Y_test, np.round(stack6_sv_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.5  <a class=\"anchor\" id=\"8_2_5\"></a> Top 5 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models separately\n",
    "level5 = list()\n",
    "level5.append(('knn', knn_7))\n",
    "level5.append(('dtc', dtc))\n",
    "level5.append(('soft voting', soft_voting))\n",
    "level5.append(('rfc tuned', rfc_tuned))\n",
    "level5.append(('xgbc tuned', xgbc_tuned))\n",
    "level5.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel5 = list()\n",
    "\tlevel5.append(('knn', knn_7))\n",
    "\tlevel5.append(('dtc', dtc))\n",
    "\tlevel5.append(('soft voting', soft_voting))\n",
    "\tlevel5.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel5.append(('xgbc tuned', xgbc_tuned))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on soft voting classifier\n",
    "\tmodel = StackingClassifier(estimators=level5, final_estimator=soft_voting, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on soft voting classifier\n",
    "stack5_sv = StackingClassifier(estimators=level5, final_estimator=soft_voting, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack5_sv = stack5_sv.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack5_sv_y_pred = stack5_sv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 5 models learnt on soft voting classifier: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack5_sv_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 5 models learnt on soft voting classifier: ' + str(round(metrics.recall_score(Y_test, np.round(stack5_sv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 5 models learnt on soft voting classifier: ' + str(round(metrics.precision_score(Y_test, np.round(stack5_sv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 5 models learnt on soft voting classifier: ' + str(round(metrics.f1_score(Y_test, np.round(stack5_sv_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble based on base XGBC\n",
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel5 = list()\n",
    "\tlevel5.append(('knn', knn_7))\n",
    "\tlevel5.append(('dtc', dtc))\n",
    "\tlevel5.append(('soft voting', soft_voting))\n",
    "\tlevel5.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel5.append(('xgbc tuned', xgbc_tuned))\n",
    "\n",
    "\t# Define the stacking ensemble\n",
    "\tmodel = StackingClassifier(estimators=level5, final_estimator=xgbc, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble based on base XGBC\n",
    "xgbc_stack5 = StackingClassifier(estimators=level5, final_estimator=xgbc, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "xgbc_stack5 = xgbc_stack5.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "xgbc_stack5_y_pred = xgbc_stack5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 5 models learnt on base XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(xgbc_stack5_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 5 models learnt on base XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(xgbc_stack5_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 5 models learnt on base XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(xgbc_stack5_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 5 models learnt on base XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(xgbc_stack5_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.6  <a class=\"anchor\" id=\"8_2_6\"></a> Top 4 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel4 = list()\n",
    "\tlevel4.append(('dtc', dtc))\n",
    "\tlevel4.append(('soft voting', soft_voting))\n",
    "\tlevel4.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel4.append(('xgbc tuned', xgbc_tuned))\n",
    "\n",
    "\t# Define the final stacking ensemble learnt on base Gaussian classifier\n",
    "\tmodel = StackingClassifier(estimators=level4, final_estimator=xgbc, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models separately\n",
    "level4 = list()\n",
    "level4.append(('dtc', dtc))\n",
    "level4.append(('soft voting', soft_voting))\n",
    "level4.append(('rfc tuned', rfc_tuned))\n",
    "level4.append(('xgbc tuned', xgbc_tuned))\n",
    "level4.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the final stacking ensemble learnt on base Gaussian classifier\n",
    "stack4_xgbc = StackingClassifier(estimators=level4, final_estimator=xgbc, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack4_xgbc = stack4_xgbc.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack4_xgbc_y_pred = stack4_xgbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 4 models learnt on base XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack4_xgbc_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 4 models learnt on base XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(stack4_xgbc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 4 models learnt on base XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(stack4_xgbc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 4 models learnt on base XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(stack4_xgbc_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32faf87829e52f10b3379fa51fb017496aba8a2082e84bf41be67a5b199752f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
