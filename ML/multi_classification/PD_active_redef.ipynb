{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">S2R Analytics</h1>\n",
    "<h2 align=\"center\">Profitability of Client X projects: run 1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "* [Part 6](#part6): Classification\n",
    "    * [6.0](#6_0): Data splitting\n",
    "    * [6.1](#6_1): Models\n",
    "<br />\n",
    "<br />\n",
    "* [Part 7](#part7): Fine-tuning\n",
    "* [Part 8](#part8): Ensemble learning\n",
    "* [Part 9](#part9): Evaluation of the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentials\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from pandas.api.types import CategoricalDtype\n",
    "pd.options.display.max_columns = None\n",
    "import sqlite3\n",
    "import pyodbc\n",
    "import numpy as np; np.random.seed(1)\n",
    "\n",
    "# Image creation and display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import pyplot\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Metrics of accuracy\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from pycm import *\n",
    "import imbalanced_ensemble as imbens\n",
    "from imbalanced_ensemble.ensemble.base import sort_dict_by_key\n",
    "from collections import Counter\n",
    "\n",
    "# Fine-tuning and enseble learning\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Other\n",
    "import itertools as it\n",
    "import io\n",
    "import os\n",
    "os.sys.path\n",
    "import sys\n",
    "import glob\n",
    "import concurrent.futures\n",
    "from __future__ import print_function\n",
    "import binascii\n",
    "import struct\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import scipy.cluster\n",
    "import datetime, time\n",
    "import functools, operator\n",
    "from datetime import datetime\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../ETL/csv-files/active_redef.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: <a class=\"anchor\" id=\"part6\"></a> Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0 <a class=\"anchor\" id=\"6_0\"></a> Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose dependent variables\n",
    "Y = df[['Redefined Class']]\n",
    "\n",
    "# Drop the dependent variables from the feature data set\n",
    "X = df.drop(columns = ['Redefined Class'])\n",
    "\n",
    "# Scale the explanatory variables\n",
    "X1 = pd.DataFrame(StandardScaler().fit_transform(X))\n",
    "X1.columns = X.columns\n",
    "X = X1\n",
    "\n",
    "# Split data set into train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state=1, stratify = Y)\n",
    "\n",
    "print(f'No. of training data: {X_train.shape[0]}')\n",
    "print(f'No. of training targets: {Y_train.shape[0]}')\n",
    "print(f'No. of testing data: {X_test.shape[0]}')\n",
    "print(f'No. of testing targets: {Y_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 <a class=\"anchor\" id=\"6_1\"></a> Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1  <a class=\"anchor\" id=\"6_1_1\"></a> Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression(random_state = 1, max_iter = 30000)\n",
    "log.fit(X_train, Y_train.values.ravel())\n",
    "log_y_pred=log.predict(X_test)\n",
    "\n",
    "print('Precision score of LOG: ' + str(round(metrics.precision_score(Y_test, np.round(log_y_pred), average='weighted', zero_division=0), 3)*100)+'%')\n",
    "print('F1 of LOG: ' + str(round(metrics.f1_score(Y_test, np.round(log_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall score of LOG: ' + str(round(metrics.recall_score(Y_test, np.round(log_y_pred), average='weighted', zero_division=0), 3)*100)+'%')\n",
    "print('Accuracy score of LOG: ' + str(round(metrics.accuracy_score(Y_test, np.round(log_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.2 <a class=\"anchor\" id=\"6_1_2\"></a> K-Neighbours classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "knn_7 = KNeighborsClassifier(n_neighbors=7)\n",
    "knn_7.fit(X_train, Y_train.values.ravel())\n",
    "knn_7_y_pred = knn_7.predict(X_test)\n",
    "\n",
    "print('Precision score of KNN-7: ' + str(round(metrics.precision_score(Y_test, np.round(knn_7_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of KNN-7: ' + str(round(metrics.f1_score(Y_test, np.round(knn_7_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of KNN-7: ' + str(round(metrics.accuracy_score(Y_test, np.round(knn_7_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3  <a class=\"anchor\" id=\"6_1_3\"></a> Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state = 1)\n",
    "dtc = dtc.fit(X_train, Y_train.values.ravel())\n",
    "dtc_y_pred = dtc.predict(X_test)\n",
    "\n",
    "print('Precision score of DTC: ' + str(round(metrics.precision_score(Y_test, np.round(dtc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of DTC: ' + str(round(metrics.f1_score(Y_test, np.round(dtc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of DTC: ' + str(round(metrics.accuracy_score(Y_test, np.round(dtc_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.4  <a class=\"anchor\" id=\"6_1_4\"></a> Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state = 1)\n",
    "rfc.fit(X_train, Y_train.values.ravel())\n",
    "rfc_y_pred=rfc.predict(X_test)\n",
    "\n",
    "print('Precision score of RFC: ' + str(round(metrics.precision_score(Y_test, np.round(rfc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of RFC: ' + str(round(metrics.f1_score(Y_test, np.round(rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(rfc_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.5  <a class=\"anchor\" id=\"6_1_5\"></a> XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(n_estimators=100, learning_rate=0.05, booster='gbtree', random_state = 1, eval_metric='mlogloss', use_label_encoder=False)\n",
    "xgbc.fit(X_train, Y_train.values.ravel())\n",
    "xgbc_y_pred=xgbc.predict(X_test)\n",
    "\n",
    "print('Precision score of XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(xgbc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(xgbc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(xgbc_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.6  <a class=\"anchor\" id=\"6_1_6\"></a> Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, Y_train.values.ravel())\n",
    "gnb_y_pred = gnb.predict(X_test)\n",
    "\n",
    "print('Precision score of GNB: ' + str(round(metrics.precision_score(Y_test, np.round(gnb_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of GNB: ' + str(round(metrics.f1_score(Y_test, np.round(gnb_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of GNB: ' + str(round(metrics.accuracy_score(Y_test, np.round(gnb_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.7  <a class=\"anchor\" id=\"6_1_7\"></a> Linear discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components = 2)\n",
    "lda.fit(X_train, Y_train.values.ravel())\n",
    "lda_y_pred = lda.predict(X_test)\n",
    "\n",
    "print('Precision score of LDA: ' + str(round(metrics.precision_score(Y_test, np.round(lda_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of LDA: ' + str(round(metrics.f1_score(Y_test, np.round(lda_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of LDA: ' + str(round(metrics.accuracy_score(Y_test, np.round(lda_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.8  <a class=\"anchor\" id=\"6_1_8\"></a> Quadratic discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, Y_train.values.ravel())\n",
    "qda_y_pred = qda.predict(X_test)\n",
    "\n",
    "print('Precision score of QDA: ' + str(round(metrics.precision_score(Y_test, np.round(qda_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of QDA: ' + str(round(metrics.f1_score(Y_test, np.round(qda_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of QDA: ' + str(round(metrics.accuracy_score(Y_test, np.round(qda_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.9  <a class=\"anchor\" id=\"6_1_9\"></a> Ridge regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg = RidgeClassifier(alpha=1.0, random_state = 1, max_iter = 30000)\n",
    "rdg.fit(X_train, Y_train.values.ravel())\n",
    "rdg_y_pred=rdg.predict(X_test)\n",
    "\n",
    "print('Precision score of RDG: ' + str(round(metrics.precision_score(Y_test, np.round(rdg_y_pred), average='weighted', zero_division=0), 3)*100)+'%')\n",
    "print('F1 of RDG: ' + str(round(metrics.f1_score(Y_test, np.round(rdg_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of RDG: ' + str(round(metrics.accuracy_score(Y_test, np.round(rdg_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.10  <a class=\"anchor\" id=\"6_1_10\"></a> Support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear', random_state = 1, probability=True)\n",
    "svm.fit(X_train, Y_train.values.ravel())\n",
    "svm_y_pred = svm.predict(X_test)\n",
    "\n",
    "print('Precision score of SVM: ' + str(round(metrics.precision_score(Y_test, np.round(svm_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of SVM: ' + str(round(metrics.f1_score(Y_test, np.round(svm_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of SVM: ' + str(round(metrics.accuracy_score(Y_test, np.round(svm_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: <a class=\"anchor\" id=\"part7\"></a> Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1  <a class=\"anchor\" id=\"7_1\"></a> XGBoost grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at parameters used by our current XGBoost model\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(xgbc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameter range\n",
    "xgbc_grid = {'learning_rate':[0.1, 1],\n",
    "    'n_estimators':[1000, 1500],\n",
    "    'max_depth':[4,5,6],\n",
    "    'min_child_weight':[6,8,10,12],\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "    'objective':['binary:logistic'],\n",
    "    'nthread':[4],\n",
    "    'seed':[1],\n",
    "    'eval_metric':['mlogloss']}\n",
    "\n",
    "pprint(xgbc_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model for grid search\n",
    "xgbc_tuned = GridSearchCV(XGBClassifier(), xgbc_grid, refit = True)\n",
    "xgbc_tuned.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best parameter after tuning\n",
    "print(xgbc_tuned.best_params_)\n",
    " \n",
    "# Print how our model looks after hyper-parameter tuning\n",
    "print(xgbc_tuned.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a XGBoost_tuned model\n",
    "xgbc_tuned = XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
    "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
    "              early_stopping_rounds=None, enable_categorical=False,\n",
    "              eval_metric='mlogloss', gamma=0.4, gpu_id=-1,\n",
    "              grow_policy='depthwise', importance_type=None,\n",
    "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
    "              max_cat_to_onehot=4, max_delta_step=0, max_depth=6, max_leaves=0,\n",
    "              min_child_weight=10, monotone_constraints='()',\n",
    "              n_estimators=1000, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
    "              objective='multi:softprob', predictor='auto', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model results\n",
    "xgbc_base_y_pred = xgbc.predict(X_test)\n",
    "xgbc_base_precision = round(metrics.precision_score(Y_test, np.round(xgbc_base_y_pred), average='weighted', zero_division=1), 3)*100\n",
    "print('Precision of base XGBC is ' + str(xgbc_base_precision)+'%')\n",
    "\n",
    "# Tuned model results\n",
    "xgbc_tuned.fit(X_train, Y_train.values.ravel())\n",
    "xgbc_tuned_y_pred = xgbc_tuned.predict(X_test)\n",
    "xgbc_tuned_precision = round(metrics.precision_score(Y_test, np.round(xgbc_tuned_y_pred), average='weighted', zero_division=1), 3)*100\n",
    "print('Precision of tuned XGBC is ' + str(xgbc_tuned_precision)+'%')\n",
    "\n",
    "# Comparison\n",
    "print('Improvement of {:0.2f}%'.format(100 * (xgbc_tuned_precision - xgbc_base_precision) / xgbc_base_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rest of the measures\n",
    "print('F1 of tuned XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(xgbc_tuned_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall of tuned XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(xgbc_tuned_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy of tuned XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(xgbc_tuned_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2  <a class=\"anchor\" id=\"7_2\"></a> Random forest classifier grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "                     'max_features': max_features,\n",
    "                     'max_depth': max_depth,\n",
    "                     'min_samples_split': min_samples_split,\n",
    "                      'min_samples_leaf': min_samples_leaf,\n",
    "                      'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=1),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 311, 522, 733,\n",
       "                                                         944, 1155, 1366, 1577,\n",
       "                                                         1788, 2000]},\n",
       "                   random_state=1, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=1),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 311, 522, 733,\n",
       "                                                         944, 1155, 1366, 1577,\n",
       "                                                         1788, 2000]},\n",
       "                   random_state=1, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=1),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 311, 522, 733,\n",
       "                                                         944, 1155, 1366, 1577,\n",
       "                                                         1788, 2000]},\n",
       "                   random_state=1, verbose=2)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_tuned = RandomizedSearchCV(estimator = rfc,\n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 100,\n",
    "                               cv = 5,\n",
    "                               verbose = 2,\n",
    "                               random_state = 1,\n",
    "                               n_jobs = -1)\n",
    "                               \n",
    "# Fit the random search model\n",
    "rfc_tuned.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1155, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}\n",
      "RandomForestClassifier(max_depth=10, min_samples_leaf=4, n_estimators=1155,\n",
      "                       random_state=1)\n"
     ]
    }
   ],
   "source": [
    "# Print best parameter after tuning\n",
    "print(rfc_tuned.best_params_)\n",
    " \n",
    "# Print how our model looks after hyper-parameter tuning\n",
    "print(rfc_tuned.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an RFC_tuned model\n",
    "rfc_tuned = RandomForestClassifier(max_depth=10, min_samples_leaf=4, n_estimators=1155, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of base RFC is 57.8%\n",
      "Precision of tuned RFC is 59.8%\n",
      "Improvement of 3.5%\n"
     ]
    }
   ],
   "source": [
    "# Base model results\n",
    "rfc_base_y_pred = rfc.predict(X_test)\n",
    "rfc_base_precision = round(metrics.precision_score(Y_test, np.round(rfc_base_y_pred), average='weighted', zero_division=1), 3)*100\n",
    "print('Precision of base RFC is ' + str(rfc_base_precision)+'%')\n",
    "\n",
    "# Tuned model results\n",
    "rfc_tuned.fit(X_train, Y_train.values.ravel())\n",
    "rfc_tuned_y_pred = rfc_tuned.predict(X_test)\n",
    "rfc_tuned_precision = round(metrics.precision_score(Y_test, np.round(rfc_tuned_y_pred), average='weighted', zero_division=1), 3)*100\n",
    "print('Precision of tuned RFC is ' + str(rfc_tuned_precision)+'%')\n",
    "\n",
    "# Comparison\n",
    "print('Improvement of {:0.1f}%'.format(100 * (rfc_tuned_precision - rfc_base_precision) / rfc_base_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 of tuned RFC: 51.0%\n",
      "Accuracy score of tuned RFC: 57.9%\n"
     ]
    }
   ],
   "source": [
    "print('F1 of tuned RFC: ' + str(round(metrics.f1_score(Y_test, np.round(rfc_tuned_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of tuned RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(rfc_tuned_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3  <a class=\"anchor\" id=\"7_3\"></a> SVM RBF grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'C': 1.0,\n",
      " 'break_ties': False,\n",
      " 'cache_size': 200,\n",
      " 'class_weight': None,\n",
      " 'coef0': 0.0,\n",
      " 'decision_function_shape': 'ovr',\n",
      " 'degree': 3,\n",
      " 'gamma': 'scale',\n",
      " 'kernel': 'linear',\n",
      " 'max_iter': -1,\n",
      " 'probability': True,\n",
      " 'random_state': 1,\n",
      " 'shrinking': True,\n",
      " 'tol': 0.001,\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "# Look at parameters used by our current SVM model\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(svm.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 2, 3, 4, 5, 10],\n",
       "                         &#x27;gamma&#x27;: [1, 2, 3, 4, 5, 0.1, 0.01],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 2, 3, 4, 5, 10],\n",
       "                         &#x27;gamma&#x27;: [1, 2, 3, 4, 5, 0.1, 0.01],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 2, 3, 4, 5, 10],\n",
       "                         'gamma': [1, 2, 3, 4, 5, 0.1, 0.01],\n",
       "                         'kernel': ['linear']})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining parameter range\n",
    "svm_grid = {'C': [0.1, 1, 2, 3, 4, 5, 10],\n",
    "            'gamma': [1, 2, 3, 4, 5, 0.1, 0.01],\n",
    "            'kernel': ['linear']}\n",
    " \n",
    "# Fitting the model for grid search\n",
    "svm_tuned = GridSearchCV(SVC(), svm_grid, refit = True) \n",
    "svm_tuned.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'gamma': 1, 'kernel': 'linear'}\n",
      "SVC(C=0.1, gamma=1, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "# Print best parameter after tuning\n",
    "print(svm_tuned.best_params_)\n",
    " \n",
    "# Print how our model looks after hyper-parameter tuning\n",
    "print(svm_tuned.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1, gamma=1, kernel=&#x27;linear&#x27;, probability=True, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1, gamma=1, kernel=&#x27;linear&#x27;, probability=True, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.1, gamma=1, kernel='linear', probability=True, random_state=1)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tuned SVC model with linear kernel\n",
    "svm_tuned = SVC(kernel='linear', C = 0.1, gamma = 1, random_state = 1, probability=True)\n",
    "svm_tuned.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of base SVM is 41.699999999999996%\n",
      "Precision of tuned SVM with RBF kernel is 41.699999999999996%\n",
      "Improvement of 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Base model results\n",
    "svm_base_y_pred = svm.predict(X_test)\n",
    "svm_base_precision = round(metrics.precision_score(Y_test, np.round(svm_base_y_pred), average='weighted', zero_division=1), 3)*100\n",
    "print('Precision of base SVM is ' + str(svm_base_precision)+'%')\n",
    "\n",
    "# Tuned model results with kernel\n",
    "svm_tuned_y_pred = svm_tuned.predict(X_test)\n",
    "svm_tuned_precision = round(metrics.precision_score(Y_test, np.round(svm_tuned_y_pred), average='weighted', zero_division=1), 3)*100\n",
    "print('Precision of tuned SVM with RBF kernel is ' + str(svm_tuned_precision)+'%')\n",
    "\n",
    "print('Improvement of {:0.2f}%'.format(100 * (svm_tuned_precision - svm_base_precision) / svm_base_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1, gamma=1, probability=True, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1, gamma=1, probability=True, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.1, gamma=1, probability=True, random_state=1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tuned SVC model with RBF kernel\n",
    "svm_tuned = SVC(kernel='rbf', C = 0.1, gamma = 1, random_state = 1, probability=True)\n",
    "svm_tuned.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of base SVM is 41.699999999999996%\n",
      "Precision of tuned SVM with RBF kernel is 75.0%\n",
      "Improvement of 79.86%\n"
     ]
    }
   ],
   "source": [
    "# Base model results\n",
    "svm_base_y_pred = svm.predict(X_test)\n",
    "svm_base_precision = round(metrics.precision_score(Y_test, np.round(svm_base_y_pred), average='weighted', zero_division=1), 3)*100\n",
    "print('Precision of base SVM is ' + str(svm_base_precision)+'%')\n",
    "\n",
    "# Tuned model results with kernel\n",
    "svm_tuned_y_pred = svm_tuned.predict(X_test)\n",
    "svm_tuned_precision = round(metrics.precision_score(Y_test, np.round(svm_tuned_y_pred), average='weighted', zero_division=1), 3)*100\n",
    "print('Precision of tuned SVM with RBF kernel is ' + str(svm_tuned_precision)+'%')\n",
    "\n",
    "print('Improvement of {:0.2f}%'.format(100 * (svm_tuned_precision - svm_base_precision) / svm_base_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 of tuned SVM with RBF kernel: 33.300000000000004%\n",
      "Accuracy of tuned SVM with RBF kernel: 50.0%\n"
     ]
    }
   ],
   "source": [
    "# Rest of the measures\n",
    "print('F1 of tuned SVM with RBF kernel: ' + str(round(metrics.f1_score(Y_test, np.round(svm_tuned_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy of tuned SVM with RBF kernel: ' + str(round(metrics.accuracy_score(Y_test, np.round(svm_tuned_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: <a class=\"anchor\" id=\"part8\"></a> Ensemble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1  <a class=\"anchor\" id=\"8_1\"></a> Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_voting = VotingClassifier(estimators=[('xgbc_t', xgbc_tuned), ('rfc_t', rfc_tuned)], voting='soft')\n",
    "soft_voting.fit(X_train, Y_train.values.ravel())\n",
    "sv_y_pred = soft_voting.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision score of soft voting classifier: ' + str(round(metrics.precision_score(Y_test, np.round(sv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of soft voting classifier: ' + str(round(metrics.f1_score(Y_test, np.round(sv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall score of soft voting classifier ' + str(round(metrics.recall_score(Y_test, np.round(sv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of soft voting classifier: ' + str(round(metrics.accuracy_score(Y_test, np.round(sv_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_voting = VotingClassifier(estimators=[('xgbc_t', xgbc_tuned), ('rfc_t', rfc_tuned), ('svm_tuned', svm_tuned)], voting='hard')\n",
    "hard_voting.fit(X_train, Y_train.values.ravel())\n",
    "hv_y_pred = hard_voting.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision score of hard voting classifier: ' + str(round(metrics.precision_score(Y_test, np.round(hv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 of hard voting classifier: ' + str(round(metrics.f1_score(Y_test, np.round(hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall score of hard voting classifier ' + str(round(metrics.recall_score(Y_test, np.round(hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy score of hard voting classifier: ' + str(round(metrics.accuracy_score(Y_test, np.round(hv_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2  <a class=\"anchor\" id=\"8_2\"></a> Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.1  <a class=\"anchor\" id=\"8_2_1\"></a> All models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level11 = list()\n",
    "    level11.append(('hard voting', hard_voting))\n",
    "    level11.append(('rfc', rfc))\n",
    "    level11.append(('xgbc tuned', xgbc_tuned))\n",
    "    level11.append(('svm tuned', svm_tuned))\n",
    "    level11.append(('gnb', gnb))\n",
    "    level11.append(('dtc', dtc))\n",
    "    level11.append(('knn', knn_7))\n",
    "    level11.append(('qda', qda))\n",
    "    level11.append(('rdg', rdg))\n",
    "    level11.append(('log', log))\n",
    "    level11.append(('lda', lda))\n",
    "    model = StackingClassifier(estimators=level11, final_estimator=hard_voting, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level11 = list()\n",
    "level11.append(('hard voting', hard_voting))\n",
    "level11.append(('rfc', rfc))\n",
    "level11.append(('xgbc tuned', xgbc_tuned))\n",
    "level11.append(('svm tuned', svm_tuned))\n",
    "level11.append(('gnb', gnb))\n",
    "level11.append(('dtc', dtc))\n",
    "level11.append(('knn', knn_7))\n",
    "level11.append(('qda', qda))\n",
    "level11.append(('rdg', rdg))\n",
    "level11.append(('log', log))\n",
    "level11.append(('lda', lda))\n",
    "level11.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack11_hv = StackingClassifier(estimators=level11, final_estimator=hard_voting, cv=5)\n",
    "stack11_hv = stack11_hv.fit(X, Y.values.ravel())\n",
    "stack11_hv_y_pred = stack11_hv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 11 models learnt on HV: ' + str(round(metrics.precision_score(Y_test, np.round(stack11_hv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 11 models learnt on HV: ' + str(round(metrics.f1_score(Y_test, np.round(stack11_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 11 models learnt on HV: ' + str(round(metrics.recall_score(Y_test, np.round(stack11_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 11 models learnt on HV: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack11_hv_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level11 = list()\n",
    "    level11.append(('hard voting', hard_voting))\n",
    "    level11.append(('rfc', rfc))\n",
    "    level11.append(('xgbc tuned', xgbc_tuned))\n",
    "    level11.append(('svm tuned', svm_tuned))\n",
    "    level11.append(('gnb', gnb))\n",
    "    level11.append(('dtc', dtc))\n",
    "    level11.append(('knn', knn_7))\n",
    "    level11.append(('qda', qda))\n",
    "    level11.append(('rdg', rdg))\n",
    "    level11.append(('log', log))\n",
    "    level11.append(('lda', lda))\n",
    "    model = StackingClassifier(estimators=level11, final_estimator=rfc, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack11_rfc = StackingClassifier(estimators=level11, final_estimator=rfc, cv=5)\n",
    "stack11_rfc = stack11_rfc.fit(X, Y.values.ravel())\n",
    "stack11_rfc_y_pred = stack11_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 11 models learnt on base RFC: ' + str(round(metrics.precision_score(Y_test, np.round(stack11_rfc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 11 models learnt on base RFC: ' + str(round(metrics.f1_score(Y_test, np.round(stack11_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 11 models learnt on base RFC: ' + str(round(metrics.recall_score(Y_test, np.round(stack11_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 11 models learnt on base RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack11_rfc_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level11 = list()\n",
    "    level11.append(('hard voting', hard_voting))\n",
    "    level11.append(('rfc', rfc))\n",
    "    level11.append(('xgbc tuned', xgbc_tuned))\n",
    "    level11.append(('svm tuned', svm_tuned))\n",
    "    level11.append(('gnb', gnb))\n",
    "    level11.append(('dtc', dtc))\n",
    "    level11.append(('knn', knn_7))\n",
    "    level11.append(('qda', qda))\n",
    "    level11.append(('rdg', rdg))\n",
    "    level11.append(('log', log))\n",
    "    level11.append(('lda', lda))\n",
    "    model = StackingClassifier(estimators=level11, final_estimator=xgbc_tuned, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack11_xgbc_t = StackingClassifier(estimators=level11, final_estimator=xgbc_tuned, cv=5)\n",
    "stack11_xgbc_t = stack11_xgbc_t.fit(X, Y.values.ravel())\n",
    "stack11_xgbc_t_y_pred = stack11_xgbc_t.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 11 models learnt on tuned XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(stack11_xgbc_t_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 11 models learnt on tuned XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(stack11_xgbc_t_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 11 models learnt on tuned XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(stack11_xgbc_t_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 11 models learnt on tuned XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack11_xgbc_t_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.2  <a class=\"anchor\" id=\"8_2_2\"></a> Top 10 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level10 = list()\n",
    "    level10.append(('hard voting', hard_voting))\n",
    "    level10.append(('rfc', rfc))\n",
    "    level10.append(('xgbc tuned', xgbc_tuned))\n",
    "    level10.append(('svm tuned', svm_tuned))\n",
    "    level10.append(('gnb', gnb))\n",
    "    level10.append(('dtc', dtc))\n",
    "    level10.append(('knn', knn_7))\n",
    "    level10.append(('qda', qda))\n",
    "    level10.append(('rdg', rdg))\n",
    "    level10.append(('log', log))\n",
    "    model = StackingClassifier(estimators=level10, final_estimator=hard_voting, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level10 = list()\n",
    "level10.append(('hard voting', hard_voting))\n",
    "level10.append(('rfc', rfc))\n",
    "level10.append(('xgbc tuned', xgbc_tuned))\n",
    "level10.append(('svm tuned', svm_tuned))\n",
    "level10.append(('gnb', gnb))\n",
    "level10.append(('dtc', dtc))\n",
    "level10.append(('knn', knn_7))\n",
    "level10.append(('qda', qda))\n",
    "level10.append(('rdg', rdg))\n",
    "level10.append(('log', log))\n",
    "level10.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack10_hv = StackingClassifier(estimators=level10, final_estimator=hard_voting, cv=5)\n",
    "stack10_hv = stack10_hv.fit(X, Y.values.ravel())\n",
    "stack10_hv_y_pred = stack10_hv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 10 models learnt on HV: ' + str(round(metrics.precision_score(Y_test, np.round(stack10_hv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 10 models learnt on HV: ' + str(round(metrics.f1_score(Y_test, np.round(stack10_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 10 models learnt on HV: ' + str(round(metrics.recall_score(Y_test, np.round(stack10_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 10 models learnt on HV: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack10_hv_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level10 = list()\n",
    "    level10.append(('hard voting', hard_voting))\n",
    "    level10.append(('rfc', rfc))\n",
    "    level10.append(('xgbc tuned', xgbc_tuned))\n",
    "    level10.append(('svm tuned', svm_tuned))\n",
    "    level10.append(('gnb', gnb))\n",
    "    level10.append(('dtc', dtc))\n",
    "    level10.append(('knn', knn_7))\n",
    "    level10.append(('qda', qda))\n",
    "    level10.append(('rdg', rdg))\n",
    "    level10.append(('log', log))\n",
    "    model = StackingClassifier(estimators=level10, final_estimator=rfc, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack10_rfc = StackingClassifier(estimators=level10, final_estimator=rfc, cv=5)\n",
    "stack10_rfc = stack10_rfc.fit(X, Y.values.ravel())\n",
    "stack10_rfc_y_pred = stack10_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 10 models learnt on base RFC: ' + str(round(metrics.precision_score(Y_test, np.round(stack10_rfc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 10 models learnt on base RFC: ' + str(round(metrics.f1_score(Y_test, np.round(stack10_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 10 models learnt on base RFC: ' + str(round(metrics.recall_score(Y_test, np.round(stack10_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 10 models learnt on base RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack10_rfc_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level10 = list()\n",
    "    level10.append(('hard voting', hard_voting))\n",
    "    level10.append(('rfc', rfc))\n",
    "    level10.append(('xgbc tuned', xgbc_tuned))\n",
    "    level10.append(('svm tuned', svm_tuned))\n",
    "    level10.append(('gnb', gnb))\n",
    "    level10.append(('dtc', dtc))\n",
    "    level10.append(('knn', knn_7))\n",
    "    level10.append(('qda', qda))\n",
    "    level10.append(('rdg', rdg))\n",
    "    level10.append(('log', log))\n",
    "    model = StackingClassifier(estimators=level10, final_estimator=xgbc_tuned, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack10_xgbc_t = StackingClassifier(estimators=level10, final_estimator=xgbc_tuned, cv=5)\n",
    "stack10_xgbc_t = stack10_xgbc_t.fit(X, Y.values.ravel())\n",
    "stack10_xgbc_t_y_pred = stack10_xgbc_t.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 10 models learnt on tuned XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(stack10_xgbc_t_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 10 models learnt on tuned XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(stack10_xgbc_t_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 10 models learnt on tuned XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(stack10_xgbc_t_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 10 models learnt on tuned XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack10_xgbc_t_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.3  <a class=\"anchor\" id=\"8_2_3\"></a> Top 9 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level9 = list()\n",
    "    level9.append(('hard voting', hard_voting))\n",
    "    level9.append(('rfc', rfc))\n",
    "    level9.append(('xgbc tuned', xgbc_tuned))\n",
    "    level9.append(('svm tuned', svm_tuned))\n",
    "    level9.append(('gnb', gnb))\n",
    "    level9.append(('dtc', dtc))\n",
    "    level9.append(('knn', knn_7))\n",
    "    level9.append(('qda', qda))\n",
    "    level9.append(('rdg', rdg))\n",
    "    model = StackingClassifier(estimators=level9, final_estimator=hard_voting, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level9 = list()\n",
    "level9.append(('hard voting', hard_voting))\n",
    "level9.append(('rfc', rfc))\n",
    "level9.append(('xgbc tuned', xgbc_tuned))\n",
    "level9.append(('svm tuned', svm_tuned))\n",
    "level9.append(('gnb', gnb))\n",
    "level9.append(('dtc', dtc))\n",
    "level9.append(('knn', knn_7))\n",
    "level9.append(('qda', qda))\n",
    "level9.append(('rdg', rdg))\n",
    "level9.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack9_hv = StackingClassifier(estimators=level9, final_estimator=hard_voting, cv=5)\n",
    "stack9_hv = stack9_hv.fit(X, Y.values.ravel())\n",
    "stack9_hv_y_pred = stack9_hv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 9 models learnt on HV: ' + str(round(metrics.precision_score(Y_test, np.round(stack9_hv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 9 models learnt on HV: ' + str(round(metrics.f1_score(Y_test, np.round(stack9_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 9 models learnt on HV: ' + str(round(metrics.recall_score(Y_test, np.round(stack9_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 9 models learnt on HV: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack9_hv_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level9 = list()\n",
    "    level9.append(('hard voting', hard_voting))\n",
    "    level9.append(('rfc', rfc))\n",
    "    level9.append(('xgbc tuned', xgbc_tuned))\n",
    "    level9.append(('svm tuned', svm_tuned))\n",
    "    level9.append(('gnb', gnb))\n",
    "    level9.append(('dtc', dtc))\n",
    "    level9.append(('knn', knn_7))\n",
    "    level9.append(('qda', qda))\n",
    "    level9.append(('rdg', rdg))\n",
    "    model = StackingClassifier(estimators=level9, final_estimator=rfc, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack9_rfc = StackingClassifier(estimators=level9, final_estimator=rfc, cv=5)\n",
    "stack9_rfc = stack9_rfc.fit(X, Y.values.ravel())\n",
    "stack9_rfc_y_pred = stack9_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 9 models learnt on base RFC: ' + str(round(metrics.precision_score(Y_test, np.round(stack9_rfc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 9 models learnt on base RFC: ' + str(round(metrics.f1_score(Y_test, np.round(stack9_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 9 models learnt on base RFC: ' + str(round(metrics.recall_score(Y_test, np.round(stack9_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 9 models learnt on base RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack9_rfc_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level9 = list()\n",
    "    level9.append(('hard voting', hard_voting))\n",
    "    level9.append(('rfc', rfc))\n",
    "    level9.append(('xgbc tuned', xgbc_tuned))\n",
    "    level9.append(('svm tuned', svm_tuned))\n",
    "    level9.append(('gnb', gnb))\n",
    "    level9.append(('dtc', dtc))\n",
    "    level9.append(('knn', knn_7))\n",
    "    level9.append(('qda', qda))\n",
    "    level9.append(('rdg', rdg))\n",
    "    model = StackingClassifier(estimators=level9, final_estimator=xgbc_tuned, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack9_xgbc_t = StackingClassifier(estimators=level9, final_estimator=xgbc_tuned, cv=5)\n",
    "stack9_xgbc_t = stack9_xgbc_t.fit(X, Y.values.ravel())\n",
    "stack9_xgbc_t_y_pred = stack9_xgbc_t.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 9 models learnt on tuned XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(stack9_xgbc_t_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 9 models learnt on tuned XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(stack9_xgbc_t_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 9 models learnt on tuned XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(stack9_xgbc_t_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 9 models learnt on tuned XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack9_xgbc_t_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.4  <a class=\"anchor\" id=\"8_2_4\"></a> Top 8 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level8 = list()\n",
    "    level8.append(('hard voting', hard_voting))\n",
    "    level8.append(('rfc', rfc))\n",
    "    level8.append(('xgbc tuned', xgbc_tuned))\n",
    "    level8.append(('svm tuned', svm_tuned))\n",
    "    level8.append(('gnb', gnb))\n",
    "    level8.append(('dtc', dtc))\n",
    "    level8.append(('knn', knn_7))\n",
    "    level8.append(('qda', qda))\n",
    "    model = StackingClassifier(estimators=level8, final_estimator=hard_voting, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level8 = list()\n",
    "level8.append(('hard voting', hard_voting))\n",
    "level8.append(('rfc', rfc))\n",
    "level8.append(('xgbc tuned', xgbc_tuned))\n",
    "level8.append(('svm tuned', svm_tuned))\n",
    "level8.append(('gnb', gnb))\n",
    "level8.append(('dtc', dtc))\n",
    "level8.append(('knn', knn_7))\n",
    "level8.append(('qda', qda))\n",
    "level8.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack8_hv = StackingClassifier(estimators=level8, final_estimator=hard_voting, cv=5)\n",
    "stack8_hv = stack8_hv.fit(X, Y.values.ravel())\n",
    "stack8_hv_y_pred = stack8_hv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 8 models learnt on HV: ' + str(round(metrics.precision_score(Y_test, np.round(stack8_hv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 8 models learnt on HV: ' + str(round(metrics.f1_score(Y_test, np.round(stack8_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 8 models learnt on HV: ' + str(round(metrics.recall_score(Y_test, np.round(stack8_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 8 models learnt on HV: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack8_hv_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level8 = list()\n",
    "    level8.append(('hard voting', hard_voting))\n",
    "    level8.append(('rfc', rfc))\n",
    "    level8.append(('xgbc tuned', xgbc_tuned))\n",
    "    level8.append(('svm tuned', svm_tuned))\n",
    "    level8.append(('gnb', gnb))\n",
    "    level8.append(('dtc', dtc))\n",
    "    level8.append(('knn', knn_7))\n",
    "    level8.append(('qda', qda))\n",
    "    model = StackingClassifier(estimators=level8, final_estimator=rfc, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack8_rfc = StackingClassifier(estimators=level8, final_estimator=rfc, cv=5)\n",
    "stack8_rfc = stack8_rfc.fit(X, Y.values.ravel())\n",
    "stack8_rfc_y_pred = stack8_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 8 models learnt on base RFC: ' + str(round(metrics.precision_score(Y_test, np.round(stack8_rfc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 8 models learnt on base RFC: ' + str(round(metrics.f1_score(Y_test, np.round(stack8_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 8 models learnt on base RFC: ' + str(round(metrics.recall_score(Y_test, np.round(stack8_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 8 models learnt on base RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack8_rfc_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level8 = list()\n",
    "    level8.append(('hard voting', hard_voting))\n",
    "    level8.append(('rfc', rfc))\n",
    "    level8.append(('xgbc tuned', xgbc_tuned))\n",
    "    level8.append(('svm tuned', svm_tuned))\n",
    "    level8.append(('gnb', gnb))\n",
    "    level8.append(('dtc', dtc))\n",
    "    level8.append(('knn', knn_7))\n",
    "    level8.append(('qda', qda))\n",
    "    model = StackingClassifier(estimators=level8, final_estimator=xgbc_tuned, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack8_xgbc_t = StackingClassifier(estimators=level8, final_estimator=xgbc_tuned, cv=5)\n",
    "stack8_xgbc_t = stack8_xgbc_t.fit(X, Y.values.ravel())\n",
    "stack8_xgbc_t_y_pred = stack8_xgbc_t.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 8 models learnt on tuned XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(stack8_xgbc_t_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 8 models learnt on tuned XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(stack8_xgbc_t_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 8 models learnt on tuned XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(stack8_xgbc_t_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 8 models learnt on tuned XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack8_xgbc_t_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.5  <a class=\"anchor\" id=\"8_2_5\"></a> Top 7 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level9 = list()\n",
    "    level9.append(('hard voting', hard_voting))\n",
    "    level9.append(('rfc', rfc))\n",
    "    level9.append(('xgbc tuned', xgbc_tuned))\n",
    "    level9.append(('svm tuned', svm_tuned))\n",
    "    level9.append(('gnb', gnb))\n",
    "    level9.append(('dtc', dtc))\n",
    "    level9.append(('knn', knn_7))\n",
    "    level9.append(('qda', qda))\n",
    "    level9.append(('rdg', rdg))\n",
    "    model = StackingClassifier(estimators=level9, final_estimator=hard_voting, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level9 = list()\n",
    "level9.append(('hard voting', hard_voting))\n",
    "level9.append(('rfc', rfc))\n",
    "level9.append(('xgbc tuned', xgbc_tuned))\n",
    "level9.append(('svm tuned', svm_tuned))\n",
    "level9.append(('gnb', gnb))\n",
    "level9.append(('dtc', dtc))\n",
    "level9.append(('knn', knn_7))\n",
    "level9.append(('qda', qda))\n",
    "level9.append(('rdg', rdg))\n",
    "level9.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack9_hv = StackingClassifier(estimators=level9, final_estimator=hard_voting, cv=5)\n",
    "stack9_hv = stack9_hv.fit(X, Y.values.ravel())\n",
    "stack9_hv_y_pred = stack9_hv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 9 models learnt on HV: ' + str(round(metrics.precision_score(Y_test, np.round(stack9_hv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 9 models learnt on HV: ' + str(round(metrics.f1_score(Y_test, np.round(stack9_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 9 models learnt on HV: ' + str(round(metrics.recall_score(Y_test, np.round(stack9_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 9 models learnt on HV: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack9_hv_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level9 = list()\n",
    "    level9.append(('hard voting', hard_voting))\n",
    "    level9.append(('rfc', rfc))\n",
    "    level9.append(('xgbc tuned', xgbc_tuned))\n",
    "    level9.append(('svm tuned', svm_tuned))\n",
    "    level9.append(('gnb', gnb))\n",
    "    level9.append(('dtc', dtc))\n",
    "    level9.append(('knn', knn_7))\n",
    "    level9.append(('qda', qda))\n",
    "    level9.append(('rdg', rdg))\n",
    "    model = StackingClassifier(estimators=level9, final_estimator=rfc, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack9_rfc = StackingClassifier(estimators=level9, final_estimator=rfc, cv=5)\n",
    "stack9_rfc = stack9_rfc.fit(X, Y.values.ravel())\n",
    "stack9_rfc_y_pred = stack9_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 9 models learnt on base RFC: ' + str(round(metrics.precision_score(Y_test, np.round(stack9_rfc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 9 models learnt on base RFC: ' + str(round(metrics.f1_score(Y_test, np.round(stack9_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 9 models learnt on base RFC: ' + str(round(metrics.recall_score(Y_test, np.round(stack9_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 9 models learnt on base RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack9_rfc_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level9 = list()\n",
    "    level9.append(('hard voting', hard_voting))\n",
    "    level9.append(('rfc', rfc))\n",
    "    level9.append(('xgbc tuned', xgbc_tuned))\n",
    "    level9.append(('svm tuned', svm_tuned))\n",
    "    level9.append(('gnb', gnb))\n",
    "    level9.append(('dtc', dtc))\n",
    "    level9.append(('knn', knn_7))\n",
    "    level9.append(('qda', qda))\n",
    "    level9.append(('rdg', rdg))\n",
    "    model = StackingClassifier(estimators=level9, final_estimator=xgbc_tuned, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack9_xgbc_t = StackingClassifier(estimators=level9, final_estimator=xgbc_tuned, cv=5)\n",
    "stack9_xgbc_t = stack9_xgbc_t.fit(X, Y.values.ravel())\n",
    "stack9_xgbc_t_y_pred = stack9_xgbc_t.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 9 models learnt on tuned XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(stack9_xgbc_t_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 9 models learnt on tuned XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(stack9_xgbc_t_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 9 models learnt on tuned XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(stack9_xgbc_t_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 9 models learnt on tuned XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack9_xgbc_t_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.6  <a class=\"anchor\" id=\"8_2_6\"></a> Top 6 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.7  <a class=\"anchor\" id=\"8_2_7\"></a> Top 5 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.8  <a class=\"anchor\" id=\"8_2_8\"></a> Top 4 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.9  <a class=\"anchor\" id=\"8_2_9\"></a> Top 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level3 = list()\n",
    "    level3.append(('hard voting', hard_voting))\n",
    "    level3.append(('rfc', rfc))\n",
    "    level3.append(('xgbc tuned', xgbc_tuned))\n",
    "    model = StackingClassifier(estimators=level3, final_estimator=hard_voting, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level3 = list()\n",
    "level3.append(('hard voting', hard_voting))\n",
    "level3.append(('rfc', rfc))\n",
    "level3.append(('xgbc tuned', xgbc_tuned))\n",
    "level3.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack3_hv = StackingClassifier(estimators=level3, final_estimator=hard_voting, cv=5)\n",
    "stack3_hv = stack3_hv.fit(X, Y.values.ravel())\n",
    "stack3_hv_y_pred = stack3_hv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 3 models learnt on HV: ' + str(round(metrics.precision_score(Y_test, np.round(stack3_hv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 3 models learnt on HV: ' + str(round(metrics.f1_score(Y_test, np.round(stack3_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 3 models learnt on HV: ' + str(round(metrics.recall_score(Y_test, np.round(stack3_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 3 models learnt on HV: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack3_hv_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level3 = list()\n",
    "    level3.append(('hard voting', hard_voting))\n",
    "    level3.append(('rfc', rfc))\n",
    "    level3.append(('xgbc tuned', xgbc_tuned))\n",
    "    model = StackingClassifier(estimators=level3, final_estimator=rfc, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack3_rfc = StackingClassifier(estimators=level3, final_estimator=rfc, cv=5)\n",
    "stack3_rfc = stack3_rfc.fit(X, Y.values.ravel())\n",
    "stack3_rfc_y_pred = stack3_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 3 models learnt on base RFC: ' + str(round(metrics.precision_score(Y_test, np.round(stack3_rfc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 3 models learnt on base RFC: ' + str(round(metrics.f1_score(Y_test, np.round(stack3_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 3 models learnt on base RFC: ' + str(round(metrics.recall_score(Y_test, np.round(stack3_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 3 models learnt on base RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack3_rfc_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level3 = list()\n",
    "    level3.append(('hard voting', hard_voting))\n",
    "    level3.append(('rfc', rfc))\n",
    "    level3.append(('xgbc tuned', xgbc_tuned))\n",
    "    model = StackingClassifier(estimators=level3, final_estimator=xgbc_tuned, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack3_xgbc_t = StackingClassifier(estimators=level3, final_estimator=xgbc_tuned, cv=5)\n",
    "stack3_xgbc_t = stack3_xgbc_t.fit(X, Y.values.ravel())\n",
    "stack3_xgbc_t_y_pred = stack3_xgbc_t.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 3 models learnt on tuned XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(stack3_xgbc_t_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 3 models learnt on tuned XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(stack3_xgbc_t_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 3 models learnt on tuned XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(stack3_xgbc_t_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 3 models learnt on tuned XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack3_xgbc_t_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.10  <a class=\"anchor\" id=\"8_2_10\"></a> Top 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level2 = list()\n",
    "    level2.append(('hard voting', hard_voting))\n",
    "    level2.append(('rfc', rfc))\n",
    "    model = StackingClassifier(estimators=level2, final_estimator=hard_voting, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level2 = list()\n",
    "level2.append(('hard voting', hard_voting))\n",
    "level2.append(('rfc', rfc))\n",
    "level2.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack2_hv = StackingClassifier(estimators=level2, final_estimator=hard_voting, cv=5)\n",
    "stack2_hv = stack2_hv.fit(X, Y.values.ravel())\n",
    "stack2_hv_y_pred = stack2_hv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 2 models learnt on HV: ' + str(round(metrics.precision_score(Y_test, np.round(stack2_hv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 2 models learnt on HV: ' + str(round(metrics.f1_score(Y_test, np.round(stack2_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 2 models learnt on HV: ' + str(round(metrics.recall_score(Y_test, np.round(stack2_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 2 models learnt on HV: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack2_hv_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level2 = list()\n",
    "    level2.append(('hard voting', hard_voting))\n",
    "    level2.append(('rfc', rfc))\n",
    "    model = StackingClassifier(estimators=level2, final_estimator=rfc, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack2_rfc = StackingClassifier(estimators=level2, final_estimator=rfc, cv=5)\n",
    "stack2_rfc = stack2_rfc.fit(X, Y.values.ravel())\n",
    "stack2_rfc_y_pred = stack2_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 2 models learnt on base RFC: ' + str(round(metrics.precision_score(Y_test, np.round(stack2_rfc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 2 models learnt on base RFC: ' + str(round(metrics.f1_score(Y_test, np.round(stack2_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 2 models learnt on base RFC: ' + str(round(metrics.recall_score(Y_test, np.round(stack2_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 2 models learnt on base RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack2_rfc_y_pred)), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    level2 = list()\n",
    "    level2.append(('hard voting', hard_voting))\n",
    "    level2.append(('rfc', rfc))\n",
    "    model = StackingClassifier(estimators=level2, final_estimator=xgbc_tuned, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack2_xgbc_t = StackingClassifier(estimators=level2, final_estimator=xgbc_tuned, cv=5)\n",
    "stack2_xgbc_t = stack2_xgbc_t.fit(X, Y.values.ravel())\n",
    "stack2_xgbc_t_y_pred = stack2_xgbc_t.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision with 2 models learnt on tuned XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(stack2_xgbc_t_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 with 2 models learnt on tuned XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(stack2_xgbc_t_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Recall with 2 models learnt on tuned XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(stack2_xgbc_t_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Accuracy with 2 models learnt on tuned XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack2_xgbc_t_y_pred)), 3)*100)+'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32faf87829e52f10b3379fa51fb017496aba8a2082e84bf41be67a5b199752f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
