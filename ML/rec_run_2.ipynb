{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">MSIN0114: Business Analytics Consulting Project</h1>\n",
    "<h2 align=\"center\">S2R Analytics, pt. 3.1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "* [Part 6](#part6): Classification\n",
    "    * [6.0](#6_0): Data splitting\n",
    "    * [6.1](#6_1): Models\n",
    "    * [6.2](#6_2): Models comparison\n",
    "<br />\n",
    "<br />\n",
    "* [Part 7](#part7): Fine-tuning\n",
    "    * [7.1](#7_1): XGBoost grid search\n",
    "    * [7.2](#7_2): Random forest classifier grid earch\n",
    "<br />\n",
    "<br />\n",
    "* [Part 8](#part8): Ensemble learning\n",
    "    * [8.1](#8_1): Voting classifier\n",
    "    * [8.2](#8_2): Stacking\n",
    "<br />\n",
    "<br />\n",
    "* [Part 9](#part9): Evaluation of the final model\n",
    "    * [9.1](#9_1): Confusion matrix\n",
    "    * [9.2](#9_2): ROC curve\n",
    "    * [9.3](#9_3): Prediction-recall curve\n",
    "    * [9.4](#9_4): Cost matrix\n",
    "    * [9.5](#9_5): Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentials\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from pandas.api.types import CategoricalDtype\n",
    "pd.options.display.max_columns = None\n",
    "import sqlite3\n",
    "import pyodbc\n",
    "import numpy as np; np.random.seed(1)\n",
    "\n",
    "# Image creation and display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import pyplot\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Metrics of accuracy\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from pycm import *\n",
    "import imbalanced_ensemble as imbens\n",
    "from imbalanced_ensemble.ensemble.base import sort_dict_by_key\n",
    "from collections import Counter\n",
    "\n",
    "# Fine-tuning and enseble learning\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#- Other\n",
    "import itertools as it\n",
    "import io\n",
    "import os\n",
    "os.sys.path\n",
    "import sys\n",
    "import glob\n",
    "import concurrent.futures\n",
    "from __future__ import print_function\n",
    "import binascii\n",
    "import struct\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import scipy.cluster\n",
    "import datetime, time\n",
    "import functools, operator\n",
    "from datetime import datetime\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv-files/resampled_compact_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: <a class=\"anchor\" id=\"part6\"></a> Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0 <a class=\"anchor\" id=\"6_0\"></a> Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training data: 7437\n",
      "No. of training targets: 7437\n",
      "No. of testing data: 1860\n",
      "No. of testing targets: 1860\n"
     ]
    }
   ],
   "source": [
    "# Choose dependent variables\n",
    "Y = df[['Rec_Class']]\n",
    "\n",
    "# Drop the dependent variables from the feature data set\n",
    "X = df.drop(columns = ['Rec_Class', 'Profit_Class'])\n",
    "\n",
    "# Scale the explanatory variables\n",
    "X1 = pd.DataFrame(preprocessing.normalize(X))\n",
    "X1.columns = X.columns\n",
    "X = X1\n",
    "\n",
    "# Split data set into train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=1, stratify = Y)\n",
    "\n",
    "print(f'No. of training data: {X_train.shape[0]}')\n",
    "print(f'No. of training targets: {Y_train.shape[0]}')\n",
    "print(f'No. of testing data: {X_test.shape[0]}')\n",
    "print(f'No. of testing targets: {Y_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 <a class=\"anchor\" id=\"6_1\"></a> Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1  <a class=\"anchor\" id=\"6_1_1\"></a> Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of LOG: 68.30000000000001%\n",
      "Precision score of LOG: 68.30000000000001%\n",
      "Recall score of LOG: 68.30000000000001%\n",
      "F1 of LOG: 68.30000000000001%\n"
     ]
    }
   ],
   "source": [
    "# Create a logistic regression classifier model\n",
    "log = LogisticRegression(random_state = 1, max_iter = 30000)\n",
    "\n",
    "# Train the model using train set\n",
    "log.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "log_y_pred=log.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Accuracy score of LOG: ' + str(round(metrics.accuracy_score(Y_test, np.round(log_y_pred)), 3)*100)+'%')\n",
    "print('Precision score of LOG: ' + str(round(metrics.precision_score(Y_test, np.round(log_y_pred), average='weighted', zero_division=0), 3)*100)+'%')\n",
    "print('Recall score of LOG: ' + str(round(metrics.recall_score(Y_test, np.round(log_y_pred), average='weighted', zero_division=0), 3)*100)+'%')\n",
    "print('F1 of LOG: ' + str(round(metrics.f1_score(Y_test, np.round(log_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.2  <a class=\"anchor\" id=\"6_1_2\"></a> Ridge regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of RDG: 68.10000000000001%\n",
      "Precision score of RDG: 68.10000000000001%\n",
      "Recall score of RDG: 68.10000000000001%\n",
      "F1 of RDG: 68.10000000000001%\n"
     ]
    }
   ],
   "source": [
    "# Create a ridge regression classifier model\n",
    "rdg = RidgeClassifier(alpha=1.0, random_state = 1, max_iter = 30000)\n",
    "\n",
    "# Train the model using train set\n",
    "rdg.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "rdg_y_pred=rdg.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Accuracy score of RDG: ' + str(round(metrics.accuracy_score(Y_test, np.round(rdg_y_pred)), 3)*100)+'%')\n",
    "print('Precision score of RDG: ' + str(round(metrics.precision_score(Y_test, np.round(rdg_y_pred), average='weighted', zero_division=0), 3)*100)+'%')\n",
    "print('Recall score of RDG: ' + str(round(metrics.recall_score(Y_test, np.round(rdg_y_pred), average='weighted', zero_division=0), 3)*100)+'%')\n",
    "print('F1 of RDG: ' + str(round(metrics.f1_score(Y_test, np.round(rdg_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3 <a class=\"anchor\" id=\"6_1_3\"></a> K-Neighbours classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of KNN-100: 66.0%\n",
      "Precision score of KNN-100: 66.10000000000001%\n",
      "Recall score of KNN-100: 66.0%\n",
      "F1 of KNN-100: 66.0%\n"
     ]
    }
   ],
   "source": [
    "# Create a k-Neighbours classifier model with 100 neighbours\n",
    "np.random.seed(1)\n",
    "knn_100 = KNeighborsClassifier(n_neighbors=100)\n",
    "\n",
    "# Train the model using train set\n",
    "knn_100.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "knn_100_y_pred = knn_100.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Accuracy score of KNN-100: ' + str(round(metrics.accuracy_score(Y_test, np.round(knn_100_y_pred)), 3)*100)+'%')\n",
    "print('Precision score of KNN-100: ' + str(round(metrics.precision_score(Y_test, np.round(knn_100_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('Recall score of KNN-100: ' + str(round(metrics.recall_score(Y_test, np.round(knn_100_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('F1 of KNN-100: ' + str(round(metrics.f1_score(Y_test, np.round(knn_100_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.4  <a class=\"anchor\" id=\"6_1_4\"></a> Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of DTC: 63.6%\n",
      "Precision score of DTC: 63.6%\n",
      "Recall score of DTC: 63.6%\n",
      "F1 of DTC: 63.6%\n"
     ]
    }
   ],
   "source": [
    "# Create decision tree classifier model\n",
    "dtc = DecisionTreeClassifier(random_state = 1)\n",
    "\n",
    "# Train the model using train set\n",
    "dtc = dtc.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "dtc_y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Accuracy score of DTC: ' + str(round(metrics.accuracy_score(Y_test, np.round(dtc_y_pred)), 3)*100)+'%')\n",
    "print('Precision score of DTC: ' + str(round(metrics.precision_score(Y_test, np.round(dtc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('Recall score of DTC: ' + str(round(metrics.recall_score(Y_test, np.round(dtc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('F1 of DTC: ' + str(round(metrics.f1_score(Y_test, np.round(dtc_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.5  <a class=\"anchor\" id=\"6_1_5\"></a> Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of RFC: 70.3%\n",
      "Precision score of RFC: 70.39999999999999%\n",
      "Recall score of RFC: 70.3%\n",
      "F1 of RFC: 70.3%\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier model\n",
    "rfc = RandomForestClassifier(random_state = 1)\n",
    "\n",
    "# Train the model using train set\n",
    "rfc.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "rfc_y_pred=rfc.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Accuracy score of RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(rfc_y_pred)), 3)*100)+'%')\n",
    "print('Precision score of RFC: ' + str(round(metrics.precision_score(Y_test, np.round(rfc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('Recall score of RFC: ' + str(round(metrics.recall_score(Y_test, np.round(rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('F1 of RFC: ' + str(round(metrics.f1_score(Y_test, np.round(rfc_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.6  <a class=\"anchor\" id=\"6_1_6\"></a> Gaussian classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of XGBC: 71.1%\n",
      "Precision score of XGBC: 71.39999999999999%\n",
      "Recall score of XGBC: 71.1%\n",
      "F1 of XGBC: 71.0%\n"
     ]
    }
   ],
   "source": [
    "# Create a Gaussian classifier model\n",
    "xgbc = XGBClassifier(n_estimators=100, learning_rate=0.05, booster='gbtree', random_state = 1, eval_metric='mlogloss', objective='binary:logistic', use_label_encoder=False)\n",
    "\n",
    "# Train the model using train set\n",
    "xgbc.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "xgbc_y_pred=xgbc.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Accuracy score of XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(xgbc_y_pred)), 3)*100)+'%')\n",
    "print('Precision score of XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(xgbc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('Recall score of XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(xgbc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('F1 of XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(xgbc_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.7  <a class=\"anchor\" id=\"6_1_7\"></a> Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of GNB: 52.400000000000006%\n",
      "Precision score of GNB: 56.99999999999999%\n",
      "Recall score of GNB: 52.400000000000006%\n",
      "F1 of GNB: 42.9%\n"
     ]
    }
   ],
   "source": [
    "# Create a Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model using train set\n",
    "gnb.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "gnb_y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Accuracy score of GNB: ' + str(round(metrics.accuracy_score(Y_test, np.round(gnb_y_pred)), 3)*100)+'%')\n",
    "print('Precision score of GNB: ' + str(round(metrics.precision_score(Y_test, np.round(gnb_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('Recall score of GNB: ' + str(round(metrics.recall_score(Y_test, np.round(gnb_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('F1 of GNB: ' + str(round(metrics.f1_score(Y_test, np.round(gnb_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.8  <a class=\"anchor\" id=\"6_1_8\"></a> Linear discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of LDA: 68.10000000000001%\n",
      "Precision score of LDA: 68.10000000000001%\n",
      "Recall score of LDA: 68.10000000000001%\n",
      "F1 of LDA: 68.10000000000001%\n"
     ]
    }
   ],
   "source": [
    "# Create a linear discriminant analysis model\n",
    "lda = LinearDiscriminantAnalysis(n_components = 1)\n",
    "\n",
    "# Train the model using train set\n",
    "lda.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "lda_y_pred = lda.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Accuracy score of LDA: ' + str(round(metrics.accuracy_score(Y_test, np.round(lda_y_pred)), 3)*100)+'%')\n",
    "print('Precision score of LDA: ' + str(round(metrics.precision_score(Y_test, np.round(lda_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('Recall score of LDA: ' + str(round(metrics.recall_score(Y_test, np.round(lda_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('F1 of LDA: ' + str(round(metrics.f1_score(Y_test, np.round(lda_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.9  <a class=\"anchor\" id=\"6_1_9\"></a> Quadratic discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of QDA: 54.400000000000006%\n",
      "Precision score of QDA: 61.4%\n",
      "Recall score of QDA: 54.400000000000006%\n",
      "F1 of QDA: 46.2%\n"
     ]
    }
   ],
   "source": [
    "# Create a QDA model\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "# Train the model using train set\n",
    "qda.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "qda_y_pred = qda.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Accuracy score of QDA: ' + str(round(metrics.accuracy_score(Y_test, np.round(qda_y_pred)), 3)*100)+'%')\n",
    "print('Precision score of QDA: ' + str(round(metrics.precision_score(Y_test, np.round(qda_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('Recall score of QDA: ' + str(round(metrics.recall_score(Y_test, np.round(qda_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('F1 of QDA: ' + str(round(metrics.f1_score(Y_test, np.round(qda_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.10  <a class=\"anchor\" id=\"6_1_10\"></a> Mixture discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.11  <a class=\"anchor\" id=\"6_1_11\"></a> Regularized discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.12  <a class=\"anchor\" id=\"6_1_12\"></a> Flexible discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.13  <a class=\"anchor\" id=\"6_1_13\"></a> Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.14  <a class=\"anchor\" id=\"6_1_14\"></a> Support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of SVM: 68.30000000000001%\n",
      "Precision score of SVM: 68.4%\n",
      "Recall score of SVM: 68.30000000000001%\n",
      "F1 of SVM: 68.30000000000001%\n"
     ]
    }
   ],
   "source": [
    "# Create an SVM Classifier model\n",
    "svm = SVC(kernel='linear', random_state = 1, probability=True)\n",
    "\n",
    "# Train the model using the train set\n",
    "svm.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "svm_y_pred = svm.predict(X_test)\n",
    "\n",
    "# Accuracy measures\n",
    "print('Accuracy score of SVM: ' + str(round(metrics.accuracy_score(Y_test, np.round(svm_y_pred)), 3)*100)+'%')\n",
    "print('Precision score of SVM: ' + str(round(metrics.precision_score(Y_test, np.round(svm_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('Recall score of SVM: ' + str(round(metrics.recall_score(Y_test, np.round(svm_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('F1 of SVM: ' + str(round(metrics.f1_score(Y_test, np.round(svm_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: <a class=\"anchor\" id=\"part7\"></a> Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1  <a class=\"anchor\" id=\"7_1\"></a> XGBoost grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
      " 'eval_metric': ['mlogloss'],\n",
      " 'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
      " 'learning_rate': [0.1],\n",
      " 'max_depth': [4, 5, 6],\n",
      " 'min_child_weight': [6, 8, 10, 12],\n",
      " 'n_estimators': [1000],\n",
      " 'nthread': [4],\n",
      " 'objective': ['binary:logistic'],\n",
      " 'scale_pos_weight': [1],\n",
      " 'seed': [1],\n",
      " 'subsample': [0.6, 0.7, 0.8, 0.9]}\n"
     ]
    }
   ],
   "source": [
    "#URL: https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "\n",
    "# Defining parameter range\n",
    "xgbc_grid = {'learning_rate':[0.1],\n",
    "    'n_estimators':[1000],\n",
    "    'max_depth':[4,5,6],\n",
    "    'min_child_weight':[6,8,10,12],\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "    'objective':['binary:logistic'],\n",
    "    'nthread':[4],\n",
    "    'scale_pos_weight':[1],\n",
    "    'seed':[1],\n",
    "    'eval_metric':['mlogloss']}\n",
    "\n",
    "pprint(xgbc_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_to_...\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, ...),\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.6, 0.7, 0.8, 0.9],\n",
       "                         &#x27;eval_metric&#x27;: [&#x27;mlogloss&#x27;],\n",
       "                         &#x27;gamma&#x27;: [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [4, 5, 6],\n",
       "                         &#x27;min_child_weight&#x27;: [6, 8, 10, 12],\n",
       "                         &#x27;n_estimators&#x27;: [1000], &#x27;nthread&#x27;: [4],\n",
       "                         &#x27;objective&#x27;: [&#x27;binary:logistic&#x27;],\n",
       "                         &#x27;scale_pos_weight&#x27;: [1], &#x27;seed&#x27;: [1],\n",
       "                         &#x27;subsample&#x27;: [0.6, 0.7, 0.8, 0.9]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_to_...\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, ...),\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.6, 0.7, 0.8, 0.9],\n",
       "                         &#x27;eval_metric&#x27;: [&#x27;mlogloss&#x27;],\n",
       "                         &#x27;gamma&#x27;: [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [4, 5, 6],\n",
       "                         &#x27;min_child_weight&#x27;: [6, 8, 10, 12],\n",
       "                         &#x27;n_estimators&#x27;: [1000], &#x27;nthread&#x27;: [4],\n",
       "                         &#x27;objective&#x27;: [&#x27;binary:logistic&#x27;],\n",
       "                         &#x27;scale_pos_weight&#x27;: [1], &#x27;seed&#x27;: [1],\n",
       "                         &#x27;subsample&#x27;: [0.6, 0.7, 0.8, 0.9]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None,\n",
       "              reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None,\n",
       "              reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_to_...\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
       "                         'eval_metric': ['mlogloss'],\n",
       "                         'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                         'learning_rate': [0.1], 'max_depth': [4, 5, 6],\n",
       "                         'min_child_weight': [6, 8, 10, 12],\n",
       "                         'n_estimators': [1000], 'nthread': [4],\n",
       "                         'objective': ['binary:logistic'],\n",
       "                         'scale_pos_weight': [1], 'seed': [1],\n",
       "                         'subsample': [0.6, 0.7, 0.8, 0.9]})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model for grid search\n",
    "xgbc_tuned = GridSearchCV(XGBClassifier(), xgbc_grid, refit = True)\n",
    "xgbc_tuned.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.6, 'eval_metric': 'mlogloss', 'gamma': 0.2, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 10, 'n_estimators': 1000, 'nthread': 4, 'objective': 'binary:logistic', 'scale_pos_weight': 1, 'seed': 1, 'subsample': 0.8}\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.6,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric='mlogloss', gamma=0.2, gpu_id=-1,\n",
      "              grow_policy='depthwise', importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
      "              max_cat_to_onehot=4, max_delta_step=0, max_depth=4, max_leaves=0,\n",
      "              min_child_weight=10, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=1000, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
      "              predictor='auto', random_state=1, reg_alpha=0, ...)\n"
     ]
    }
   ],
   "source": [
    "# Print best parameter after tuning\n",
    "print(xgbc_tuned.best_params_)\n",
    " \n",
    "# Print how our model looks after hyper-parameter tuning\n",
    "print(xgbc_tuned.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.6,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;mlogloss&#x27;, gamma=0.2, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_to_onehot=4, max_delta_step=0, max_depth=4, max_leaves=0,\n",
       "              min_child_weight=10, missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "              n_estimators=1000, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
       "              predictor=&#x27;auto&#x27;, random_state=1, reg_alpha=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.6,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;mlogloss&#x27;, gamma=0.2, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_to_onehot=4, max_delta_step=0, max_depth=4, max_leaves=0,\n",
       "              min_child_weight=10, missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "              n_estimators=1000, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
       "              predictor=&#x27;auto&#x27;, random_state=1, reg_alpha=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.6,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='mlogloss', gamma=0.2, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
       "              max_cat_to_onehot=4, max_delta_step=0, max_depth=4, max_leaves=0,\n",
       "              min_child_weight=10, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=1000, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
       "              predictor='auto', random_state=1, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tuned XGBC model\n",
    "xgbc_tuned = XGBClassifier(colsample_bytree=0.6, eval_metric='mlogloss',\n",
    "gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=10, n_estimators=1000,\n",
    "nthread=4, objective='binary:logistic', scale_pos_weight = 1, seed=1, subsample=0.8)\n",
    "xgbc_tuned.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of base XGBC is 71.1%\n",
      "Accuracy of tuned XGBC is 69.3%\n",
      "Improvement of -2.5%\n"
     ]
    }
   ],
   "source": [
    "# Base model results\n",
    "xgbc_base_y_pred = xgbc.predict(X_test)\n",
    "xgbc_base_accuracy = round(metrics.accuracy_score(Y_test, np.round(xgbc_base_y_pred)), 3)*100\n",
    "print('Accuracy of base XGBC is ' + str(xgbc_base_accuracy)+'%')\n",
    "\n",
    "# Tuned model results\n",
    "xgbc_tuned_y_pred = xgbc_tuned.predict(X_test)\n",
    "xgbc_tuned_accuracy = round(metrics.accuracy_score(Y_test, xgbc_tuned_y_pred), 3)*100\n",
    "print('Accuracy of tuned XGBC is ' + str(xgbc_tuned_accuracy)+'%')\n",
    "\n",
    "# Comparison\n",
    "print('Improvement of {:0.1f}%'.format(100 * (xgbc_tuned_accuracy - xgbc_base_accuracy) / xgbc_base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of tuned XGBC: 69.3%\n",
      "Recall score of tuned XGBC: 69.3%\n",
      "F1 of tuned XGBC: 69.3%\n"
     ]
    }
   ],
   "source": [
    "# Rest of the measures\n",
    "print('Precision score of tuned XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(xgbc_tuned_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('Recall score of tuned XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(xgbc_tuned_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('F1 of tuned XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(xgbc_tuned_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3  <a class=\"anchor\" id=\"7_2\"></a> SVM grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'C': 1.0,\n",
      " 'break_ties': False,\n",
      " 'cache_size': 200,\n",
      " 'class_weight': None,\n",
      " 'coef0': 0.0,\n",
      " 'decision_function_shape': 'ovr',\n",
      " 'degree': 3,\n",
      " 'gamma': 'scale',\n",
      " 'kernel': 'linear',\n",
      " 'max_iter': -1,\n",
      " 'probability': True,\n",
      " 'random_state': 1,\n",
      " 'shrinking': True,\n",
      " 'tol': 0.001,\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "# Look at parameters used by our current SVM model\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(svm.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [1, 0.1, 0.01],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [1, 0.1, 0.01],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01],\n",
       "                         'kernel': ['linear']})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#URL: https://www.geeksforgeeks.org/svm-hyperparameter-tuning-using-gridsearchcv-ml/\n",
    "\n",
    "# Defining parameter range\n",
    "svm_grid = {'C': [0.1, 1, 10],\n",
    "            'gamma': [1, 0.1, 0.01],\n",
    "            'kernel': ['linear']}\n",
    " \n",
    "# Fitting the model for grid search\n",
    "svm_tuned = GridSearchCV(SVC(), svm_grid, refit = True) \n",
    "svm_tuned.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1, 'kernel': 'linear'}\n",
      "SVC(C=10, gamma=1, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "# Print best parameter after tuning\n",
    "print(svm_tuned.best_params_)\n",
    " \n",
    "# Print how our model looks after hyper-parameter tuning\n",
    "print(svm_tuned.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of base SVM is 68.30000000000001%\n",
      "Accuracy of tuned SVM is 68.4%\n",
      "Improvement of 0.15%\n"
     ]
    }
   ],
   "source": [
    "# Base model results\n",
    "svm_base_y_pred = svm.predict(X_test)\n",
    "svm_base_accuracy = round(metrics.accuracy_score(Y_test, svm_base_y_pred), 3)*100\n",
    "print('Accuracy of base SVM is ' + str(svm_base_accuracy)+'%')\n",
    "\n",
    "# Tuned model results\n",
    "svm_tuned_y_pred = svm_tuned.predict(X_test)\n",
    "svm_tuned_accuracy = round(metrics.accuracy_score(Y_test, svm_tuned_y_pred), 3)*100\n",
    "print('Accuracy of tuned SVM is ' + str(svm_tuned_accuracy)+'%')\n",
    "\n",
    "print('Improvement of {:0.2f}%'.format(100 * (svm_tuned_accuracy - svm_base_accuracy) / svm_base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: <a class=\"anchor\" id=\"part8\"></a> Ensemble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1  <a class=\"anchor\" id=\"8_1\"></a> Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;xgbc&#x27;,\n",
       "                              XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                            callbacks=None, colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=1,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=&#x27;mlogloss&#x27;, gamma=0,\n",
       "                                            gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=&#x27;&#x27;,\n",
       "                                            learning_rate=0.05, max_bin=256,\n",
       "                                            max_cat_to_onehot=4,\n",
       "                                            max_delta_step=0, max_depth=6,\n",
       "                                            max_leaves=0, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints=&#x27;()&#x27;,\n",
       "                                            n_estimators=100, n_jobs=0,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            predictor=&#x27;auto&#x27;, random_state=1,\n",
       "                                            reg_alpha=0, reg_lambda=1, ...)),\n",
       "                             (&#x27;rfc&#x27;, RandomForestClassifier(random_state=1))],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;xgbc&#x27;,\n",
       "                              XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                            callbacks=None, colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=1,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=&#x27;mlogloss&#x27;, gamma=0,\n",
       "                                            gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=&#x27;&#x27;,\n",
       "                                            learning_rate=0.05, max_bin=256,\n",
       "                                            max_cat_to_onehot=4,\n",
       "                                            max_delta_step=0, max_depth=6,\n",
       "                                            max_leaves=0, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints=&#x27;()&#x27;,\n",
       "                                            n_estimators=100, n_jobs=0,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            predictor=&#x27;auto&#x27;, random_state=1,\n",
       "                                            reg_alpha=0, reg_lambda=1, ...)),\n",
       "                             (&#x27;rfc&#x27;, RandomForestClassifier(random_state=1))],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgbc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;mlogloss&#x27;, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.05, max_bin=256,\n",
       "              max_cat_to_onehot=4, max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "              random_state=1, reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rfc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('xgbc',\n",
       "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            callbacks=None, colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=1,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric='mlogloss', gamma=0,\n",
       "                                            gpu_id=-1, grow_policy='depthwise',\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints='',\n",
       "                                            learning_rate=0.05, max_bin=256,\n",
       "                                            max_cat_to_onehot=4,\n",
       "                                            max_delta_step=0, max_depth=6,\n",
       "                                            max_leaves=0, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=100, n_jobs=0,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            predictor='auto', random_state=1,\n",
       "                                            reg_alpha=0, reg_lambda=1, ...)),\n",
       "                             ('rfc', RandomForestClassifier(random_state=1))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_voting = VotingClassifier(\n",
    "    estimators=[('xgbc', xgbc), ('rfc', rfc)],\n",
    "    voting='soft')\n",
    "\n",
    "soft_voting.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2  <a class=\"anchor\" id=\"8_2\"></a> Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.1  <a class=\"anchor\" id=\"8_2_1\"></a> Top 9 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/\n",
    "\n",
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel9 = list()\n",
    "\tlevel9.append(('dtc', dtc))\n",
    "\tlevel9.append(('knn', knn_100))\n",
    "\tlevel9.append(('rdg', rdg))\n",
    "\tlevel9.append(('lda', lda))\n",
    "\tlevel9.append(('log', log))\n",
    "\tlevel9.append(('svm_t', svm_tuned))\n",
    "\tlevel9.append(('rfc', rfc))\n",
    "\tlevel9.append(('sv', soft_voting))\n",
    "\tlevel9.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on base XGBC\n",
    "\tmodel = StackingClassifier(estimators=level9, final_estimator=xgbc, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models separately\n",
    "level9 = list()\n",
    "level9.append(('gnb', gnb))\n",
    "level9.append(('qda', qda))\n",
    "level9.append(('lda', lda))\n",
    "level9.append(('log', log))\n",
    "level9.append(('knn', knn_7))\n",
    "level9.append(('dtc', dtc))\n",
    "level9.append(('hard voting', hard_voting))\n",
    "level9.append(('rfc tuned', rfc_tuned))\n",
    "level9.append(('xgbc', xgbc))\n",
    "level9.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on base XGBC\n",
    "stack9_xgbc = StackingClassifier(estimators=level9, final_estimator=xgbc, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack9_xgbc = stack9_xgbc.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack9_xgbc_y_pred = stack9_xgbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 9 models: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack9_xgbc_y_pred)), 3)*100)+'%')\n",
    "print('Recall score  with 9 models: ' + str(round(metrics.recall_score(Y_test, np.round(stack9_xgbc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score  with 9 models: ' + str(round(metrics.precision_score(Y_test, np.round(stack9_xgbc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 9 models: ' + str(round(metrics.f1_score(Y_test, np.round(stack9_xgbc_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.2  <a class=\"anchor\" id=\"8_2_2\"></a> Top 8 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel8 = list()\n",
    "\tlevel8.append(('qda', qda))\n",
    "\tlevel8.append(('lda', lda))\n",
    "\tlevel8.append(('log', log))\n",
    "\tlevel8.append(('knn', knn_7))\n",
    "\tlevel8.append(('dtc', dtc))\n",
    "\tlevel8.append(('hard voting', hard_voting))\n",
    "\tlevel8.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel8.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on hard voting classifier\n",
    "\tmodel = StackingClassifier(estimators=level8, final_estimator=hard_voting, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models seperately\n",
    "level8 = list()\n",
    "level8.append(('qda', qda))\n",
    "level8.append(('lda', lda))\n",
    "level8.append(('log', log))\n",
    "level8.append(('knn', knn_7))\n",
    "level8.append(('dtc', dtc))\n",
    "level8.append(('hard voting', hard_voting))\n",
    "level8.append(('rfc tuned', rfc_tuned))\n",
    "level8.append(('xgbc', xgbc))\n",
    "level8.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on hard voting classifier\n",
    "#stack8_hv = StackingClassifier(estimators=level8, final_estimator=hard_voting, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "#stack8_hv = stack8_hv.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "#stack8_hv_y_pred = stack8_hv.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ValueError: Input X contains NaN.\n",
    "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.isfinite(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(np.isnan(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 8 models learnt on hard voting classifier: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack8_hv_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 8 models learnt on hard voting classifier: ' + str(round(metrics.recall_score(Y_test, np.round(stack8_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 8 models learnt on hard voting classifier: ' + str(round(metrics.precision_score(Y_test, np.round(stack8_hv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 8 models learnt on hard voting classifier: ' + str(round(metrics.f1_score(Y_test, np.round(stack8_hv_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.3  <a class=\"anchor\" id=\"8_2_3\"></a> Top 7 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/\n",
    "\n",
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "\t# define the base models\n",
    "\tlevel0 = list()\n",
    "\tlevel0.append(('lda', lda))\n",
    "\tlevel0.append(('log', log))\n",
    "\tlevel0.append(('knn', knn_7))\n",
    "\tlevel0.append(('dtc', dtc))\n",
    "\tlevel0.append(('hard voting', hard_voting))\n",
    "\tlevel0.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel0.append(('xgbc', xgbc))\n",
    "\n",
    "\t# define the stacking ensemble\n",
    "\tmodel = StackingClassifier(estimators=level0, final_estimator=hard_voting, cv=5)\n",
    "\treturn model\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['LDA'] = lda\n",
    "\tmodels['LOG'] = log\n",
    "\tmodels['KNN'] = knn_7\n",
    "\tmodels['DTC'] = dtc\n",
    "\tmodels['HD'] = hard_voting\n",
    "\tmodels['RFC_T'] = rfc_tuned\n",
    "\tmodels['XGBC'] = xgbc\n",
    "\tmodels['STACKING'] = get_stacking()\n",
    "\treturn models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, Y):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, Y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, Y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models separately\n",
    "level7 = list()\n",
    "level7.append(('lda', lda))\n",
    "level7.append(('log', log))\n",
    "level7.append(('knn', knn_7))\n",
    "level7.append(('dtc', dtc))\n",
    "level7.append(('hard voting', hard_voting))\n",
    "level7.append(('rfc tuned', rfc_tuned))\n",
    "level7.append(('xgbc', xgbc))\n",
    "level7.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel7 = list()\n",
    "\tlevel7.append(('lda', lda))\n",
    "\tlevel7.append(('log', log))\n",
    "\tlevel7.append(('knn', knn_7))\n",
    "\tlevel7.append(('dtc', dtc))\n",
    "\tlevel7.append(('hard voting', hard_voting))\n",
    "\tlevel7.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel7.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on base XGBC\n",
    "\tmodel = StackingClassifier(estimators=level7, final_estimator=xgbc, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on base XGBC\n",
    "stack7_xgbc = StackingClassifier(estimators=level7, final_estimator=xgbc, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack7_xgbc = stack7_xgbc.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack7_xgbc_y_pred = stack7_xgbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 7 models learnt on base XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack7_xgbc_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 7 models learnt on base XGBC:' + str(round(metrics.recall_score(Y_test, np.round(stack7_xgbc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 7 models learnt on base XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(stack7_xgbc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 7 models learnt on base XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(stack7_xgbc_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel7 = list()\n",
    "\tlevel7.append(('lda', lda))\n",
    "\tlevel7.append(('log', log))\n",
    "\tlevel7.append(('knn', knn_7))\n",
    "\tlevel7.append(('dtc', dtc))\n",
    "\tlevel7.append(('hard voting', hard_voting))\n",
    "\tlevel7.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel7.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on base XGBC\n",
    "\tmodel = StackingClassifier(estimators=level7, final_estimator=hard_voting, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on hard voting classifier\n",
    "stack7_hv = StackingClassifier(estimators=level7, final_estimator=hard_voting, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack7_hv = stack7_hv.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack7_hv_y_pred = stack7_hv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 7 models based on hard voting classifier: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack7_hv_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 7 models based on hard voting classifier: ' + str(round(metrics.recall_score(Y_test, np.round(stack7_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 7 models based on hard voting classifier: ' + str(round(metrics.precision_score(Y_test, np.round(stack7_hv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 7 models based on hard voting classifier: ' + str(round(metrics.f1_score(Y_test, np.round(stack7_hv_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.4  <a class=\"anchor\" id=\"8_2_4\"></a> Top 6 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models\n",
    "level6 = list()\n",
    "level6.append(('log', log))\n",
    "level6.append(('knn', knn_7))\n",
    "level6.append(('dtc', dtc))\n",
    "level6.append(('hard voting', hard_voting))\n",
    "level6.append(('rfc tuned', rfc_tuned))\n",
    "level6.append(('xgbc', xgbc))\n",
    "level6.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel0 = list()\n",
    "\tlevel0.append(('log', log))\n",
    "\tlevel0.append(('knn', knn_7))\n",
    "\tlevel0.append(('dtc', dtc))\n",
    "\tlevel0.append(('hard voting', hard_voting))\n",
    "\tlevel0.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel0.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on hard voting classifier\n",
    "\tmodel = StackingClassifier(estimators=level0, final_estimator=hard_voting, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on hard voting classifier\n",
    "stack6_hv = StackingClassifier(estimators=level6, final_estimator=hard_voting, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack6_hv = stack6_hv.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack6_hv_y_pred = stack6_hv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 6 models learnt on hard voting classifier: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack6_hv_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 6 models learnt on hard voting classifier: ' + str(round(metrics.recall_score(Y_test, np.round(stack6_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 6 models learnt on hard voting classifier: ' + str(round(metrics.precision_score(Y_test, np.round(stack6_hv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 6 models learnt on hard voting classifier: ' + str(round(metrics.f1_score(Y_test, np.round(stack6_hv_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel0 = list()\n",
    "\tlevel0.append(('log', log))\n",
    "\tlevel0.append(('knn', knn_7))\n",
    "\tlevel0.append(('dtc', dtc))\n",
    "\tlevel0.append(('hard voting', hard_voting))\n",
    "\tlevel0.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel0.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on base Gaussian classifier\n",
    "\tmodel = StackingClassifier(estimators=level0, final_estimator=xgbc, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on base Gaussian classifier\n",
    "stack6_xgbc = StackingClassifier(estimators=level6, final_estimator=xgbc, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack6_xgbc = stack6_xgbc.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack6_xgbc_y_pred = stack6_xgbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 6 models learnt on base XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack6_xgbc_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 6 models learnt on base XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(stack6_xgbc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 6 models learnt on base XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(stack6_xgbc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 6 models learnt on base XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(stack6_xgbc_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['LOG'] = log\n",
    "\tmodels['KNN'] = knn_7\n",
    "\tmodels['DTC'] = dtc\n",
    "\tmodels['HD'] = hard_voting\n",
    "\tmodels['RFC_T'] = rfc_tuned\n",
    "\tmodels['XGBC'] = xgbc\n",
    "\tmodels['STACKING'] = get_stacking()\n",
    "\treturn models\n",
    "\n",
    "# Evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, Y):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, Y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    "\n",
    "# Get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# Evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, Y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "\n",
    "# Plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.5  <a class=\"anchor\" id=\"8_2_4\"></a> Top 5 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models separately\n",
    "level5 = list()\n",
    "level5.append(('knn', knn_7))\n",
    "level5.append(('dtc', dtc))\n",
    "level5.append(('hard voting', hard_voting))\n",
    "level5.append(('rfc tuned', rfc_tuned))\n",
    "level5.append(('xgbc', xgbc))\n",
    "level5.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel5 = list()\n",
    "\tlevel5.append(('knn', knn_7))\n",
    "\tlevel5.append(('dtc', dtc))\n",
    "\tlevel5.append(('hard voting', hard_voting))\n",
    "\tlevel5.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel5.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on hard voting classifier\n",
    "\tmodel = StackingClassifier(estimators=level5, final_estimator=hard_voting, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on hard voting classifier\n",
    "stack5_hv = StackingClassifier(estimators=level5, final_estimator=hard_voting, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack5_hv = stack5_hv.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack5_hv_y_pred = stack5_hv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 5 models learnt on hard voting classifier: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack5_hv_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 5 models learnt on hard voting classifier: ' + str(round(metrics.recall_score(Y_test, np.round(stack5_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 5 models learnt on hard voting classifier: ' + str(round(metrics.precision_score(Y_test, np.round(stack5_hv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 5 models learnt on hard voting classifier: ' + str(round(metrics.f1_score(Y_test, np.round(stack5_hv_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel5 = list()\n",
    "\tlevel5.append(('knn', knn_7))\n",
    "\tlevel5.append(('dtc', dtc))\n",
    "\tlevel5.append(('hard voting', hard_voting))\n",
    "\tlevel5.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel5.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on base Gaussian classifier\n",
    "\tmodel = StackingClassifier(estimators=level5, final_estimator=xgbc, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on base Gaussian classifier\n",
    "stack5_xgbc = StackingClassifier(estimators=level5, final_estimator=xgbc, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack5_xgbc = stack5_xgbc.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack5_xgbc_y_pred = stack5_xgbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 5 models learnt on base XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack5_xgbc_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 5 models learnt on base XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(stack5_xgbc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 5 models learnt on base XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(stack5_xgbc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 5 models learnt on base XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(stack5_xgbc_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.6  <a class=\"anchor\" id=\"8_2_6\"></a> Top 4 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel4 = list()\n",
    "\tlevel4.append(('svm_t', svm_tuned))\n",
    "\tlevel4.append(('rfc', rfc))\n",
    "\tlevel4.append(('sv', soft_voting))\n",
    "\tlevel4.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on hard voting classifier\n",
    "\tmodel = StackingClassifier(estimators=level4, final_estimator=soft_voting, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models separately\n",
    "level4 = list()\n",
    "level4.append(('svm_t', svm_tuned))\n",
    "level4.append(('rfc', rfc))\n",
    "level4.append(('sv', soft_voting))\n",
    "level4.append(('xgbc', xgbc))\n",
    "level4.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on hard voting classifier\n",
    "stack4_sv = StackingClassifier(estimators=level4, final_estimator=soft_voting, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack4_sv = stack4_sv.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack4_sv_y_pred = stack4_sv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 4 models learnt on soft voting classifier: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack4_sv_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 4 models learnt on soft voting classifier: ' + str(round(metrics.recall_score(Y_test, np.round(stack4_sv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 4 models learnt on soft voting classifier: ' + str(round(metrics.precision_score(Y_test, np.round(stack4_sv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 4 models learnt on soft voting classifier: ' + str(round(metrics.f1_score(Y_test, np.round(stack4_sv_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.7  <a class=\"anchor\" id=\"8_2_7\"></a> Top 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel3 = list()\n",
    "\tlevel3.append(('rfc', rfc))\n",
    "\tlevel3.append(('sv', soft_voting))\n",
    "\tlevel3.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on hard voting classifier\n",
    "\tmodel = StackingClassifier(estimators=level3, final_estimator=soft_voting, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models separately\n",
    "level3 = list()\n",
    "level3.append(('rfc', rfc))\n",
    "level3.append(('sv', soft_voting))\n",
    "level3.append(('xgbc', xgbc))\n",
    "level3.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on hard voting classifier\n",
    "stack3_sv = StackingClassifier(estimators=level3, final_estimator=soft_voting, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack3_sv = stack3_sv.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack3_sv_y_pred = stack3_sv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with 3 models learnt on soft voting classifier: 82.3%\n",
      "Recall score with 3 models learnt on soft voting classifier: 82.3%\n",
      "Precision score with 3 models learnt on soft voting classifier: 82.3%\n",
      "F1 score with 3 models learnt on soft voting classifier: 82.3%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 3 models learnt on soft voting classifier: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack3_sv_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 3 models learnt on soft voting classifier: ' + str(round(metrics.recall_score(Y_test, np.round(stack3_sv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 3 models learnt on soft voting classifier: ' + str(round(metrics.precision_score(Y_test, np.round(stack3_sv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 3 models learnt on soft voting classifier: ' + str(round(metrics.f1_score(Y_test, np.round(stack3_sv_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel3 = list()\n",
    "\tlevel3.append(('hard voting', hard_voting))\n",
    "\tlevel3.append(('rfc tuned', rfc_tuned))\n",
    "\tlevel3.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on tuned random forest classifier\n",
    "\tmodel = StackingClassifier(estimators=level3, final_estimator=rfc_tuned, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models separately\n",
    "level3 = list()\n",
    "level3.append(('hard voting', hard_voting))\n",
    "level3.append(('rfc tuned', rfc_tuned))\n",
    "level3.append(('xgbc', xgbc))\n",
    "level3.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on tuned random forest classifier\n",
    "stack3_rfc_t = StackingClassifier(estimators=level3, final_estimator=rfc_tuned, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack3_rfc_t = stack3_rfc_t.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack3_rfc_t_y_pred = stack3_rfc_t.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 3 models learnt on tuned RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack3_rfc_t_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 3 models learnt on tuned RFC: ' + str(round(metrics.recall_score(Y_test, np.round(stack3_rfc_t_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 3 models learnt on tuned RFC: ' + str(round(metrics.precision_score(Y_test, np.round(stack3_rfc_t_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 3 models learnt on tuned RFC: ' + str(round(metrics.f1_score(Y_test, np.round(stack3_rfc_t_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.8  <a class=\"anchor\" id=\"8_2_8\"></a> Top 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel2 = list()\n",
    "\tlevel2.append(('hard voting', hard_voting))\n",
    "\tlevel2.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on hard voting classifier\n",
    "\tmodel = StackingClassifier(estimators=level2, final_estimator=hard_voting, cv=5)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models separately\n",
    "level2 = list()\n",
    "level2.append(('hard voting', hard_voting))\n",
    "level2.append(('xgbc', xgbc))\n",
    "level2.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stacking ensemble learnt on hard voting classifier\n",
    "stack2_hv = StackingClassifier(estimators=level2, final_estimator=hard_voting, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack2_hv = stack2_hv.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack2_hv_y_pred = stack2_hv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 2 models learnt on hard voting classifier: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack2_hv_y_pred)), 3)*100)+'%')\n",
    "print('Recall score with 2 models learnt on hard voting classifier: ' + str(round(metrics.recall_score(Y_test, np.round(stack2_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score with 2 models learnt on hard voting classifier: ' + str(round(metrics.precision_score(Y_test, np.round(stack2_hv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 2 models learnt on hard voting classifier: ' + str(round(metrics.f1_score(Y_test, np.round(stack2_hv_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: <a class=\"anchor\" id=\"part9\"></a> Evaluation of the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1  <a class=\"anchor\" id=\"9_1\"></a> Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL: https://pythonawesome.com/multi-class-confusion-matrix-library-in-python/#:~:text=PyCM%20is%20a%20multi-class%20confusion%20matrix%20library%20written,that%20supports%20most%20classes%20and%20overall%20statistics%20parameters.\n",
    "\n",
    "y_actu = Y_test['Rec_Class'].to_numpy()\n",
    "y_pred = stack3_hv_y_pred\n",
    "cm = ConfusionMatrix(actual_vector=y_actu, predict_vector=y_pred)\n",
    "cm.classes\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AUC of class 0 is 0.52 which is poor.\n",
    "* AUC of class 1 is 0.79 which is good.\n",
    "* AUC of class 2 is 0.82 which is very good.\n",
    "<br />\n",
    "<br />\n",
    "* F1 of class 0 is 0.09 which is poor.\n",
    "* F1 of class 1 is 0.78 which is good.\n",
    "* F1 of class 2 is 0.82 which is very good.\n",
    "<br />\n",
    "<br />\n",
    "Class 0 - low recoverability/unrecoverable projects\n",
    "Class 1 - average recoverability\n",
    "Class 2 - highly recoverable projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://www.stackvidhya.com/plot-confusion-matrix-in-python-and-why/#:~:text=You%20can%20create%20the%20confusion%20matrix%20using%20the,Positives%2C%20False%20Negatives%2C%20and%20True%20negatives.%20%2A%2A%20Snippet%2A%2A\n",
    "\n",
    "plt.subplots(figsize = (8,7))\n",
    "final_matrix = confusion_matrix(Y_test, stack3_hv_y_pred)\n",
    "ax = sns.heatmap(final_matrix/np.sum(final_matrix), annot=True, fmt='.1%', linewidths=.2, cmap='Greens')\n",
    "\n",
    "ax.set_title('Confusion Matrix of the Final Recoverability Model\\n', fontsize = 14);\n",
    "ax.set_xlabel('\\nPredicted recoverability class')\n",
    "ax.set_ylabel('Actual recoverability class');\n",
    "ax.xaxis.set_ticklabels(['low','average', 'high'])\n",
    "ax.yaxis.set_ticklabels(['low','average', 'high'])\n",
    "plt.savefig('figures/rec/Confusion Matrix of the Final Recoverability Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2  <a class=\"anchor\" id=\"9_2\"></a> Cost matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL: https://imbalanced-ensemble.readthedocs.io/en/latest/auto_examples/classification/plot_cost_matrix.html\n",
    "\n",
    "init_kwargs = {\n",
    "    'n_estimators': 5,\n",
    "    'random_state': 1,\n",
    "}\n",
    "adacost_clf = imbens.ensemble.AdaCostClassifier(**init_kwargs)\n",
    "\n",
    "cost_matrices = {}\n",
    "\n",
    "def plot_cost_matrix(cost_matrix, title:str, **kwargs):\n",
    "    ax = sns.heatmap(data=cost_matrix, **kwargs)\n",
    "    ax.set_ylabel('Predicted class')\n",
    "    ax.set_xlabel('Ground truth')\n",
    "    ax.set_title(title)\n",
    "\n",
    "adacost_clf.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default cost matrix\n",
    "plt.subplots(figsize = (8,7))\n",
    "title = 'Misclassification Cost Matrix\\n(by inverse class frequency)'\n",
    "cost_matrices[title] = adacost_clf.cost_matrix_\n",
    "plot_cost_matrix(adacost_clf.cost_matrix_, title, annot=True, cmap='YlOrRd', vmax=17, linewidths=.2)\n",
    "plt.savefig('figures/rec/Misclassification Cost Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cost matrix:\n",
    "* correct classification of highly recoverable projects gives a +1 benefit,\n",
    "* misclassification of a highly recoverable project as average project has nearly the same impact 0f 0.94 units,\n",
    "* whilst mistaking a highly recoverable project for an unrecoverable one is neutral (+0.059);\n",
    "<br />\n",
    "<br />\n",
    "* correct classification of average projects gives a +1 benefit,\n",
    "* misclassification of an average project as highly recoverable project has nearly the same impact of +1.1 units,\n",
    "* mistaking an average project for an unrecoverable one is also neutral (+0.063);\n",
    "<br />\n",
    "<br />\n",
    "* correct classification of unrecoverable projects gives a +1 benefit,\n",
    "* misclassification of an unrecoverable project for an average one brings 16 units of impact,\n",
    "* mistaking an unrecoverable project for highly recoverable has the most drastic impact on prediction cost with 17 units of impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3  <a class=\"anchor\" id=\"9_3\"></a> Receiver Operating Characteristic (ROC) curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack3_hv_param = stack3_hv.get_params()\n",
    "stack3_hv_param['num_class'] = 3\n",
    "stack3_hv_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovrc_param = OVRC.get_params()\n",
    "ovrc_param['num_class'] = 3\n",
    "ovrc_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://stackoverflow.com/questions/45332410/roc-for-multiclass-classification\n",
    "\n",
    "# Binarize the output\n",
    "Y = label_binarize(Y, classes=[0, 1, 2])\n",
    "n_classes = Y.shape[1]\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "FINAL_MODEL = stack3_hv\n",
    "OVRC = OneVsRestClassifier(FINAL_MODEL)\n",
    "OVRC.fit(X_train, Y_train)\n",
    "\n",
    "Y = label_binarize(Y, classes=[0,1,2])\n",
    "\n",
    "# Shuffle and split training and test sets\n",
    "X_train, X_test, Y_train, Y_test =\\\n",
    "    train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Classifier\n",
    "Y_score = OVRC.fit(X_train, Y_train).predict(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], Y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('false positive rate')\n",
    "    plt.ylabel('true Positive Rate')\n",
    "    plt.title('ROC curve class {}'.format(i))\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    plt.savefig('figures/rec/ROC curve for each recoverability class.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://stackoverflow.com/questions/56090541/how-to-plot-precision-and-recall-of-multiclass-classifier\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i],\n",
    "                                  Y_score[:, i])\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label='class {}'.format(i))\n",
    "\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.title('ROC curve for all classes')\n",
    "plt.show()\n",
    "plt.savefig('figures/rec/ROC curve for all recoverability classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://stackoverflow.com/questions/45332410/roc-for-multiclass-classification\n",
    "\n",
    "# Binarize the output\n",
    "Y = label_binarize(Y, classes=[0, 1, 2])\n",
    "n_classes = Y.shape[1]\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "FINAL_MODEL = xgbc\n",
    "OVRC = OneVsRestClassifier(FINAL_MODEL)\n",
    "OVRC.fit(X_train, Y_train)\n",
    "\n",
    "Y = label_binarize(Y, classes=[0,1,2])\n",
    "n_classes = 3\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, Y_train, Y_test =\\\n",
    "    train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "# classifier\n",
    "Y_score = OVRC.fit(X_train, Y_train).predict(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], Y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('false positive rate')\n",
    "    plt.ylabel('true Positive Rate')\n",
    "    plt.title('ROC curve class {}'.format(i))\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    plt.savefig('figures/rec/ROC curve for each recoverability class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://stackoverflow.com/questions/56090541/how-to-plot-precision-and-recall-of-multiclass-classifier\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i],\n",
    "                                  Y_score[:, i])\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label='class {}'.format(i))\n",
    "\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.title('ROC curve for all classes')\n",
    "plt.show()\n",
    "plt.savefig('figures/rec/ROC curve for all recoverability classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4  <a class=\"anchor\" id=\"9_4\"></a> Precision-recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://stackoverflow.com/questions/56090541/how-to-plot-precision-and-recall-of-multiclass-classifier\n",
    "\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "for i in range(3):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(Y_test[:, i],\n",
    "                                                        Y_score[:, i])\n",
    "    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Precision vs. Recall Curve')\n",
    "plt.show()\n",
    "plt.savefig('figures/rec/Precision-recall curve for all recoverability classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5  <a class=\"anchor\" id=\"9_5\"></a> Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc.feature_names = X.columns\n",
    "final_feature_importance = pd.DataFrame({'Feature': xgbc.feature_names,'Importance':xgbc.feature_importances_})\n",
    "final_feature_importance = final_feature_importance.sort_values(by = ['Importance'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a bar plot for feature importance\n",
    "fig, ax = plt.subplots(figsize = (16,10))\n",
    "sns.barplot(final_feature_importance['Importance'], final_feature_importance['Feature'], color = 'green')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.xticks(rotation = 'horizontal')\n",
    "plt.title('Feature Importance')\n",
    "plt.savefig('figures/rec/Final Feature Importance')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32faf87829e52f10b3379fa51fb017496aba8a2082e84bf41be67a5b199752f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
