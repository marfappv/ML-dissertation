{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">MSIN0114: Business Analytics Consulting Project</h1>\n",
    "<h2 align=\"center\">Recoverability of Client X projects: run 3</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentials\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from pandas.api.types import CategoricalDtype\n",
    "pd.options.display.max_columns = None\n",
    "import sqlite3\n",
    "import pyodbc\n",
    "import numpy as np; np.random.seed(1)\n",
    "\n",
    "# Image creation and display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import pyplot\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Metrics of accuracy\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from pycm import *\n",
    "import imbalanced_ensemble as imbens\n",
    "from imbalanced_ensemble.ensemble.base import sort_dict_by_key\n",
    "from collections import Counter\n",
    "\n",
    "# Fine-tuning and enseble learning\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Other\n",
    "import itertools as it\n",
    "import io\n",
    "import os\n",
    "os.sys.path\n",
    "import sys\n",
    "import glob\n",
    "import concurrent.futures\n",
    "from __future__ import print_function\n",
    "import binascii\n",
    "import struct\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import scipy.cluster\n",
    "import datetime, time\n",
    "import functools, operator\n",
    "from datetime import datetime\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv-files/resampled_compact_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[['Rec_Class']]\n",
    "X = df.drop(columns = ['Rec_Class', 'Profit_Class'])\n",
    "X1 = pd.DataFrame(preprocessing.normalize(X))\n",
    "X1.columns = X.columns\n",
    "X = X1\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=1, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "log = LogisticRegression(random_state = 1, max_iter = 30000)\n",
    "log.fit(X_train, Y_train.values.ravel())\n",
    "log_y_pred=log.predict(X_test)\n",
    "\n",
    "# Ridge regression\n",
    "rdg = RidgeClassifier(alpha=1.0, random_state = 1, max_iter = 30000)\n",
    "rdg.fit(X_train, Y_train.values.ravel())\n",
    "rdg_y_pred=rdg.predict(X_test)\n",
    "\n",
    "# k-Neighbours\n",
    "np.random.seed(1)\n",
    "knn_100 = KNeighborsClassifier(n_neighbors=100)\n",
    "knn_100.fit(X_train, Y_train.values.ravel())\n",
    "knn_100_y_pred = knn_100.predict(X_test)\n",
    "\n",
    "# Decision tree classifier\n",
    "dtc = DecisionTreeClassifier(random_state = 1)\n",
    "dtc = dtc.fit(X_train, Y_train.values.ravel())\n",
    "dtc_y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Random forest classifier\n",
    "rfc = RandomForestClassifier(random_state=1)\n",
    "rfc.fit(X_train, Y_train.values.ravel())\n",
    "# Logistic regression\n",
    "log = LogisticRegression(random_state = 1, max_iter = 30000)\n",
    "log.fit(X_train, Y_train.values.ravel())\n",
    "log_y_pred=log.predict(X_test)\n",
    "\n",
    "# Ridge regression\n",
    "rdg = RidgeClassifier(alpha=1.0, random_state = 1, max_iter = 30000)\n",
    "rdg.fit(X_train, Y_train.values.ravel())\n",
    "rdg_y_pred=rdg.predict(X_test)\n",
    "\n",
    "# k-Neighbours\n",
    "np.random.seed(1)\n",
    "knn_100 = KNeighborsClassifier(n_neighbors=100)\n",
    "knn_100.fit(X_train, Y_train.values.ravel())\n",
    "knn_100_y_pred = knn_100.predict(X_test)\n",
    "\n",
    "# Decision tree classifier\n",
    "dtc = DecisionTreeClassifier(random_state = 1)\n",
    "dtc = dtc.fit(X_train, Y_train.values.ravel())\n",
    "dtc_y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Random forest classifier\n",
    "rfc = RandomForestClassifier(random_state=1)\n",
    "rfc.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# XGBoost classifier\n",
    "xgbc = XGBClassifier(n_estimators=100, learning_rate=0.05, booster='gbtree', random_state = 1, eval_metric='mlogloss', objective='binary:logistic', use_label_encoder=False)\n",
    "xgbc.fit(X_train, Y_train.values.ravel())\n",
    "xgbc_y_pred=xgbc.predict(X_test)\n",
    "\n",
    "# Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, Y_train.values.ravel())\n",
    "gnb_y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Linear discriminant analysis\n",
    "lda = LinearDiscriminantAnalysis(n_components = 1)\n",
    "lda.fit(X_train, Y_train.values.ravel())\n",
    "lda_y_pred = lda.predict(X_test)\n",
    "\n",
    "# Quadratic discriminant analysis\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, Y_train.values.ravel())\n",
    "qda_y_pred = qda.predict(X_test)\n",
    "\n",
    "# Support vector machine\n",
    "svm_tuned = SVC(kernel='rbf', C = 2, gamma = 3, random_state = 1, probability=True)\n",
    "svm_tuned.fit(X_train, Y_train.values.ravel())\n",
    "svm_y_pred = svm_tuned.predict(X_test)\n",
    "\n",
    "# Soft voting classifier\n",
    "soft_voting = VotingClassifier(estimators=[('xgbc', xgbc), ('rfc', rfc), ('svm_t', svm_tuned)],voting='soft')\n",
    "soft_voting.fit(X_train, Y_train.values.ravel())\n",
    "sv_y_pred = soft_voting.predict(X_test)\n",
    "\n",
    "# Hard voting classifier\n",
    "hard_voting = VotingClassifier(estimators=[('xgbc', xgbc), ('rfc', rfc), ('svm_t', svm_tuned)], voting='hard')\n",
    "hard_voting.fit(X_train, Y_train.values.ravel())\n",
    "hv_y_pred = hard_voting.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.1  <a class=\"anchor\" id=\"8_2_1\"></a> Top 9 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See results for **HV** in pr_run_1, **base XGBC** in pr_run_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel9 = list()\n",
    "\tlevel9.append(('dtc', dtc))\n",
    "\tlevel9.append(('knn', knn_100))\n",
    "\tlevel9.append(('rdg', rdg))\n",
    "\tlevel9.append(('lda', lda))\n",
    "\tlevel9.append(('log', log))\n",
    "\tlevel9.append(('svm_t', svm_tuned))\n",
    "\tlevel9.append(('rfc', rfc))\n",
    "\tlevel9.append(('hv', hard_voting))\n",
    "\tlevel9.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on base random forest classifier\n",
    "\tmodel = StackingClassifier(estimators=level9, final_estimator=rfc, cv=5)\n",
    "\treturn model\n",
    "\n",
    "# Define the base models separately\n",
    "level9 = list()\n",
    "level9.append(('dtc', dtc))\n",
    "level9.append(('knn', knn_100))\n",
    "level9.append(('rdg', rdg))\n",
    "level9.append(('lda', lda))\n",
    "level9.append(('log', log))\n",
    "level9.append(('svm_t', svm_tuned))\n",
    "level9.append(('rfc', rfc))\n",
    "level9.append(('hv', hard_voting))\n",
    "level9.append(('xgbc', xgbc))\n",
    "level9.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "stack9_rfc = StackingClassifier(estimators=level9, final_estimator=rfc, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack9_rfc = stack9_rfc.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack9_rfc_y_pred = stack9_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with 9 models learnt on base RFC: 79.2%\n",
      "Recall score  with 9 models learnt on base RFC: 79.2%\n",
      "Precision score  with 9 models learnt on base RFC: 79.2%\n",
      "F1 score with 9 models learnt on base RFC: 79.2%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 9 models learnt on base RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack9_rfc_y_pred)), 3)*100)+'%')\n",
    "print('Recall score  with 9 models learnt on base RFC: ' + str(round(metrics.recall_score(Y_test, np.round(stack9_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score  with 9 models learnt on base RFC: ' + str(round(metrics.precision_score(Y_test, np.round(stack9_rfc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 9 models learnt on base RFC: ' + str(round(metrics.f1_score(Y_test, np.round(stack9_rfc_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.2  <a class=\"anchor\" id=\"8_2_2\"></a> Top 8 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See results for **HV** in pr_run_1, **base XGBC** in pr_run_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel8 = list()\n",
    "\tlevel8.append(('knn', knn_100))\n",
    "\tlevel8.append(('rdg', rdg))\n",
    "\tlevel8.append(('lda', lda))\n",
    "\tlevel8.append(('log', log))\n",
    "\tlevel8.append(('svm_t', svm_tuned))\n",
    "\tlevel8.append(('rfc', rfc))\n",
    "\tlevel8.append(('hv', hard_voting))\n",
    "\tlevel8.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on base random forest classifier\n",
    "\tmodel = StackingClassifier(estimators=level8, final_estimator=rfc, cv=5)\n",
    "\treturn model\n",
    "\n",
    "# Define the base models separately\n",
    "level8 = list()\n",
    "level8.append(('knn', knn_100))\n",
    "level8.append(('rdg', rdg))\n",
    "level8.append(('lda', lda))\n",
    "level8.append(('log', log))\n",
    "level8.append(('svm_t', svm_tuned))\n",
    "level8.append(('rfc', rfc))\n",
    "level8.append(('hv', hard_voting))\n",
    "level8.append(('xgbc', xgbc))\n",
    "level8.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "stack8_rfc = StackingClassifier(estimators=level8, final_estimator=rfc, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack8_rfc = stack8_rfc.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack8_rfc_y_pred = stack8_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with 8 models learnt on base RFC: 76.5%\n",
      "Recall score  with 8 models learnt on base RFC: 76.5%\n",
      "Precision score  with 8 models learnt on base RFC: 76.5%\n",
      "F1 score with 8 models learnt on base RFC: 76.5%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 8 models learnt on base RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack8_rfc_y_pred)), 3)*100)+'%')\n",
    "print('Recall score  with 8 models learnt on base RFC: ' + str(round(metrics.recall_score(Y_test, np.round(stack8_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score  with 8 models learnt on base RFC: ' + str(round(metrics.precision_score(Y_test, np.round(stack8_rfc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 8 models learnt on base RFC: ' + str(round(metrics.f1_score(Y_test, np.round(stack8_rfc_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.3  <a class=\"anchor\" id=\"8_2_3\"></a> Top 7 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See results for **HV** in pr_run_1, **base XGBC** in pr_run_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel7 = list()\n",
    "\tlevel7.append(('rdg', rdg))\n",
    "\tlevel7.append(('lda', lda))\n",
    "\tlevel7.append(('log', log))\n",
    "\tlevel7.append(('svm_t', svm_tuned))\n",
    "\tlevel7.append(('rfc', rfc))\n",
    "\tlevel7.append(('hv', hard_voting))\n",
    "\tlevel7.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on base random forest classifier\n",
    "\tmodel = StackingClassifier(estimators=level7, final_estimator=rfc, cv=5)\n",
    "\treturn model\n",
    "\n",
    "# Define the base models separately\n",
    "level7 = list()\n",
    "level7.append(('rdg', rdg))\n",
    "level7.append(('lda', lda))\n",
    "level7.append(('log', log))\n",
    "level7.append(('svm_t', svm_tuned))\n",
    "level7.append(('rfc', rfc))\n",
    "level7.append(('hv', hard_voting))\n",
    "level7.append(('xgbc', xgbc))\n",
    "level7.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "stack7_rfc = StackingClassifier(estimators=level7, final_estimator=rfc, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack7_rfc = stack7_rfc.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack7_rfc_y_pred = stack7_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with 7 models learnt on base RFC: 77.2%\n",
      "Recall score  with 7 models learnt on base RFC: 77.2%\n",
      "Precision score  with 7 models learnt on base RFC: 77.2%\n",
      "F1 score with 7 models learnt on base RFC: 77.2%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 7 models learnt on base RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack7_rfc_y_pred)), 3)*100)+'%')\n",
    "print('Recall score  with 7 models learnt on base RFC: ' + str(round(metrics.recall_score(Y_test, np.round(stack7_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score  with 7 models learnt on base RFC: ' + str(round(metrics.precision_score(Y_test, np.round(stack7_rfc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 7 models learnt on base RFC: ' + str(round(metrics.f1_score(Y_test, np.round(stack7_rfc_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.4  <a class=\"anchor\" id=\"8_2_4\"></a> Top 6 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See results for **base XGBC and base RFC** in pr_run_2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.5  <a class=\"anchor\" id=\"8_2_5\"></a> Top 5 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See results for **base XGBC and HV** in pr_run_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel5 = list()\n",
    "\tlevel5.append(('log', log))\n",
    "\tlevel5.append(('svm_t', svm_tuned))\n",
    "\tlevel5.append(('rfc', rfc))\n",
    "\tlevel5.append(('hv', hard_voting))\n",
    "\tlevel5.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on base random forest classifier classifier\n",
    "\tmodel = StackingClassifier(estimators=level5, final_estimator=rfc, cv=5)\n",
    "\treturn model\n",
    "\n",
    "# Define the base models separately\n",
    "level5 = list()\n",
    "level5.append(('log', log))\n",
    "level5.append(('svm_t', svm_tuned))\n",
    "level5.append(('rfc', rfc))\n",
    "level5.append(('hv', hard_voting))\n",
    "level5.append(('xgbc', xgbc))\n",
    "level5.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "stack5_rfc = StackingClassifier(estimators=level5, final_estimator=rfc, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack5_rfc = stack5_rfc.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack5_rfc_y_pred = stack5_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with 5 models learnt on base RFC: 76.2%\n",
      "Recall score  with 5 models learnt on base RFC: 76.2%\n",
      "Precision score  with 5 models learnt on base RFC: 76.2%\n",
      "F1 score with 5 models learnt on base RFC: 76.2%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 5 models learnt on base RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack5_rfc_y_pred)), 3)*100)+'%')\n",
    "print('Recall score  with 5 models learnt on base RFC: ' + str(round(metrics.recall_score(Y_test, np.round(stack5_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score  with 5 models learnt on base RFC: ' + str(round(metrics.precision_score(Y_test, np.round(stack5_rfc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 5 models learnt on base RFC: ' + str(round(metrics.f1_score(Y_test, np.round(stack5_rfc_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.6  <a class=\"anchor\" id=\"8_2_6\"></a> Top 4 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See results for **SV** in pr_run_1, **HV** in pr_run_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel4 = list()\n",
    "\tlevel4.append(('svm_t', svm_tuned))\n",
    "\tlevel4.append(('rfc', rfc))\n",
    "\tlevel4.append(('hv', hard_voting))\n",
    "\tlevel4.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on hard voting classifier\n",
    "\tmodel = StackingClassifier(estimators=level4, final_estimator=xgbc, cv=5)\n",
    "\treturn model\n",
    "\n",
    "# Define the base models separately\n",
    "level4 = list()\n",
    "level4.append(('svm_t', svm_tuned))\n",
    "level4.append(('rfc', rfc))\n",
    "level4.append(('xgbc', xgbc))\n",
    "level4.append(('hv', hard_voting))\n",
    "level4.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "stack4_xgbc = StackingClassifier(estimators=level4, final_estimator=xgbc, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack4_xgbc = stack4_xgbc.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack4_xgbc_y_pred = stack4_xgbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with 4 models learnt on base XGBC: 77.2%\n",
      "Recall score  with 4 models learnt on base XGBC: 77.2%\n",
      "Precision score  with 4 models learnt on base XGBC: 77.5%\n",
      "F1 score with 4 models learnt on base XGBC: 77.10000000000001%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 4 models learnt on base XGBC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack4_xgbc_y_pred)), 3)*100)+'%')\n",
    "print('Recall score  with 4 models learnt on base XGBC: ' + str(round(metrics.recall_score(Y_test, np.round(stack4_xgbc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score  with 4 models learnt on base XGBC: ' + str(round(metrics.precision_score(Y_test, np.round(stack4_xgbc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 4 models learnt on base XGBC: ' + str(round(metrics.f1_score(Y_test, np.round(stack4_xgbc_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel4 = list()\n",
    "\tlevel4.append(('svm_t', svm_tuned))\n",
    "\tlevel4.append(('rfc', rfc))\n",
    "\tlevel4.append(('hv', hard_voting))\n",
    "\tlevel4.append(('xgbc', xgbc))\n",
    "\n",
    "\t# Define the stacking ensemble learnt on random forest classifer\n",
    "\tmodel = StackingClassifier(estimators=level4, final_estimator=rfc, cv=5)\n",
    "\treturn model\n",
    "\n",
    "# Define the base models separately\n",
    "level4 = list()\n",
    "level4.append(('svm_t', svm_tuned))\n",
    "level4.append(('rfc', rfc))\n",
    "level4.append(('xgbc', xgbc))\n",
    "level4.append(('hv', hard_voting))\n",
    "level4.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "stack4_rfc = StackingClassifier(estimators=level4, final_estimator=rfc, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack4_rfc = stack4_rfc.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack4_rfc_y_pred = stack4_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with 4 models learnt on base RFC: 76.2%\n",
      "Recall score  with 4 models learnt on base RFC: 76.2%\n",
      "Precision score  with 4 models learnt on base RFC: 76.3%\n",
      "F1 score with 4 models learnt on base RFC: 76.2%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 4 models learnt on base RFC: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack4_rfc_y_pred)), 3)*100)+'%')\n",
    "print('Recall score  with 4 models learnt on base RFC: ' + str(round(metrics.recall_score(Y_test, np.round(stack4_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score  with 4 models learnt on base RFC: ' + str(round(metrics.precision_score(Y_test, np.round(stack4_rfc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 4 models learnt on base RFC: ' + str(round(metrics.f1_score(Y_test, np.round(stack4_rfc_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.7  <a class=\"anchor\" id=\"8_2_7\"></a> Top 3 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See results for See results for **HV, SV, base RFC on SV** in pr_run_1, **XGBC, base RFC on HV** in pr_run_2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.8  <a class=\"anchor\" id=\"8_2_8\"></a> Top 2 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See results for **HV, SV** in pr_run_1, **base XGBC** in pr_run_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel2 = list()\n",
    "\tlevel2.append(('xgbc', xgbc))\n",
    "\tlevel2.append(('hv', hard_voting))\n",
    "\n",
    "\t# Define the stacking ensemble\n",
    "\tmodel = StackingClassifier(estimators=level2, final_estimator=rfc, cv=5)\n",
    "\treturn model\n",
    "\n",
    "# Define the base models separately\n",
    "level2 = list()\n",
    "level2.append(('xgbc', xgbc))\n",
    "level2.append(('hv', hard_voting))\n",
    "level2.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "stack2_rfc = StackingClassifier(estimators=level2, final_estimator=rfc, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack2_rfc = stack2_rfc.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack2_rfc_y_pred = stack2_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with 2 models learnt on base RFC with HV: 69.69999999999999%\n",
      "Recall score  with 2 models learnt on base RFC with HV: 69.69999999999999%\n",
      "Precision score  with 2 models learnt on base RFC with HV: 69.69999999999999%\n",
      "F1 score with 2 models learnt on base RFC with HV: 69.69999999999999%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 2 models learnt on base RFC with HV: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack2_rfc_y_pred)), 3)*100)+'%')\n",
    "print('Recall score  with 2 models learnt on base RFC with HV: ' + str(round(metrics.recall_score(Y_test, np.round(stack2_rfc_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score  with 2 models learnt on base RFC with HV: ' + str(round(metrics.precision_score(Y_test, np.round(stack2_rfc_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 2 models learnt on base RFC with HV: ' + str(round(metrics.f1_score(Y_test, np.round(stack2_rfc_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel2 = list()\n",
    "\tlevel2.append(('xgbc', xgbc))\n",
    "\tlevel2.append(('sv', soft_voting))\n",
    "\n",
    "\t# Define the stacking ensemble\n",
    "\tmodel = StackingClassifier(estimators=level2, final_estimator=rfc, cv=5)\n",
    "\treturn model\n",
    "\n",
    "# Define the base models separately\n",
    "level2 = list()\n",
    "level2.append(('xgbc', xgbc))\n",
    "level2.append(('sv', soft_voting))\n",
    "level2.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "stack2_rfc_sv = StackingClassifier(estimators=level2, final_estimator=rfc, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack2_rfc_sv = stack2_rfc_sv.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack2_rfc_sv_y_pred = stack2_rfc_sv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with 2 models learnt on base RFC with SV: 82.19999999999999%\n",
      "Recall score  with 2 models learnt on base RFC with SV: 82.19999999999999%\n",
      "Precision score  with 2 models learnt on base RFC with SV: 82.19999999999999%\n",
      "F1 score with 2 models learnt on base RFC with SV: 82.1%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 2 models learnt on base RFC with SV: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack2_rfc_sv_y_pred)), 3)*100)+'%')\n",
    "print('Recall score  with 2 models learnt on base RFC with SV: ' + str(round(metrics.recall_score(Y_test, np.round(stack2_rfc_sv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score  with 2 models learnt on base RFC with SV: ' + str(round(metrics.precision_score(Y_test, np.round(stack2_rfc_sv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 2 models learnt on base RFC with SV: ' + str(round(metrics.f1_score(Y_test, np.round(stack2_rfc_sv_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "\t# Define the base models\n",
    "\tlevel2 = list()\n",
    "\tlevel2.append(('svm_t', svm_tuned))\n",
    "\tlevel2.append(('hv', hard_voting))\n",
    "\n",
    "\t# Define the stacking ensemble\n",
    "\tmodel = StackingClassifier(estimators=level2, final_estimator=svm_tuned, cv=5)\n",
    "\treturn model\n",
    "\n",
    "# Define the base models separately\n",
    "level2 = list()\n",
    "level2.append(('svm_t', svm_tuned))\n",
    "level2.append(('hv', hard_voting))\n",
    "level2.append(('stacking', get_stacking()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "stack2_svm_t_hv = StackingClassifier(estimators=level2, final_estimator=svm_tuned, cv=5)\n",
    "\n",
    "# Fit the model on all available data\n",
    "stack2_svm_t_hv = stack2_svm_t_hv.fit(X, Y.values.ravel())\n",
    "\n",
    "# Predict the response for test set\n",
    "stack2_svm_t_hv_y_pred = stack2_svm_t_hv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with 2 models learnt on tuned SVM with HV: 80.9%\n",
      "Recall score  with 2 models learnt on tuned SVM with HV: 80.9%\n",
      "Precision score  with 2 models learnt on tuned SVM with HV: 81.3%\n",
      "F1 score with 2 models learnt on tuned SVM with HV: 80.9%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy measures\n",
    "print('Accuracy score with 2 models learnt on tuned SVM with HV: ' + str(round(metrics.accuracy_score(Y_test, np.round(stack2_svm_t_hv_y_pred)), 3)*100)+'%')\n",
    "print('Recall score  with 2 models learnt on tuned SVM with HV: ' + str(round(metrics.recall_score(Y_test, np.round(stack2_svm_t_hv_y_pred), average='weighted'), 3)*100)+'%')\n",
    "print('Precision score  with 2 models learnt on tuned SVM with HV: ' + str(round(metrics.precision_score(Y_test, np.round(stack2_svm_t_hv_y_pred), average='weighted', zero_division=1), 3)*100)+'%')\n",
    "print('F1 score with 2 models learnt on tuned SVM with HV: ' + str(round(metrics.f1_score(Y_test, np.round(stack2_svm_t_hv_y_pred), average='weighted'), 3)*100)+'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32faf87829e52f10b3379fa51fb017496aba8a2082e84bf41be67a5b199752f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
