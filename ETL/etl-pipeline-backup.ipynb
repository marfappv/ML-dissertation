{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f4ab4c",
   "metadata": {
    "id": "57f4ab4c"
   },
   "source": [
    "<h1 align=\"center\">MSIN0114: Business Analytics Consulting Project</h1>\n",
    "<h2 align=\"center\">S2R Analytics</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e892fa8b",
   "metadata": {
    "id": "e892fa8b"
   },
   "source": [
    "# Table of Contents\n",
    "\n",
    "**Data enginering**\n",
    "\n",
    "* [Part 0](#part0): Data extraction\n",
    "\n",
    "* [Part 1](#part1): Data transformation\n",
    "    * [1.1](#1.1): Project\n",
    "    * [1.2](#1.2): Client\n",
    "    * [1.3](#1.3): Transactions\n",
    "    * [1.4](#1.4): Data health\n",
    "    * [1.5](#1.5): What else?\n",
    "    \n",
    "* [Part 2](#part2): Data loading\n",
    "    * [2.1](#2.1): Database design\n",
    "    * [2.2](#2.2): Data storage\n",
    "\n",
    "**Predictive analytics**\n",
    "\n",
    "* [Part 3](#part3): Data splitting and scaling\n",
    "* [Part 4](#part4): Model training\n",
    "* [Part 5](#part5): Performance evaluation\n",
    "* [Part 6](#part6): Feature importance and statistical tests\n",
    "* [Part 7](#part7): Converting the output\n",
    "* [Part 8](#part8): Pipeline creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p89ifKLxEcrr",
   "metadata": {
    "id": "p89ifKLxEcrr"
   },
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F8qq-kkSaAp1",
   "metadata": {
    "id": "F8qq-kkSaAp1"
   },
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install plotly\n",
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BpTEkpFbb0yS",
   "metadata": {
    "id": "BpTEkpFbb0yS"
   },
   "outputs": [],
   "source": [
    "#Essentials\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from pandas.api.types import CategoricalDtype\n",
    "pd.options.display.max_columns = None\n",
    "import numpy as np; np.random.seed(2022)\n",
    "import random\n",
    "import sqlite3\n",
    "import pyodbc\n",
    "\n",
    "#Image creation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import pyplot\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#Image display\n",
    "from IPython.display import Image as image\n",
    "from IPython.display import display\n",
    "\n",
    "#Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#Other\n",
    "import itertools as it\n",
    "import io\n",
    "import os\n",
    "os.sys.path\n",
    "import sys\n",
    "import glob\n",
    "import concurrent.futures\n",
    "from __future__ import print_function\n",
    "import binascii\n",
    "import struct\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import scipy.cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8712833",
   "metadata": {},
   "source": [
    "## Part 0: <a class=\"anchor\" id=\"part0\"></a> Data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a65fe96",
   "metadata": {},
   "source": [
    "API scripts from Jonny."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdb1179",
   "metadata": {
    "id": "7cdb1179"
   },
   "source": [
    "## Part 1: <a class=\"anchor\" id=\"part1\"></a> Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G1HNJaLU3WGg",
   "metadata": {
    "id": "G1HNJaLU3WGg"
   },
   "source": [
    "Check whether the database is relational or flat file. If flat file, proceed to step 3. If RDB, make it a flat file, i.e., make the data table a 2-dimensional table. Convert the hierarchical database into a flat one.\n",
    "\n",
    "URL: https://stackoverflow.com/questions/52122119/create-database-using-python-on-jupyter-notebook#:~:text=read%20the%20CSV%20df%20%3D%20pd.read_csv%20%28%27sample.csv%27%29%20connect,creates%20a%20Any_Database_Name.db%20file%20in%20the%20current%20directory?msclkid=92378564cf7911eca8118bfb618ee4dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ef8575",
   "metadata": {},
   "source": [
    "URL: https://sparkbyexamples.com/pyspark/select-columns-from-pyspark-dataframe/#:~:text=You%20can%20select%20the%20single%20or%20multiple%20columns,ways%20to%20select%20single%2C%20multiple%20or%20all%20columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411c2673",
   "metadata": {},
   "source": [
    "### 1.1 <a class=\"anchor\" id=\"1_1\"></a> Projects (wga.projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9baf2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from Synergy API\n",
    "api_projects = pd.read_csv('wga_synergy_incremental_projects.csv')\n",
    "\n",
    "\n",
    "# Drop unnecesary columns\n",
    "api_projects.drop(columns = ['Unnamed: 0', 'Primary Contact Name', 'Project Status', 'Status Name',\n",
    "                             'customFields', 'Address Line 1', 'Address Line 2', 'Project Type ID',\n",
    "                             'Primary Contact', 'Primary Contact ID', 'Project Scope', 'Address Postal Code',\n",
    "                             'Address State', 'Address Town', 'Address Google', 'Client Reference Number',\n",
    "                             'Address State Postal Code Country', 'Address Single Line', 'Project Type Code',\n",
    "                             'External Name', 'Address Longitude', 'Address Latitude',\n",
    "                             'Project Forecast Value', 'Created Date', 'Updated Date', 'Manager ID'], inplace = True)\n",
    "\n",
    "\n",
    "# Drop all internal projects\n",
    "api_projects = api_projects[(api_projects['Is Office Project'] != 'Yes') & (api_projects['Is Billable'] != 'No')]\n",
    "api_projects.drop(columns = ['Project Number', 'Project Name', 'Is Office Project', 'Is Billable'], inplace = True)\n",
    "\n",
    "\n",
    "# Drop rows that are not 'Complete', 'Active' or 'Pending Invoice'\n",
    "projects_status = pd.read_csv('wga_synergy_overnight_1_projects_status.csv')\n",
    "projects_status.rename(columns = {'Project Status ID': 'Status ID', 'Group': 'Project Status'}, inplace = True)\n",
    "projects_status.drop(columns = ['Unnamed: 0', 'Status Name', 'Status Type', 'Success Factor'], inplace = True)\n",
    "api_projects = pd.merge(api_projects, projects_status, how='left', left_on='Status ID', right_on='Status ID')\n",
    "api_projects.drop(columns = 'Status ID', inplace = True)\n",
    "api_projects = api_projects[api_projects['Project Status'].isin(['Complete', 'Active', 'Pending Invoice']) == True]\n",
    "\n",
    "\n",
    "# Convert columns for unified style\n",
    "api_projects.rename(columns = {'Invoices':'Number of Invoices', 'Project Net Residual (Neg as Zero)':'Project Net Residual',\n",
    "                              'Start Date (Project)': 'Project Start Date', 'End Date (Project)': 'Project End Date',\n",
    "                              'Address Country':'Country'}, inplace = True)\n",
    "api_projects['Country'].replace(['AUSTRALIA', 'AUS', 'Autralia', 'NZ', 'new zealand', 'PNG', 'samoa', 'SAMOA', 'TONGA', 'SA', 'CHINA'],\n",
    "                                ['Australia', 'Australia', 'Australia', 'New Zealand', 'New Zealand', 'Papua New Guinea', 'Samoa', 'Samoa', 'Tonga', 'Saudi Arabia', 'China'],inplace=True)\n",
    "api_projects['Project Start Date'] = pd.to_datetime(api_projects['Project Start Date'])\n",
    "api_projects['Project End Date'] = pd.to_datetime(api_projects['Project End Date'])\n",
    "\n",
    "\n",
    "# Move 31 'Commercial' project types to 'Commercial & Retail Buildings' projet types\n",
    "api_projects['Project Type'].mask(api_projects['Project Type'] == 'Commercial', 'Commercial & Retail Buildings', inplace=True)\n",
    "\n",
    "\n",
    "# Adding 'Due Date' and'Project Director' columns\n",
    "custom_fields = pd.read_csv('wga_synergy_incremental_projects_custom_fields.csv')\n",
    "custom_fields = custom_fields[['PROPOSAL - Due Date', 'PROSPECT - Project Director', 'Project ID']].copy()\n",
    "custom_fields.rename(columns = {'PROSPECT - Project Director':'Project Director', 'PROPOSAL - Due Date': 'Due Date'}, inplace = True)\n",
    "custom_fields['Due Date'] = pd.to_datetime(custom_fields['Due Date'])\n",
    "api_projects = pd.merge(api_projects, custom_fields,  how='left', left_on='Project ID', right_on='Project ID')\n",
    "\n",
    "\n",
    "# Rearrange column names for easier interpretation\n",
    "api_projects = api_projects[['Project ID', 'Organisation ID', 'Country',\n",
    "                             'Project Status', 'Project Type',\n",
    "                             'Project Director', 'Project Manager', 'Office',\n",
    "                             'Project Start Date', 'Project End Date', 'Due Date',\n",
    "                             'Default Rate Group','Number of Invoices', 'Project Net Residual']]\n",
    "\n",
    "\n",
    "api_projects.head(1)\n",
    "len(api_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8709b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pre-transformed data from PowerBI\n",
    "pbi_projects = pd.read_csv('wga_power_bi_projects.csv', encoding = 'ISO-8859-1')\n",
    "pbi_projects = pbi_projects[['Project ID', 'Project Number', 'Project Name',\n",
    "                             'Project Size Sort Order', 'Project Duration (Weeks)',\n",
    "                             'Sector', 'Is Multi Discipline Project',\n",
    "                             'Is First Client Project',  'Project Status Group',\n",
    "                             'Is Office Project', 'Is Billable','Is INT Project']].copy()\n",
    "\n",
    "# Exclude all projects that we are not interested in\n",
    "pbi_projects = pbi_projects[pbi_projects['Project Status Group'].isin(['Complete', 'Active', 'Pending Invoice']) == True]\n",
    "pbi_projects = pbi_projects[(pbi_projects['Project Number'] != 'Internal')]\n",
    "pbi_projects = pbi_projects[(pbi_projects['Project Name'] != 'Internal')]\n",
    "pbi_projects = pbi_projects[(pbi_projects['Is INT Project'] != 'Yes')]\n",
    "pbi_projects = pbi_projects[(pbi_projects['Is Office Project'] != 'Yes') & (pbi_projects['Is Billable'] != 'No')]\n",
    "pbi_projects.drop(columns = ['Project Number', 'Project Name', 'Is Office Project', 'Is Billable', 'Is INT Project', 'Project Status Group'], inplace = True)\n",
    "\n",
    "\n",
    "# Convert columns for unified style\n",
    "pbi_projects.rename(columns = {'Project Duration (Weeks)':'Project Duration Weeks'}, inplace = True)\n",
    "pbi_projects['Is Multi Discipline Project'].replace(['No', 'Yes'],[False, True],inplace=True)\n",
    "pbi_projects['Is First Client Project'].replace(['No', 'Yes'],[False, True],inplace=True)\n",
    "\n",
    "\n",
    "pbi_projects.head(1)\n",
    "len(pbi_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2d0ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_projects.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae491ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_projects.drop(columns = ['Unnamed: 0', 'Project Number', 'Primary Contact Name', 'Status Name',\n",
    "                             'customFields', 'Address Line 1', 'Address Line 2',\n",
    "                             'Primary Contact', 'Primary Contact ID', 'Project Scope', 'Address Postal Code',\n",
    "                             'Address State', 'Address Town', 'Address Google', 'Client Reference Number',\n",
    "                             'Address State Postal Code Country', 'Address Single Line', 'Project Type Code',\n",
    "                             'External Name', 'Address Longitude', 'Address Latitude',\n",
    "                             'Project Forecast Value', 'Project Type'], inplace = True)\n",
    "inc_projects.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b009f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_projects['Is Office Project'].value_counts()\n",
    "inc_projects['Is Billable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf5446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_projects['Is Office Project'].replace(['No', 'Yes'],[False, True],inplace=True)\n",
    "inc_projects['Is Office Project'].value_counts()\n",
    "\n",
    "inc_projects['Is Billable'].replace(['No', 'Yes'],[False, True],inplace=True)\n",
    "inc_projects['Is Billable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96e230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_projects.rename(columns = {'Invoices':'Number of Invoices', 'Project Net Residual (Neg as Zero)':'Project Net Residual',\n",
    "                              'Start Date (Project)': 'Project Start Date', 'End Date (Project)': 'Project End Date'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf61005",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_projects['Address Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e9326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_projects['Address Country'].replace(['AUSTRALIA', 'AUS', 'Autralia', 'NZ', 'new zealand', 'PNG', 'samoa', 'SAMOA', 'TONGA', 'SA', 'CHINA'],\n",
    "                                        ['Australia', 'Australia', 'Australia', 'New Zealand', 'New Zealand', 'Papua New Guinea', 'Samoa', 'Samoa', 'Tonga', 'Saudi Arabia', 'China'],inplace=True)\n",
    "                                        \n",
    "inc_projects['Address Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_projects.dtypes.astype(str).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a6df0b",
   "metadata": {},
   "source": [
    "Notice that there are no column with timstamp data type. This means we have to transform start and end date columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e864d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_projects['Project Start Date'] = pd.to_datetime(inc_projects['Project Start Date'])\n",
    "inc_projects['Project Start Year'] = pd.DatetimeIndex(inc_projects['Project Start Date']).year\n",
    "inc_projects['Project Start Month'] = pd.DatetimeIndex(inc_projects['Project Start Date']).month\n",
    "\n",
    "inc_projects['Project End Date'] = pd.to_datetime(inc_projects['Project End Date'])\n",
    "inc_projects['Project End Year'] = pd.DatetimeIndex(inc_projects['Project End Date']).year\n",
    "inc_projects['Project End Month'] = pd.DatetimeIndex(inc_projects['Project End Date']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9df29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_status = pd.read_csv('wga_synergy_overnight_1_projects_status.csv')\n",
    "projects_status.rename(columns = {'Project Status ID':'Status ID', 'Group': 'Project Status Group'}, inplace = True)\n",
    "projects_status.drop(columns = ['Unnamed: 0', 'Status Name', 'Status Type', 'Success Factor'], inplace = True)\n",
    "projects_status.head()\n",
    "len(projects_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289627b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_1 = pd.merge(inc_projects, projects_status, on=['Status ID'])\n",
    "merge_1.head(1)\n",
    "len(merge_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4e0cdf",
   "metadata": {},
   "source": [
    "We want as fewer categorical columns as possible. This is why we will mostly only use IDs rther than full names of stages and project types, so that encoding is not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c923dd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_types = pd.read_csv('wga_synergy_overnight_1_projects_types.csv')\n",
    "projects_types.drop(columns = ['Unnamed: 0', 'Project Type Display', 'Project Type Code'], inplace = True)\n",
    "projects_types.head(1)\n",
    "len(projects_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82880745",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_2 = pd.merge(merge_1, projects_types,  how='left', left_on='Project Type ID', right_on='Project Type ID')\n",
    "merge_2.head(1)\n",
    "len(merge_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5507587",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_fields = pd.read_csv('wga_synergy_incremental_projects_custom_fields.csv')\n",
    "custom_fields.head()\n",
    "len(custom_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b48c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_fields.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c32088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_fields = custom_fields[['PROPOSAL - Due Date', 'PROSPECT - Project Director', 'Project ID']].copy()\n",
    "custom_fields.rename(columns = {'PROSPECT - Project Director':'Project Director', 'PROPOSAL - Due Date': 'Due Date'}, inplace = True)\n",
    "custom_fields['Due Date'] = pd.to_datetime(custom_fields['Due Date'])\n",
    "custom_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31091d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_3 = pd.merge(merge_2, custom_fields,  how='left', left_on='Project ID', right_on='Project ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f034b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_3.columns\n",
    "len(merge_3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a59d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "given_projects = merge_3[['Organisation ID', 'Project ID','Project Name',\n",
    "                          'Status ID', 'Project Status', 'Project Status Group',\n",
    "                          'Project Type ID', 'Project Type Name', 'Is Office Project',\n",
    "                          'Project Director', 'Project Manager', 'Manager ID', 'Office',\n",
    "                          'Address Country','Is Billable', 'Default Rate Group',\n",
    "                          'Number of Invoices', 'Project Net Residual',\n",
    "                          'Created Date', 'Updated Date',\n",
    "                          'Project Start Date', 'Project End Date',\n",
    "                          'Project Start Year', 'Project Start Month',\n",
    "                          'Project End Year','Project End Month', 'Due Date']]\n",
    "len(given_projects.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e493a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the two columns are the same\n",
    "data_compare = [given_projects['Project Status'], given_projects['Project Status Group']]\n",
    "df_compare = pd.concat(data_compare, axis=1)\n",
    "df_compare['same'] = (df_compare['Project Status'] == df_compare['Project Status Group']) \n",
    "\n",
    "# Printing the dataframe\n",
    "df_compare[df_compare['same'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf462923",
   "metadata": {},
   "outputs": [],
   "source": [
    "given_projects['Project Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13cbc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "given_projects['Project Status Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb481dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "given_projects.drop(columns = 'Project Status', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5475ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that are not 'Complete' and 'Active'\n",
    "given_projects = given_projects[given_projects['Project Status Group'].isin(['Complete', 'Active']) == True]\n",
    "given_projects.drop(columns = 'Project Status Group', inplace = True)\n",
    "given_projects.head(1)\n",
    "len(given_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6114129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_bi_projects = pd.read_csv('wga_power_bi_projects.csv', encoding = 'ISO-8859-1')\n",
    "power_bi_projects.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cf4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_bi_projects = pd.read_csv('wga_power_bi_projects.csv', encoding = 'ISO-8859-1')\n",
    "power_bi_projects = power_bi_projects[['Project ID','Project Duration (Weeks)', 'Project Size', 'Project Size Sort Order',\n",
    "                                       'Is Multi Discipline Project', \n",
    "                                       'Project Fee Remaining','Project Fee Remaining - Active Only',\n",
    "                                       'Is First Client Project', 'Primary Service', 'Sector', 'Sub-Sector',\n",
    "                                       'Is INT Project','Project Team Manager', 'Project Status Group']].copy()\n",
    "power_bi_projects = power_bi_projects[power_bi_projects['Project Status Group'].isin(['Complete', 'Active']) == True]\n",
    "power_bi_projects.drop(columns = 'Project Status Group', inplace = True)\n",
    "power_bi_projects.head(1)\n",
    "len(power_bi_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b440564",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_bi_projects.rename(columns = {'Is INT Project':'Is Int Project', 'Sub-Sector': 'Sub Sector',\n",
    "                                    'Project Fee Remaining - Active Only':'Project Fee Remaining Active Only',\n",
    "                                    'Project Duration (Weeks)':'Project Duration Weeks'}, inplace = True)\n",
    "\n",
    "power_bi_projects['Is Multi Discipline Project'].replace(['No', 'Yes'],[False, True],inplace=True)\n",
    "power_bi_projects['Is Multi Discipline Project'].value_counts()\n",
    "\n",
    "power_bi_projects['Is Int Project'].replace(['No', 'Yes'],[False, True],inplace=True)\n",
    "power_bi_projects['Is Int Project'].value_counts()\n",
    "\n",
    "power_bi_projects.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aeb104",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_4 = pd.merge(given_projects, power_bi_projects,  how='left', left_on='Project ID', right_on='Project ID')\n",
    "merge_4.head(1)\n",
    "len(merge_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae7eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_projects = merge_4.copy()\n",
    "engineered_projects['Suffered Data Loss'] = \n",
    "#engineered_projects['Between_March_2020_Jan_2022'] = \n",
    "#engineered_projects['Delivered_on_Time'] =\n",
    "#engineered_projects['Perc_of_Stages_with_Fixed_Fee'] =\n",
    "#engineered_projects['Is_Government_Project'] =\n",
    "#engineered_projects['Sector_Profitability_Rank'] =\n",
    "#engineered_projects.head(1)\n",
    "\n",
    "engineered_projects['End Before July 2018'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fd9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loss_1(x): #projects that started after July 2018 did not suffer from data loss\n",
    "    if ['Project Start Date']date > pd.Timestamp('2018-07-15'):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def data_loss_2(x): #projects that ended before July 2018 did not suffer from data loss\n",
    "    if date < pd.Timestamp('2018-07-15'):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "engineered_projects['Suffered Data Loss_1'] = engineered_projects['Project Start Date'].apply(data_loss_1)\n",
    "engineered_projects['Suffered Data Loss_2'] = engineered_projects['Project End Date'].apply(data_loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13fc291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#engineered_projects['Suffered Data Loss'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e263e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_checker(x): #projects that ended before due date are prompt\n",
    "    if pd.Timestamp(engineered_projects['Project End Date']) > pd.Timestamp(engineered_projects['Due Date']):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d80f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['A','C']].apply(lambda x: my_func(x) if(np.all(pd.notnull(x[1]))) else x, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4111589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_projects['Delivered on Time'] = engineered_projects['Due Date'].apply(prompt_checker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681e67c2",
   "metadata": {},
   "source": [
    "**6 more features to engineer:**\n",
    "* Suffered_Data_Loss\n",
    "* Between_March_2020_Jan_2022\n",
    "* Delivered_on_Time\n",
    "* Is_Government_Project\n",
    "* Sector_Profitability_Rank (research)\n",
    "* Perc_of_Stages_with_Fixed_Fee\n",
    "\n",
    "**Table alterations:**\n",
    "* FK Total_Data_Health_Issues (references 'wga.health' table on 'Alerts_Total_Per_Project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c68d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new column containing all the days between Project_Start_Date and Project_End_Date\n",
    "projects_exec_dates['Execution_Period'] = projects_exec_dates.apply(lambda row: pd.date_range(start=row['Project_Start_Date'], end=row['Project_End_Date'], freq='D'), axis=1)\n",
    "projects_exec_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e3541",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_projects['Project Start Date'] = pd.to_datetime(inc_projects['Project Start Date'])\n",
    "inc_projects['Project Start Year'] = pd.DatetimeIndex(inc_projects['Project Start Date']).year\n",
    "inc_projects['Project Start Month'] = pd.DatetimeIndex(inc_projects['Project Start Date']).month\n",
    "\n",
    "inc_projects['Project End Date'] = pd.to_datetime(inc_projects['Project End Date'])\n",
    "inc_projects['Project End Year'] = pd.DatetimeIndex(inc_projects['Project End Date']).year\n",
    "inc_projects['Project End Month'] = pd.DatetimeIndex(inc_projects['Project End Date']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198af666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suffered_Data_Loss\n",
    "\n",
    "def data_loss_checker(start_date, end_date):\n",
    "    if start_date < pd.Timestamp('2018-07-15') and end_date < pd.Timestamp('2018-07-15'): #project started and ended before the acqusition\n",
    "        return False\n",
    "    elif start_date > pd.Timestamp('2018-07-15') and end_date > pd.Timestamp('2018-07-15'): #project started and ended after the acqusition\n",
    "        return False\n",
    "    elif start_date < pd.Timestamp('2018-07-15') and end_date > pd.Timestamp('2018-07-15'): #project started before the acqusition but ended after it\n",
    "        return True\n",
    "\n",
    "Suffered_Data_Loss = {}\n",
    "\n",
    "for start_date in projects['Project_Start_Date']:\n",
    "    for end_date in projects['Project_End_Date']:\n",
    "            if data_loss_checker(start_date, end_date) == True:\n",
    "                Suffered_Data_Loss[start_date, end_date] = True\n",
    "            else:\n",
    "                Suffered_Data_Loss[start_date, end_date] = False\n",
    "\n",
    "Suffered_Data_Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7156908",
   "metadata": {},
   "source": [
    "### 1.2 <a class=\"anchor\" id=\"1_2\"></a> Clients (wga.clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "overnight_1_clients = pd.read_csv('wga_synergy_overnight_1_clients.csv')\n",
    "overnight_1_clients.drop(columns = {'Client Name', 'Unnamed: 0'}, inplace = True)\n",
    "overnight_1_clients['Contact Type'].replace(['Company', 'Individual'],[1, 0],inplace=True)\n",
    "overnight_1_clients['Created Date'] = pd.to_datetime(overnight_1_clients['Created Date'])\n",
    "overnight_1_clients\n",
    "\n",
    "#client.columns = client.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee61ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_bi_clients = pd.read_csv('wga_power_bi_clients.csv', encoding = 'ISO-8859-1')\n",
    "power_bi_clients.drop(columns = ['ï»¿Synergy URL (Client)', 'Organisation ID', 'Client Name', 'Created Date', 'Contact Type'], inplace=True)\n",
    "power_bi_clients.rename(columns = {'Client Name (Short)':'Short Client Name',\n",
    "                                   'Client Projects - Total No': 'Client Projects Total No',\n",
    "                                   'Client Projects - First Project ID':'1st Project ID'}, inplace = True)\n",
    "power_bi_clients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f6339",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = pd.merge(overnight_1_clients, power_bi_clients,  how='left', left_on='Client ID', right_on='Client ID')\n",
    "clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c6586b",
   "metadata": {},
   "source": [
    "**2 features to engineer:**\n",
    "* Tenure_Duration_Weeks\n",
    "* Is_New\n",
    "\n",
    "**Table alterations:**\n",
    "* FK 1st_Project_ID (links 'wga.projects' table on 'Project_ID')\n",
    "* FK Organisation_ID (references 'wga.projects' table on 'Organisation_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a83e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client['Is_New'] = \n",
    "clients['Tenure_Duration_Weeks'] = (clients['Created Date']-###).apply(lambda x: x/np.timedelta64(1,'M'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9cee98",
   "metadata": {},
   "source": [
    "### 1.3 <a class=\"anchor\" id=\"1_3\"></a> Stages (wga.stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb1097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from API file\n",
    "\n",
    "#sql_stages = pd.read_csv('wga_sql_stages.csv')\n",
    "#sql_stages = sql_stages[[ 'customer', 'id', 'projectId', 'managerId', 'organisationId', 'name', 'accounts','statusId']]\n",
    "#sql_stages.head(1)\n",
    "#len(sql_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e81ec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From PowerBI file\n",
    "stages = pd.read_csv('wga_power_bi_stages.csv', encoding = 'ISO-8859-1')\n",
    "stages = stages[['customer', 'Project ID', 'Stage ID', 'Phase Name (Short)', 'Stage Status Sort Order',\n",
    "                 'Is Disbursement Stage', 'Stage Type', 'Stage Forecast Distribution Type', 'Stage Fee Type',\n",
    "                 'Stage Manager', 'Stage Discipline','Stage Start Date','Stage End Date', 'Stage Updated Date']].copy()\n",
    "\n",
    "stages['Stage Start Date'] = pd.to_datetime(stages['Stage Start Date'])\n",
    "stages['Stage End Date'] = pd.to_datetime(stages['Stage End Date'])\n",
    "stages['Stage Updated Date'] = pd.to_datetime(stages['Stage Updated Date'])\n",
    "stages.rename(columns = {'customer':'Customer','Phase Name (Short)': 'Phase Name'}, inplace = True)\n",
    "stages.columns = stages.columns.str.replace(' ', '_')\n",
    "\n",
    "stages.head(1)\n",
    "len(stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b07c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages['Customer'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da158ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages.drop(columns = 'Customer', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d4b69f",
   "metadata": {},
   "source": [
    "**1 feature to engineer:**\n",
    "* Stage_Duration_Weeks\n",
    "\n",
    "\n",
    "**Table alterations:**\n",
    "* FK Alerts_Total_Per_Stage (references 'wga.health' table on 'Alerts_Total_Per_Stage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc9d4d6",
   "metadata": {},
   "source": [
    "### 1.4 <a class=\"anchor\" id=\"1_4\"></a> Transactions (wga.transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fedbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read only valid projects' transactions\n",
    "transactions = pd.read_csv('wga_sql_transactions.csv')\n",
    "transactions = (transactions[transactions['Project ID'].isin(valid_ids)])\n",
    "\n",
    "transactions = transactions[['id', 'projectId', 'projectNumber', 'projectName',\n",
    "                                     'transactionTypeId','status',\n",
    "                                     'stageId', 'stageName',\n",
    "                                     'expenseType',\n",
    "                                     'invoiceValueTotal',\n",
    "                                     'cost', 'actualCostTotal',\n",
    "                                     'targetChargeTotal', 'standardCostTotal',\n",
    "                                     'valueTotal', 'date']].copy()\n",
    "\n",
    "transactions.rename(columns = {'id':'Transaction_ID', 'projectId':'Project_ID',\n",
    "                                   'transactionTypeId':'Transaction_Type_ID',\n",
    "                                   'status': 'Status', 'stageId': 'Stage_ID', 'stageName':'Stage_Name',\n",
    "                                   'expenseType':'Expense_Type',\n",
    "                                   'invoiceValueTotal': 'Invoice_Value_Total', 'cost': 'Cost',\n",
    "                                   'actualCostTotal':'Actual_Cost_Total',\n",
    "                                   'targetChargeTotal':'Target_Charge_Total',\n",
    "                                   'standardCostTotal':'Standard_Cost_Total',\n",
    "                                   'valueTotal':'Value_Total', 'date':'Date'}, inplace = True)\n",
    "\n",
    "# Drop any rows that have 'Internal' in the project name and the project number columns\n",
    "transactions = transactions[(transactions['projectNumber'] != 'Internal') & (transactions['projectName'] != 'Internal')]\n",
    "transactions.drop(columns = ['projectNumber', 'projectName'], inplace = True)\n",
    "\n",
    "# Transform timestamps from object data type to datetime\n",
    "transactions['Date'] = pd.to_datetime(transactions['Date'])\n",
    "\n",
    "transactions.head(1)\n",
    "len(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d63d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('wga_sql_transactions.csv')\n",
    "original.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71866503",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_transactions = pd.read_csv('wga_sql_transactions.csv')\n",
    "sql_transactions = sql_transactions[['id', 'invoiceNumber', 'projectId','transactionTypeId',\n",
    "                                     'statusId', 'status',\n",
    "                                     'stageId', 'stageName',\n",
    "                                     'taskId', 'taskName',\n",
    "                                     'rateTypeId', 'rateType',\n",
    "                                     'reasonCode', 'expenseType',\n",
    "                                     'writeOffStaffId', 'writeOffStaff',\n",
    "                                     'cost', 'actualCostTotal',\n",
    "                                     'targetChargeTotal', 'standardCostTotal',\n",
    "                                     'valueTotal', 'wipValueTotal', 'isUtilised',\n",
    "                                     'date', 'invoiceDate' ]].copy()\n",
    "\n",
    "sql_transactions.rename(columns = {'Data Quality - Is Forecastable':'DQ_Is_Forecastable',\n",
    "                         'Data Quality - Has Issues': 'DQ_Has_Issues',\n",
    "                         'Data Quality - Has Inactive Staff Resourced':'DQ_Has_Inactive_Staff_Resourced',\n",
    "                         'Data Quality - Rate Group':'DQ_Rate_Group',\n",
    "                         'Health - % Duration Complete':'Health_Perc_Duration_Complete',\n",
    "                         'Health - % Fee Used':'Health_Perc_Fee_Used',\n",
    "                         'Health - Stages With Alerts #':'Alerts_Total_Per_Stage'}, inplace = True)\n",
    "\n",
    "sql_transactions.head(1)\n",
    "len(sql_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02971b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_payments = pd.read_csv('wga_synergy_overnight_1_invoices_payments.csv')\n",
    "invoices_payments.head(1)\n",
    "len(invoices_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc3ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = pd.read_csv('wga_synergy_overnight_1_rates.csv')\n",
    "rates.head()\n",
    "len(rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a819c8c3",
   "metadata": {},
   "source": [
    "**2 features to engineer:**\n",
    "* Tenure_Duration_Weeks\n",
    "* Is_New\n",
    "\n",
    "**Table alterations:**\n",
    "* PK 1st_Project_ID (links 'wga.projects' table on 'Project_ID')\n",
    "* FK Organisation_ID (references 'wga.projects' table on 'Organisation_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16897d55",
   "metadata": {},
   "source": [
    "### 1.5 <a class=\"anchor\" id=\"1_5\"></a> Data health (wga.health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789d6622",
   "metadata": {},
   "outputs": [],
   "source": [
    "health = pd.read_csv('wga_power_bi_stages.csv', encoding = 'ISO-8859-1')\n",
    "\n",
    "health = health[['Project Number', 'Project Name', 'Is INT Project', 'Is Office Project',\n",
    "                 'Project ID', 'Stage ID',\n",
    "                 'Data Quality - Is Forecastable',\n",
    "                 'Data Quality - Has Issues',\n",
    "                 'Data Quality - Has Inactive Staff Resourced', \n",
    "                 'Data Quality - Rate Group', 'Health - % Duration Complete',\n",
    "                 'Health - % Fee Used', 'Health - Stages With Alerts #']].copy()\n",
    "\n",
    "# Exclude all projects that we are not interested in\n",
    "pbi_projects = pbi_projects[pbi_projects['Project Status Group'].isin(['Complete', 'Active', 'Pending Invoice']) == True]\n",
    "\n",
    "pbi_projects = pbi_projects[(pbi_projects['Project Name'] != 'Internal')]\n",
    "pbi_projects = pbi_projects[(pbi_projects['Is INT Project'] != 'Yes')]\n",
    "pbi_projects = pbi_projects[(pbi_projects['Is Office Project'] != 'Yes') & (pbi_projects['Is Billable'] != 'No')]\n",
    "pbi_projects.drop(columns = ['Project Number', 'Project Name', 'Is Office Project', 'Is Billable', 'Is INT Project', 'Project Status Group'], inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "health.rename(columns = {'Data Quality - Is Forecastable':'DQ_Is_Forecastable',\n",
    "                         'Data Quality - Has Issues': 'DQ_Has_Issues',\n",
    "                         'Data Quality - Has Inactive Staff Resourced':'DQ_Has_Inactive_Staff_Resourced',\n",
    "                         'Data Quality - Rate Group':'DQ_Rate_Group',\n",
    "                         'Health - % Duration Complete':'Health_Perc_Duration_Complete',\n",
    "                         'Health - % Fee Used':'Health_Perc_Fee_Used',\n",
    "                         'Health - Stages With Alerts #':'Alerts_Total_Per_Stage'}, inplace = True)\n",
    "\n",
    "health['DQ_Is_Forecastable'].replace(['No', 'Yes'],[False, True],inplace=True)\n",
    "health['DQ_Has_Issues'].replace(['No', 'Yes'],[False, True],inplace=True)\n",
    "health['DQ_Has_Inactive_Staff_Resourced'].replace(['No', 'Yes'],[False, True],inplace=True)\n",
    "health.columns = health.columns.str.replace(' ', '_')\n",
    "\n",
    "health.head(1)\n",
    "len(health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29d1ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checker = health[health['Project_ID'].isin([368035]) == True]\n",
    "checker = checker[['Project_ID', 'Stage_ID', 'Alerts_Total_Per_Stage']]\n",
    "checker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e346b9",
   "metadata": {},
   "source": [
    "**1 feature to engineer:**\n",
    "* Alerts_Total_Per_Project\n",
    "\n",
    "**Table alterations:**\n",
    "\n",
    "* FK Project_ID (references 'wga.projects' table on 'Project_ID')\n",
    "* FK Stage_ID (references 'wga.stages' table on 'Stage_ID')\n",
    "* FK Alerts_Total_Per_Project (links 'wga.projects' table on 'Total_Data_Health_Issues')\n",
    "* FK Alerts_Total_Per_Stage (links 'wga.stages' table on 'Alerts_Total_Per_Stage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed40f7",
   "metadata": {},
   "source": [
    "### 1.6 <a class=\"anchor\" id=\"1_6\"></a> Human resources (wga.hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "staff = pd.read_csv('wga_synergy_overnight_1_staff.csv')\n",
    "staff = staff[['Organisation ID', 'Staff ID', 'Reports To', 'Synergy Team', 'Employment Date', 'Termination Date']]\n",
    "staff.head(1)\n",
    "len(staff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0603ecbc",
   "metadata": {},
   "source": [
    "**1 feature to engineer:**\n",
    "* Employment_Duration_Weeks_by_May_22\n",
    "\n",
    "**Table alterations:**\n",
    "* FK Organisation_ID (references 'wga.projects' table on 'Organisation_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487462cf",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179994b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suffered_Data_Loss\n",
    "def data_loss_1(x): #projects that started after July 2018 did not suffer from data loss\n",
    "    if ['Project Start Date']date > pd.Timestamp('2018-07-15'):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def data_loss_2(x): #projects that ended before July 2018 did not suffer from data loss\n",
    "    if date < pd.Timestamp('2018-07-15'):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# Between_March_2020_Jan_2022\n",
    "\n",
    "\n",
    "# Delivered_on_Time\n",
    "def prompt_checker(x): #projects that ended before due date are prompt\n",
    "    if pd.Timestamp(engineered_projects['Project End Date']) > pd.Timestamp(engineered_projects['Due Date']):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "\n",
    "print(df['new_time'] > pd.Timestamp(2018, 1, 5, 12))\n",
    "\n",
    "# Perc_of_Stages_with_Fixed_Fee\n",
    "\n",
    "# Is_Government_Project\n",
    "\n",
    "# Sector_Profitability_Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bb227d",
   "metadata": {},
   "source": [
    "**Applying functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd09e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26a4d9a4",
   "metadata": {},
   "source": [
    "## Part 2: <a class=\"anchor\" id=\"part2\"></a> Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db3ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a database and connect to it\n",
    "\n",
    "conn = sqlite3.connect('WGA.db') #since the db does not exist, this creates a WGA.db file in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9d978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to a database cerated in MS SQL Server Management Studio\n",
    "\n",
    "server = '.\\sqlexpress' \n",
    "database = 'wga' \n",
    "username = 'sa'  \n",
    "password  = 'marfa'\n",
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+password)\n",
    "cursor = cnxn.cursor()\n",
    "\n",
    "# Test query\n",
    "sql_statement = \"select 1\"\n",
    "response = cursor.execute(sql_statement).fetchone()\n",
    "print(response[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f363bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the tables in the database:\n",
    "\n",
    "sql_transactions.to_sql('sql_transactions', conn)\n",
    "sql_stages.to_sql('sql_stages', conn)\n",
    "sql_stages_snapshot.to_sql('sql_stages_snapshot', conn)\n",
    "\n",
    "\n",
    "inc_projects.to_sql('inc_projects', conn)\n",
    "inc_projects_custom_fields.to_sql('inc_projects_custom_fields', conn)\n",
    "inc_stages_forecast.to_sql('inc_stages_forecast', conn)\n",
    "inc_staff.to_sql('inc_staff', conn)\n",
    "inc_invoices_all_fy22.to_sql('inc_invoices_all_fy22', conn)\n",
    "\n",
    "fy21.to_sql('fy21', conn)\n",
    "fy20.to_sql('fy20', conn)\n",
    "fy19.to_sql('fy19', conn)\n",
    "fy18.to_sql('fy18', conn)\n",
    "fy18_2.to_sql('fy18_2', conn)\n",
    "fy17.to_sql('fy17', conn)\n",
    "fy16.to_sql('fy16', conn)\n",
    "fy15.to_sql('fy15', conn)\n",
    "fy14.to_sql('fy14', conn)\n",
    "fy13.to_sql('fy13', conn)\n",
    "fy12.to_sql('fy12', conn)\n",
    "fy11.to_sql('fy11', conn)\n",
    "fy10.to_sql('fy10', conn)\n",
    "\n",
    "overnight_1_clients.to_sql('overnight_1_clients', conn)\n",
    "overnight_1_invoices_payments.to_sql('overnight_1_invoices_payments', conn)\n",
    "overnight_1_projects_contracts.to_sql('overnight_1_projects_contracts', conn)\n",
    "overnight_1_projects_status.to_sql('overnight_1_projects_status', conn)\n",
    "overnight_1_projects_status_change.to_sql('overnight_1_projects_status_change', conn)\n",
    "overnight_1_projects_types.to_sql('overnight_1_projects_types', conn)\n",
    "overnight_1_rates.to_sql('overnight_1_rates', conn)\n",
    "overnight_1_staff.to_sql('overnight_1_staff', conn)\n",
    "overnight_1_staff_leavers.to_sql('overnight_1_staff_leavers', conn)\n",
    "overnight_1_stages_status_changes.to_sql('overnight_1_stages_status_changes', conn)\n",
    "overnight_2_notes.to_sql('overnight_2_notes', conn)\n",
    "\n",
    "resourcing.to_sql('resourcing', conn)\n",
    "reference_staff_data.to_sql('reference_staff_data', conn)\n",
    "reference_stages_forecast_custom.to_sql('reference_stages_forecast_custom', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440778ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Read a SQL Query out of WGA database and transform it into a pandas dataframe for closer investigation\n",
    "#sql_string = 'SELECT * FROM sql_stages'\n",
    "#sql_stages = pd.read_sql(sql_string, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1301caa6",
   "metadata": {},
   "source": [
    "https://chrisnicoll.net/2020/02/exploring-an-sqlite-database-from-jupyter-notebook/#:~:text=To%20explore%20the%20database%20I%20only%20need%20to,%23%20bog-standard%20read-write%20connection%20conn%20%3D%20sqlite3.connect%20%28%27digikam4.db%27%29?msclkid=37019978cf8711ecac7d1f5d1ef22333 (Nicoll, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b6e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curs = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "curs.execute('SELECT * FROM fy21').description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30fbe6a",
   "metadata": {},
   "source": [
    "## Part 2: <a class=\"anchor\" id=\"part2\"></a> Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d20422e",
   "metadata": {},
   "source": [
    "* convert object columns to numeric columns with the (try) method\n",
    "* drop column with perfect collinearity, like 'project ID'. 'invoice ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c2abbb",
   "metadata": {
    "id": "01c2abbb"
   },
   "source": [
    "## Part 3: <a class=\"anchor\" id=\"part3\"></a> Feature engineeering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f9ea14",
   "metadata": {
    "id": "e4f9ea14"
   },
   "source": [
    "* Size of the team\n",
    "* Project complexity (number of stages)\n",
    "* Client longevity (number of months with the company)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a978012",
   "metadata": {},
   "source": [
    "## Part 4: <a class=\"anchor\" id=\"part4\"></a> Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a051509",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = df.copy()\n",
    "\n",
    "le = LabelEncoder()\n",
    "encoded_df['creator'] = le.fit_transform(encoded_df['creator'])\n",
    "encoded_df['artwork_name'] = le.fit_transform(encoded_df['artwork_name'])\n",
    "encoded_df['collection'] = le.fit_transform(encoded_df['collection'])\n",
    "encoded_df['art_series'] = le.fit_transform(encoded_df['art_series'])\n",
    "encoded_df = encoded_df.drop(columns = ['path'])\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b145be",
   "metadata": {
    "id": "62b145be"
   },
   "source": [
    "## Part 5: <a class=\"anchor\" id=\"part5\"></a> Data splitting and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af858a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into features and labels\n",
    "X = full_df[['creator', 'artwork_name', 'collection',\n",
    "           'art_series', 'media', 'likes', 'nsfw',\n",
    "           'tokens','year', 'rights', 'artwork_counts']]  # Removed original price\n",
    "y = full_df['price_class']\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2022) # 80% training and 20% test\n",
    "print(f\"No. of training data: {X_train.shape[0]}\")\n",
    "print(f\"No. of training targets: {y_train.shape[0]}\")\n",
    "print(f\"No. of testing data: {X_test.shape[0]}\")\n",
    "print(f\"No. of testing targets: {y_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mGzwDUndWgTv",
   "metadata": {
    "id": "mGzwDUndWgTv"
   },
   "source": [
    "## Part 6: <a class=\"anchor\" id=\"part6\"></a> Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c342e541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4ae8041",
   "metadata": {},
   "source": [
    "### 6.5 <a class=\"anchor\" id=\"6_5\"></a> Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL: https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/\n",
    "\n",
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "\t# define the base models\n",
    "\tlevel0 = list()\n",
    "\tlevel0.append(('lr', LogisticRegression()))\n",
    "\tlevel0.append(('knn', KNeighborsClassifier()))\n",
    "\tlevel0.append(('dtc', DecisionTreeClassifier()))\n",
    "\tlevel0.append(('rfc', rfc_tuned))\n",
    "\tlevel0.append(('xgb', XGBClassifier()))\n",
    "\tlevel0.append(('gnb', GaussianNB()))\n",
    "\n",
    "\t# define meta learner model\n",
    "\tlevel1 = rfc_tuned\n",
    "\t# define the stacking ensemble\n",
    "\tmodel = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "\treturn model\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['lr'] = LogisticRegression()\n",
    "\tmodels['knn'] = KNeighborsClassifier()\n",
    "\tmodels['dtc'] = DecisionTreeClassifier()\n",
    "\tmodels['rfc'] = rfc_tuned\n",
    "\tmodels['xgb'] = XGBClassifier()\n",
    "\tmodels['gnb'] = GaussianNB()\n",
    "\tmodels['stacking'] = get_stacking()\n",
    "\treturn models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1375bfc",
   "metadata": {
    "id": "d1375bfc"
   },
   "source": [
    "## Part 7: <a class=\"anchor\" id=\"part7\"></a> Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83573cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81eddfdc",
   "metadata": {
    "id": "81eddfdc"
   },
   "source": [
    "## Part 8: <a class=\"anchor\" id=\"part8\"></a> Feature performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a1f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(rfc_tuned.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfb03a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame for feature importance\n",
    "rfc_tuned.feature_names = normal_df.drop(\"price\", axis = 1).columns\n",
    "rfc_tuned_feature_importance = pd.DataFrame({\"Feature\": rfc_tuned.feature_names,\"Importance\":rfc_tuned.feature_importances_})\n",
    "rfc_tuned_feature_importance = rfc_tuned_feature_importance.sort_values(by = [\"Importance\"], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca1e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a bar plot for feature importance\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize = (14,7))\n",
    "sns.barplot(rfc_tuned_feature_importance[\"Feature\"], rfc_tuned_feature_importance[\"Importance\"], color = \"navy\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Feature Importance Score\")\n",
    "plt.xticks(rotation = \"vertical\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec37fe0",
   "metadata": {
    "id": "fec37fe0"
   },
   "source": [
    "## Part 9: <a class=\"anchor\" id=\"part9\"></a> Converting output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ca723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a04197f8",
   "metadata": {
    "id": "a04197f8"
   },
   "source": [
    "## Part 10: <a class=\"anchor\" id=\"Part 10\"></a> Pipeline creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4413e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of MSIN0097: Predictive Analytics.ipynb",
   "provenance": [
    {
     "file_id": "1wMnYS6Zd-TSClglZnpa6s87vKhDqcJPV",
     "timestamp": 1646991414543
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
